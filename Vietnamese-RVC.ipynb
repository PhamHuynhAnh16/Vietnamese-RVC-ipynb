{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVAACnvlmE4I"
      },
      "source": [
        "# **Ngu·ªìn g·ªëc**\n",
        "\n",
        "**D·ª± √°n n√†y ƒë∆∞·ª£c n·∫•u b·ªüi [Ph·∫°m Hu·ª≥nh Anh](https://github.com/PhamHuynhAnh16)**\n",
        "\n",
        "**D·ª± √°n ƒë∆∞·ª£c n·∫•u d·ª±a tr√™n m·ªôt s·ªë d·ª± √°n ch√≠nh nh∆∞:**\n",
        "\n",
        "**Chuy·ªÉn ƒë·ªïi, X·ª≠ l√Ω, Tr√≠ch xu·∫•t, Hu·∫•n luy·ªán, ƒê·ªçc m√¥ h√¨nh, dung h·ª£p m√¥ h√¨nh, m√¥ h√¨nh hu·∫•n luy·ªán, kho m√¥ h√¨nh...: [Applio](https://github.com/IAHispano/Applio/tree/main?tab=readme-ov-file) c·ªßa nh√≥m [AI Hispano](https://github.com/IAHispano)**\n",
        "\n",
        "**Ph∆∞∆°ng ph√°p tr√≠ch xu·∫•t, c√°ch hi·ªÉn th·ªã th√¥ng tin, c√°ch ghi nh·∫≠t k√Ω, m√¥ h√¨nh hu·∫•n luy·ªán...: [Retrieval-based-Voice-Conversion-WebUI](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI?tab=readme-ov-file) c·ªßa t√°c gi·∫£ [RVC BOSS](https://github.com/RVC-Boss)**\n",
        "\n",
        "**M√¥ h√¨nh t√°ch nh·∫°c MDX-Net v√† Demucs: [Python-audio-separator](https://github.com/nomadkaraoke/python-audio-separator?tab=readme-ov-file) c·ªßa t√°c gi·∫£ [Andrew Beveridge](https://github.com/beveradb)**\n",
        "\n",
        "# **Vui l√≤ng kh√¥ng s·ª≠ d·ª•ng d·ª± √°n v·ªõi b·∫•t k·ª≥ m·ª•c ƒë√≠ch n√†o vi ph·∫°m ƒë·∫°o ƒë·ª©c, ph√°p lu·∫≠t, ho·∫∑c g√¢y t·ªïn h·∫°i ƒë·∫øn c√° nh√¢n, t·ªï ch·ª©c...**\n",
        "\n",
        "# **Trong tr∆∞·ªùng h·ª£p ng∆∞·ªùi s·ª≠ d·ª•ng kh√¥ng tu√¢n th·ªß c√°c ƒëi·ªÅu kho·∫£n ho·∫∑c vi ph·∫°m, t√¥i s·∫Ω kh√¥ng ch·ªãu tr√°ch nhi·ªám v·ªÅ b·∫•t k·ª≥ khi·∫øu n·∫°i, thi·ªát h·∫°i, hay tr√°ch nhi·ªám ph√°p l√Ω n√†o, d√π l√† trong h·ª£p ƒë·ªìng, do s∆° su·∫•t, hay c√°c l√Ω do kh√°c, ph√°t sinh t·ª´, ngo√†i, ho·∫∑c li√™n quan ƒë·∫øn ph·∫ßn m·ªÅm, vi·ªác s·ª≠ d·ª•ng ph·∫ßn m·ªÅm ho·∫∑c c√°c giao d·ªãch kh√°c li√™n quan ƒë·∫øn ph·∫ßn m·ªÅm.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJeRif5jjL5s",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **üåè C√†i ƒë·∫∑t**\n",
        "import os\n",
        "import codecs\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "from threading import Thread\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def download_library_1():\n",
        "  with urllib.request.urlopen(codecs.decode(\"uggcf://uhttvatsnpr.pb/NauC/Pbyno_EIP_Cebwrpg_2/erfbyir/znva/hfe_1.gne.tm\", \"rot13\")) as response:\n",
        "    with tarfile.open(fileobj=response, mode=\"r:gz\") as tar:\n",
        "      tar.extractall(path=\"/usr/local/\")\n",
        "\n",
        "def download_library_2():\n",
        "  with urllib.request.urlopen(codecs.decode(\"uggcf://uhttvatsnpr.pb/NauC/Pbyno_EIP_Cebwrpg_2/erfbyir/znva/hfe_2.gne.tm\", \"rot13\")) as response:\n",
        "    with tarfile.open(fileobj=response, mode=\"r:gz\") as tar:\n",
        "      tar.extractall(path=\"/usr/local/lib/python3.10\")\n",
        "\n",
        "print(\"üë©üèª‚Äçüíª C√†i ƒë·∫∑t...\")\n",
        "\n",
        "download_rvc = Thread(target=lambda: os.system(\"git clone https://github.com/PhamHuynhAnh16/Vietnamese-RVC /content/Vietnamese_RVC\"))\n",
        "download_rvc.start()\n",
        "\n",
        "download_cudann = Thread(target=lambda: os.system(\"apt-get install -y cudnn9-cuda-12\"))\n",
        "download_cudann.start()\n",
        "\n",
        "delete_a = Thread(target=lambda: os.system('rm -rf /usr/local/bin'))\n",
        "delete_b = Thread(target=lambda: os.system('rm -rf /usr/local/lib/python3.10'))\n",
        "\n",
        "delete_a.start()\n",
        "delete_b.start()\n",
        "\n",
        "delete_a.join()\n",
        "delete_b.join()\n",
        "\n",
        "download_a = Thread(target=download_library_1)\n",
        "download_b = Thread(target=download_library_2)\n",
        "\n",
        "download_b.start()\n",
        "download_a.start()\n",
        "\n",
        "download_b.join()\n",
        "download_a.join()\n",
        "\n",
        "download_cudann.join()\n",
        "\n",
        "#@markdown **üíª C√†i ƒë·∫∑t m·∫•t t·ª´ 1-3 ph√∫t**\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 C√†i ƒë·∫∑t xong!\", button_style=\"success\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cIsBEvHaQWMJ"
      },
      "outputs": [],
      "source": [
        "#@title **üì± M·ªü giao di·ªán s·ª≠ d·ª•ng**\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "#@markdown **ƒê·ªÉ tr·∫£i nghi·ªám h·∫øt t√≠nh nƒÉng h√£y d√πng giao di·ªán:) C√≤n mu·ªën ƒë∆°n gi·∫£n th√¨ kh√¥ng d√πng giao di·ªán**\n",
        "\n",
        "#@markdown **N·∫øu bi·∫øt c√≥ th·ªÉ s·ª≠ d·ª•ng bi·ªÉu ƒë·ªì ƒë·ªÉ ki·ªÉm tra hu·∫•n luy·ªán qu√° s·ª©c üëç**\n",
        "su_dung_bieu_do = False #@param {type:\"boolean\"}\n",
        "#@markdown **N·∫øu c√≥ k·∫øt n·ªëi v√† c√≥ l∆∞u m√¥ h√¨nh v√†o drive th√¨ s·∫Ω c√≥ th·ªÉ t·∫£i l·∫°i c√°c m√¥ h√¨nh ƒë·ªÉ hu·∫•n luy·ªán ti·∫øp**\n",
        "tai_mo_hinh_trong_drive = False #@param {type:\"boolean\"}\n",
        "\n",
        "if su_dung_bieu_do:\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir ./assets/logs --port=6870\n",
        "\n",
        "!python main/app/app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkqks7bO2Cye"
      },
      "source": [
        "# **T√πy ch·ªânh th√™m üß∞**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PFEFvYQFCSBk"
      },
      "outputs": [],
      "source": [
        "#@title **C√†i ƒë·∫∑t l·∫°i ƒë·ªô ch√≠nh x√°c üöÄ**\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "#@markdown **ƒê·ªô ch√≠nh x√°c c·ªßa suy lu·∫≠n v√† hu·∫•n luy·ªán**\n",
        "do_chinh_xac = \"fp32\" #@param [\"fp16\", \"fp32\"]\n",
        "\n",
        "from Vietnamese_RVC.main.configs.config import Config\n",
        "Config().set_precision(do_chinh_xac)\n",
        "\n",
        "clear_output()\n",
        "display(Button(description=\"\\u2714 C√†i ƒë·∫∑t xong!\", button_style=\"success\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1cxnr7qP2clf"
      },
      "outputs": [],
      "source": [
        "#@title **K·∫øt n·ªëi ho·∫∑c ng·∫Øt k·∫øt n·ªëi v·ªõi drive ‚òÅ**\n",
        "import os\n",
        "from ipywidgets import Button\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "#@markdown **Khi kh√¥ng t√≠ch v√†o √¥ th√¨ s·∫Ω ng·∫Øt k·∫øt n·ªëi v·ªõi drive**\n",
        "ket_noi_drive = False #@param {\"type\":\"boolean\"}\n",
        "\n",
        "if ket_noi_drive:\n",
        "  if os.path.exists(\"/content/drive\"):\n",
        "    print(\"Google Drive ƒë√£ ƒë∆∞·ª£c k·∫øt n·ªëi s·∫≥n\")\n",
        "  else:\n",
        "    print('üîó K·∫øt n·ªëi v·ªõi drive...')\n",
        "    try:\n",
        "      drive.mount('/content/drive')\n",
        "      clear_output()\n",
        "      display(Button(description=\"\\u2714 K·∫øt n·ªëi xong!\", button_style=\"success\"))\n",
        "    except Exception as e:\n",
        "      raise ValueError(f'ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh k·∫øt n·ªëi drive: {e}')\n",
        "else:\n",
        "  if not os.path.exists(\"/content/drive\"): print(\"Google Drive kh√¥ng ƒë∆∞·ª£c k·∫øt n·ªëi tr∆∞·ªõc ƒë√≥\")\n",
        "  else:\n",
        "    print(\"üîó Ng·∫Øt k·∫øt n·ªëi v·ªõi drive...\")\n",
        "    try:\n",
        "      drive.flush_and_unmount()\n",
        "      clear_output()\n",
        "      display(Button(description=\"\\u2714 Ng·∫Øt xong!\", button_style=\"success\"))\n",
        "    except Exception as e:\n",
        "      raise ValueError(f'ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh ng·∫Øt k·∫øt n·ªëi drive: {e}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pS4-MMA7L9X",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Kh·ªüi ƒë·ªông ho·∫∑c ng·ª´ng sao l∆∞u üõ†**\n",
        "import os\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "\n",
        "logs_folder = '/content/drive/MyDrive/model/logs'; weights_folder = '/content/drive/MyDrive/model/weights'; audios_folder = '/content/drive/MyDrive/audios'\n",
        "\n",
        "#@markdown **N·∫øu kh√¥ng t√≠ch v√†o √¥ n√†o th√¨ s·∫Ω ng·ª´ng k·∫øt n·ªëi ·ªü ph·∫ßn ƒë√≥**\n",
        "khoi_dong_sao_luu_mo_hinh = False #@param {\"type\":\"boolean\"}\n",
        "khoi_dong_sao_luu_am_thanh = False #@param {\"type\":\"boolean\"}\n",
        "#@markdown **Th·ªùi gian gi·ªØa m·ªói l·∫ßn l∆∞u (t√≠nh b·∫±ng gi√¢y)**\n",
        "thoi_gian = 30 # @param {\"type\":\"slider\",\"min\":10,\"max\":100,\"step\":1}\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "from Vietnamese_RVC.main.app.sync import Channel\n",
        "\n",
        "if not \"logs_backup\" in locals(): logs_backup = Channel(\"/content/Vietnamese_RVC/assets/logs\", logs_folder, every=thoi_gian, exclude=\"mute\")\n",
        "if not \"weights_backup\" in locals(): weights_backup = Channel(\"/content/Vietnamese_RVC/assets/weights\", weights_folder, every=thoi_gian)\n",
        "if not \"audio_backup\" in locals(): audio_backup = Channel(\"/content/Vietnamese_RVC/audios\", audios_folder, every=thoi_gian)\n",
        "\n",
        "logs_backup.stop(); weights_backup.stop(); audio_backup.stop()\n",
        "\n",
        "if os.path.exists('/content/drive/MyDrive'):\n",
        "  if khoi_dong_sao_luu_mo_hinh:\n",
        "    if not os.path.exists(logs_folder): os.makedirs(logs_folder)\n",
        "    if not os.path.exists(weights_folder): os.makedirs(weights_folder)\n",
        "\n",
        "    logs_backup.start(); weights_backup.start()\n",
        "  else: logs_backup.stop(); weights_backup.stop()\n",
        "\n",
        "  if khoi_dong_sao_luu_am_thanh:\n",
        "    if not os.path.exists(audios_folder): os.makedirs(audios_folder)\n",
        "    audio_backup.start()\n",
        "  else: audio_backup.stop()\n",
        "\n",
        "  clear_output()\n",
        "else:\n",
        "  try:\n",
        "    drive.mount('/content/drive')\n",
        "  except Exception as e:\n",
        "      raise ValueError(f'ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh k·∫øt n·ªëi drive: {e}')\n",
        "\n",
        "  if khoi_dong_sao_luu_mo_hinh:\n",
        "    if not os.path.exists(logs_folder): os.makedirs(logs_folder)\n",
        "    if not os.path.exists(weights_folder): os.makedirs(weights_folder)\n",
        "\n",
        "    logs_backup.start(); weights_backup.start()\n",
        "  else: logs_backup.stop(); weights_backup.stop()\n",
        "\n",
        "  if khoi_dong_sao_luu_am_thanh:\n",
        "    if not os.path.exists(audios_folder): os.makedirs(audios_folder)\n",
        "    audio_backup.start()\n",
        "  else: audio_backup.stop()\n",
        "\n",
        "  clear_output()\n",
        "\n",
        "Button(description=\"\\u2714 Xong!\", button_style=\"success\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **‚ôªÔ∏è Kh·ªüi ƒë·ªông d·ªçn s·ªçt r√°c**\n",
        "import os\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import auth, drive\n",
        "from IPython.display import clear_output\n",
        "\n",
        "try:\n",
        "  import googleapiclient\n",
        "except:\n",
        "  os.system(\"pip install google-api-python-client\")\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "from main.app.clean import Clean\n",
        "\n",
        "#@markdown **T√≠ch v√†o √¥ ƒë·ªÉ kh·ªüi ƒë·ªông d·ªçn**\n",
        "khoi_dong = False #@param {\"type\":\"boolean\"}\n",
        "#@markdown **Th·ªùi gian gi·ªØa m·ªói l·∫ßn d·ªçn (t√≠nh b·∫±ng gi√¢y)**\n",
        "thoi_gian = 30 # @param {\"type\":\"slider\",\"min\":10,\"max\":100,\"step\":1}\n",
        "\n",
        "if khoi_dong:\n",
        "  if os.path.exists('/content/drive/MyDrive'):\n",
        "    auth.authenticate_user()\n",
        "  else:\n",
        "    try:\n",
        "      drive.mount('/content/drive')\n",
        "    except Exception as e:\n",
        "        raise ValueError(f'ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh k·∫øt n·ªëi drive: {e}')\n",
        "\n",
        "    auth.authenticate_user()\n",
        "    Clean(every=thoi_gian).start()\n",
        "\n",
        "    clear_output()\n",
        "    Button(description=\"\\u2714 Xong!\", button_style=\"success\")\n",
        "else:\n",
        "  Clean().stop()\n",
        "\n",
        "  clear_output()\n",
        "  Button(description=\"\\u2714 Xong!\", button_style=\"success\")"
      ],
      "metadata": {
        "id": "2VfuHALUuW_B",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xbcVxSFMDOV4"
      },
      "outputs": [],
      "source": [
        "#@title **T·∫£i d·ªØ li·ªáu sao l∆∞u t·ª´ drive üìÇ**\n",
        "import os\n",
        "import shutil\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "logs_folder ='/content/drive/MyDrive/model/logs'\n",
        "weights_folder = '/content/drive/MyDrive/model/weights'\n",
        "audios_folder = '/content/drive/MyDrive/audios'\n",
        "\n",
        "#@markdown **T·∫£i c√°c m√¥ h√¨nh hu·∫•n luy·ªán ƒë·ªÉ ti·∫øp t·ª•c hu·∫•n luy·ªán**\n",
        "tai_mo_hinh = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **T·∫£i c√°c √¢m thanh ƒë∆∞·ª£c sao l∆∞u ƒë·ªÉ ti·∫øp t·ª•c s·ª≠ d·ª•ng**\n",
        "tai_am_thanh = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "if os.path.exists(\"/content/drive/MyDrive\"):\n",
        "  if tai_mo_hinh:\n",
        "    if len(os.listdir(logs_folder)) < 1 or len(os.listdir(weights_folder)) < 1: print(\"Kh√¥ng t√¨m th·∫•y d·ªØ Li·ªáu\")\n",
        "    else:\n",
        "      if os.path.exists(\"/content/drive/MyDrive/model\"):\n",
        "        shutil.copytree(logs_folder, \"/content/Vietnamese_RVC/assets/logs\", dirs_exist_ok=True)\n",
        "        shutil.copytree(weights_folder, \"/content/Vietnamese_RVC/assets/weights\", dirs_exist_ok=True)\n",
        "\n",
        "        clear_output()\n",
        "      else: print(\"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu m√¥ h√¨nh\")\n",
        "  elif tai_am_thanh:\n",
        "    if len(os.listdir(audios_folder)) < 1: print(\"Kh√¥ng t√¨m th·∫•y d·ªØ Li·ªáu\")\n",
        "    else:\n",
        "      if os.path.exists(\"/content/drive/MyDrive/audios\"):\n",
        "        shutil.copytree(audios_folder, \"/content/Vietnamese_RVC/audios\", dirs_exist_ok=True)\n",
        "        clear_output()\n",
        "      else: print(\"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu √¢m thanh\")\n",
        "else: print(\"Google drive kh√¥ng ƒë∆∞·ª£c k·∫øt n·ªëi\")\n",
        "\n",
        "display(Button(description=\"\\u2714 T·∫£i l·∫°i xong!\", button_style=\"success\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "n4yZIXYyCqZL"
      },
      "outputs": [],
      "source": [
        "#@title **N√©n v√† l∆∞u m√¥ h√¨nh (Ch∆∞a vi·∫øt)üì¶**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bMHDuWNgEase"
      },
      "outputs": [],
      "source": [
        "#@title **Dung h·ª£p m√¥ h√¨nhüåÄ**\n",
        "import os\n",
        "import torch\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import files\n",
        "from collections import OrderedDict\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "#@markdown **T√™n ƒë·ªÉ l∆∞u m√¥ h√¨nh**\n",
        "ten_mo_hinh = \"\" # @param {\"type\":\"string\",\"placeholder\":\"My_Model.pth\"}\n",
        "#@markdown **ƒê∆∞·ªùng d·∫´n 2 m√¥ h√¨nh c·∫ßn dung h·ª£p**\n",
        "tep_mo_hinh_1 = \"\" # @param {\"type\":\"string\",\"placeholder\":\"assets\\\\\\\\weights\\\\\\\\My_Model_1.pth\"}\n",
        "tep_mo_hinh_2 = \"\" # @param {\"type\":\"string\",\"placeholder\":\"assets\\\\\\\\weights\\\\\\\\My_Model_2.pth\"}\n",
        "#@markdown **Ch·ªânh h∆∞·ªõng v·ªÅ b√™n n√†o s·∫Ω l√†m cho m√¥ h√¨nh gi·ªëng v·ªõi b√™n ƒë√≥**\n",
        "ty_le_mo_hinh = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "#@markdown **X√≥a th√¥ng tin ƒë·∫ßu ra**\n",
        "xoa_dau_ra = False #@param {\"type\":\"boolean\"}\n",
        "\n",
        "def fushion_model(name, pth_1, pth_2, ratio):\n",
        "    if not name: raise ValueError(\"Vui l√≤ng cung c·∫•p t√™n\")\n",
        "    if not name.endswith(\".pth\"): name = name + \".pth\"\n",
        "\n",
        "    if not pth_1 or not os.path.exists(pth_1) or not pth_1.endswith(\".pth\"): raise FileNotFoundError(\"Vui l√≤ng cung c·∫•p m√¥ h√¨nh 1\")\n",
        "    if not pth_2 or not os.path.exists(pth_2) or not pth_1.endswith(\".pth\"): raise FileNotFoundError(\"Vui l√≤ng cung c·∫•p m√¥ h√¨nh 2\")\n",
        "\n",
        "    def extract(ckpt):\n",
        "        a = ckpt[\"model\"]\n",
        "        opt = OrderedDict()\n",
        "        opt[\"weight\"] = {}\n",
        "\n",
        "        for key in a.keys():\n",
        "            if \"enc_q\" in key: continue\n",
        "\n",
        "            opt[\"weight\"][key] = a[key]\n",
        "\n",
        "        return opt\n",
        "\n",
        "    try:\n",
        "        ckpt1 = torch.load(pth_1, map_location=\"cpu\")\n",
        "        ckpt2 = torch.load(pth_2, map_location=\"cpu\")\n",
        "\n",
        "        if ckpt1[\"sr\"] != ckpt2[\"sr\"]: raise RuntimeError(\"T·ªëc ƒë·ªô l·∫•y m·∫´u c·ªßa hai m√¥ h√¨nh kh√¥ng gi·ªëng nhau\")\n",
        "\n",
        "        cfg = ckpt1[\"config\"]\n",
        "        cfg_f0 = ckpt1[\"f0\"]\n",
        "        cfg_version = ckpt1[\"version\"]\n",
        "        cfg_sr = ckpt1[\"sr\"]\n",
        "\n",
        "        ckpt1 = extract(ckpt1) if \"model\" in ckpt1 else ckpt1[\"weight\"]\n",
        "        ckpt2 = extract(ckpt2) if \"model\" in ckpt2 else ckpt2[\"weight\"]\n",
        "\n",
        "        if sorted(list(ckpt1.keys())) != sorted(list(ckpt2.keys())): raise RuntimeError(\"Kh√¥ng th·ªÉ h·ª£p nh·∫•t c√°c m√¥ h√¨nh. C√°c ki·∫øn ‚Äã‚Äãtr√∫c m√¥ h√¨nh kh√¥ng gi·ªëng nhau\")\n",
        "\n",
        "        print(\"B·∫Øt ƒë·∫ßu dung h·ª£p m√¥ h√¨nh...\")\n",
        "\n",
        "        opt = OrderedDict()\n",
        "        opt[\"weight\"] = {}\n",
        "\n",
        "        for key in ckpt1.keys():\n",
        "            if key == \"emb_g.weight\" and ckpt1[key].shape != ckpt2[key].shape:\n",
        "                min_shape0 = min(ckpt1[key].shape[0], ckpt2[key].shape[0])\n",
        "                opt[\"weight\"][key] = (ratio * (ckpt1[key][:min_shape0].float()) + (1 - ratio) * (ckpt2[key][:min_shape0].float())).half()\n",
        "            else: opt[\"weight\"][key] = (ratio * (ckpt1[key].float()) + (1 - ratio) * (ckpt2[key].float())).half()\n",
        "\n",
        "        opt[\"config\"] = cfg\n",
        "        opt[\"sr\"] = cfg_sr\n",
        "        opt[\"f0\"] = cfg_f0\n",
        "        opt[\"version\"] = cfg_version\n",
        "        opt[\"infos\"] = f\"M√¥ h√¨nh ƒë∆∞·ª£c {name} ƒë∆∞·ª£c dung h·ª£p t·ª´ {pth_1} v√† {pth_2} v·ªõi ratio {ratio}\"\n",
        "\n",
        "        output_model = os.path.join(\"assets\", \"weights\")\n",
        "\n",
        "        if not os.path.exists(output_model): os.makedirs(output_model, exist_ok=True)\n",
        "\n",
        "        torch.save(opt, os.path.join(output_model, f\"{name}.pth\"))\n",
        "\n",
        "        print(\"Ho√†n th√†nh\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"ƒê√£ x·∫£y ra l·ªói khi h·ª£p nh·∫•t c√°c m√¥ h√¨nh: {e}\")\n",
        "\n",
        "def upload_model_files():\n",
        "    uploaded = files.upload()\n",
        "    for name, data in uploaded.items():\n",
        "        with open(name, 'wb') as f:\n",
        "            f.write(data)\n",
        "        print(f'T·∫£i L√™n {name}')\n",
        "\n",
        "    return uploaded\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "if not tep_mo_hinh_1:\n",
        "    print(\"H√£y t·∫£i l√™n m√¥ h√¨nh th·ª© 1:\")\n",
        "    uploaded_files_a = upload_model_files()\n",
        "    duong_dan_mo_hinh_1 = list(uploaded_files_a.keys())[0]\n",
        "elif not tep_mo_hinh_2:\n",
        "    print(\"H√£y t·∫£i l√™n m√¥ h√¨nh th·ª© 2:\")\n",
        "    uploaded_files_b = upload_model_files()\n",
        "    duong_dan_mo_hinh_2 = list(uploaded_files_b.keys())[0]\n",
        "else:\n",
        "    duong_dan_mo_hinh_1 = os.path.join(tep_mo_hinh_1)\n",
        "    duong_dan_mo_hinh_2 = os.path.join(tep_mo_hinh_2)\n",
        "\n",
        "fushion_model(ten_mo_hinh, duong_dan_mo_hinh_1, duong_dan_mo_hinh_2, ty_le_mo_hinh)\n",
        "\n",
        "if xoa_dau_ra: clear_output()\n",
        "display(Button(description=\"\\u2714 Th√†nh C√¥ng\", button_style=\"success\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RM_z1GlVEq61",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **ƒê·ªçc th√¥ng tin m√¥ h√¨nhüì∞**\n",
        "import os\n",
        "import torch\n",
        "\n",
        "from datetime import datetime\n",
        "from ipywidgets import Button\n",
        "from google.colab import files\n",
        "from IPython.display import display\n",
        "\n",
        "duong_dan_mo_hinh = \"\" # @param {\"type\":\"string\",\"placeholder\":\"assets\\\\\\\\weights\\\\\\\\My-Model.pth\"}\n",
        "\n",
        "def model_info(path):\n",
        "    if not path or not os.path.exists(path): raise ValueError(\"Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh!\")\n",
        "\n",
        "\n",
        "    def prettify_date(date_str):\n",
        "        if date_str == \"Kh√¥ng t√¨m th·∫•y th·ªùi gian t·∫°o\": return None\n",
        "\n",
        "        try:\n",
        "            return datetime.strptime(date_str, \"%Y-%m-%dT%H:%M:%S.%f\").strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        except ValueError:\n",
        "            return \"ƒê·ªãnh d·∫°ng kh√¥ng h·ª£p l·ªá\"\n",
        "\n",
        "    model_data = torch.load(path, map_location=torch.device(\"cpu\"))\n",
        "\n",
        "    print(f\"C√°c m√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n c√°c ·ª©ng d·ª•ng kh√°c nhau c√≥ th·ªÉ ƒëem l·∫°i c√°c th√¥ng tin kh√°c nhau ho·∫∑c kh√¥ng th·ªÉ ƒë·ªçc!\")\n",
        "\n",
        "    epochs = model_data.get(\"epoch\", None)\n",
        "\n",
        "    if epochs is None:\n",
        "        epochs = model_data.get(\"info\", None)\n",
        "        epoch = epochs.replace(\"epoch\", \"\").replace(\"e\", \"\").isdigit()\n",
        "\n",
        "        if epoch and epochs is None: epochs = \"Kh√¥ng t√¨m th·∫•y k·ª∑ nguy√™n\"\n",
        "\n",
        "    steps = model_data.get(\"step\", \"Kh√¥ng t√¨m th·∫•y\")\n",
        "\n",
        "    sr = model_data.get(\"sr\", \"Kh√¥ng t√¨m th·∫•y t·ªëc ƒë·ªô l·∫•y m·∫´u\")\n",
        "    f0 = model_data.get(\"f0\", \"Kh√¥ng t√¨m th·∫•y hu·∫•n luy·ªán cao ƒë·ªô\")\n",
        "\n",
        "    version = model_data.get(\"version\", \"Kh√¥ng t√¨m th·∫•y phi√™n b·∫£n\")\n",
        "    creation_date = model_data.get(\"creation_date\", \"Kh√¥ng t√¨m th·∫•y th·ªùi gian t·∫°o\")\n",
        "    model_hash = model_data.get(\"model_hash\", \"Kh√¥ng t√¨m th·∫•y\")\n",
        "\n",
        "    pitch_guidance = \"ƒê∆∞·ª£c hu·∫•n luy·ªán cao ƒë·ªô\" if f0 else \"Kh√¥ng ƒë∆∞·ª£c hu·∫•n luy·ªán cao ƒë·ªô\"\n",
        "\n",
        "    creation_date_str = prettify_date(creation_date) if creation_date else \"Kh√¥ng t√¨m th·∫•y th·ªùi gian t·∫°o\"\n",
        "\n",
        "    model_name = model_data.get(\"model_name\", \"M√¥ h√¨nh kh√¥ng ƒë∆∞·ª£c ghi ch√©p\")\n",
        "    model_author = model_data.get(\"author\", \"M√¥ h√¨nh kh√¥ng ƒë∆∞·ª£c ghi ch√©p\")\n",
        "\n",
        "    print(\"Ho√†n th√†nh\")\n",
        "\n",
        "    return (\n",
        "        f\"T√™n m√¥ h√¨nh: {model_name}\\n\"\n",
        "        f\"Ng∆∞·ªùi t·∫°o m√¥ h√¨nh: {model_author}\\n\"\n",
        "        f\"K·ª∑ nguy√™n: {epochs}\\n\"\n",
        "        f\"S·ªë b∆∞·ªõc: {steps}\\n\"\n",
        "        f\"Phi√™n b·∫£n c·ªßa m√¥ h√¨nh: {version}\\n\"\n",
        "        f\"T·ªëc ƒë·ªô l·∫•y m·∫´u: {sr}\\n\"\n",
        "        f\"Hu·∫•n luy·ªán cao ƒë·ªô: {pitch_guidance}\\n\"\n",
        "        f\"Hash (ID): {model_hash}\\n\"\n",
        "        f\"Th·ªùi gian t·∫°o: {creation_date_str}\\n\"\n",
        "    )\n",
        "\n",
        "if not duong_dan_mo_hinh:\n",
        "  %cd /content/Vietnamese_RVC/assets/weights\n",
        "  file_name = next(iter(files.upload())); rename_file = file_name.replace(' ', '_').replace('(', '').replace(')', '').replace('{', '').replace('}', '')\n",
        "  os.rename(file_name, rename_file)\n",
        "  duong_dan_mo_hinh = os.path.join(\"assets\", \"weights\", rename_file)\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "print(model_info(duong_dan_mo_hinh))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP4ifZaG_yd5"
      },
      "source": [
        "# **T√°ch nh·∫°c üéº**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWl2RiXuA4mP",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **T·∫£i xu·ªëng √¢m thanh ‚ñ∂Ô∏è**\n",
        "import os\n",
        "import yt_dlp\n",
        "import warnings\n",
        "\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "\n",
        "#@markdown **T·∫£i xu·ªëng √¢m thanh t·ª´ youtube v·ªÅ ƒë·ªÉ s·ª≠ d·ª•ng t√°ch nh·∫°c**\n",
        "lien_ket_am_thanh = \"\" # @param {\"type\":\"string\",\"placeholder\":\"https://www.youtube.com/...\"}\n",
        "\n",
        "\n",
        "def download_url(url):\n",
        "    if not url: return gr.Warning(\"Vui l√≤ng nh·∫≠p ƒë∆∞·ªùng d·∫´n li√™n k·∫øt\")\n",
        "    if not os.path.exists(\"audios\"): os.makedirs(\"audios\", exist_ok=True)\n",
        "\n",
        "    if os.path.exists(os.path.join(\"audios\", \"audio.wav\")): os.remove(os.path.join(\"audios\", \"audio.wav\"))\n",
        "\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "\n",
        "        ydl_opts = {\n",
        "            'format': 'bestaudio/best',\n",
        "            'outtmpl': os.path.join(\"audios\", \"audio\"),\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'wav',\n",
        "                'preferredquality': '192',\n",
        "            }],\n",
        "            'noplaylist': True,\n",
        "            'verbose': False,\n",
        "        }\n",
        "\n",
        "        print(\"B·∫Øt ƒë·∫ßu t·∫£i nh·∫°c...\")\n",
        "\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([url])\n",
        "\n",
        "\n",
        "download_url(lien_ket_am_thanh)\n",
        "\n",
        "clear_output()\n",
        "display(Button(description=\"\\u2714 T·∫£i xu·ªëng xong!\", button_style=\"success\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cxOZgB1_7bg",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **T√°ch nh·∫°c Demucs üé∂**\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from ipywidgets import Button\n",
        "from pydub import AudioSegment\n",
        "from google.colab import files\n",
        "from IPython.display import display, clear_output, Audio\n",
        "\n",
        "#@markdown **T√°ch gi·ªçng b√®**\n",
        "tach_be = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **T√°ch √¢m vang c·ªßa c√°c gi·ªçng**\n",
        "tach_vang = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **Hi·ªÉn th·ªã c√°c th√¥ng tin chi ti·∫øt**\n",
        "hien_thong_tin = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown ___\n",
        "#@markdown **C√°c m√¥ h√¨nh t√°ch nh·∫°c M√¥ h√¨nh b√¨nh th∆∞·ªùng, M√¥ h√¨nh ƒë∆∞·ª£c t√πy ch·ªânh v√† 'M√¥ h√¨nh cao nh·∫•t**\n",
        "mo_hinh_tach = \"HT-Tuned\" # @param [\"HT-Normal\", \"HT-Tuned\", \"HD_MMI\", \"HT_6S\"]\n",
        "#@markdown **M·ª©c ƒë·ªô ch·ªìng ch√©o gi·ªØa c√°c ph·∫ßn √¢m thanh, k√≠ch th∆∞·ªõc c√°c ph√¢n ƒëo·∫°n v√† s·ªë l∆∞·ª£ng d·ª± ƒëo√°n**\n",
        "chong_cheo = \"0.25\" # @param [\"0.25\", \"0.5\", \"0.75\", \"0.99\"]\n",
        "kich_thuoc_phan_doan = 256 # @param {\"type\":\"slider\",\"min\":32,\"max\":2048,\"step\":8}\n",
        "so_luong_du_doan = 2 # @param {\"type\":\"slider\",\"min\":1,\"max\":20,\"step\":1}\n",
        "#@markdown ___\n",
        "#@markdown **ƒê·ªãnh d·∫°ng √¢m thanh v√† l·ªçc t·∫°p √¢m**\n",
        "loc_tap_am = False # @param {\"type\":\"boolean\"}\n",
        "dinh_dang = \"wav\" # @param [\"wav\", \"mp3\", \"flac\"]\n",
        "#@markdown Hi·ªÉn th·ªã t·ªáp √¢m thanh nghe th·ª≠(C√≥ th·ªÉ g√¢y s·∫≠p colab)\n",
        "hien_thi_tep = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "\n",
        "def separator_music_demucs(input, output, format, shifts, segments_size, overlap, clean_audio, clean_strength, backing_denoise, separator_model, kara_model, backing, reverb, reverb_denoise, backing_reverb, info):\n",
        "  if not os.path.exists(input): raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y ƒë·∫ßu v√†o\")\n",
        "  if not os.path.exists(output): raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y ƒë·∫ßu ra\")\n",
        "\n",
        "  print(\"B·∫Øt ƒë·∫ßu t√°ch nh·∫°c...\")\n",
        "\n",
        "  cmd = f'{sys.executable} main/inference/separator_music.py --input_path {input} --output_path {output} --format {format} --demucs_model {separator_model} --shifts {shifts} --segments_size {segments_size} --overlap {overlap} --clean_audio {clean_audio} --clean_strength {clean_strength} --backing_denoise {backing_denoise} --kara_model {kara_model} --backing {backing} --reverb {reverb} --reverb_denoise {reverb_denoise} --backing_reverb {backing_reverb}'\n",
        "\n",
        "  if not info: os.system(cmd)\n",
        "  else:\n",
        "    !$cmd\n",
        "\n",
        "if os.path.exists(os.path.join(\"audios\", \"audio.wav\")): input_path = os.path.join(\"audios\", \"audio.wav\")\n",
        "else:\n",
        "  %cd /content/Vietnamese_RVC/audios\n",
        "  file_name = next(iter(files.upload())); rename_file = file_name.replace(' ', '_').replace('(', '').replace(')', '').replace('{', '').replace('}', '')\n",
        "  os.rename(file_name, rename_file)\n",
        "  input_path = os.path.join(\"audios\", rename_file)\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "separator_music_demucs(input_path, os.path.join(\"audios\"), dinh_dang, so_luong_du_doan, kich_thuoc_phan_doan, chong_cheo, loc_tap_am, 0.5, True, mo_hinh_tach, \"Version-2\", tach_be, tach_vang, True, tach_be, hien_thong_tin)\n",
        "\n",
        "if not hien_thong_tin: clear_output()\n",
        "\n",
        "display(Button(description=\"\\u2714 T√°ch nh·∫°c xong\", button_style=\"success\"))\n",
        "\n",
        "original_output = os.path.join(\"audios\", f\"Original_Vocals_No_Reverb.{dinh_dang}\") if tach_vang else os.path.join(\"audios\", f\"Original_Vocals.{dinh_dang}\")\n",
        "\n",
        "if os.path.exists(original_output) and hien_thi_tep: display(Audio(data=original_output, rate=AudioSegment.from_file(original_output).frame_rate, autoplay=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c_uIsvCAF7Q",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **T√°ch nh·∫°c MDX üé∂**\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from ipywidgets import Button\n",
        "from pydub import AudioSegment\n",
        "from google.colab import files\n",
        "from IPython.display import display, clear_output, Audio\n",
        "\n",
        "\n",
        "#@markdown **T√°ch gi·ªçng b√®**\n",
        "tach_be = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **T√°ch √¢m vang c·ªßa c√°c gi·ªçng**\n",
        "tach_vang = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **Hi·ªÉn th·ªã c√°c th√¥ng tin chi ti·∫øt**\n",
        "hien_thong_tin = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown ___\n",
        "#@markdown **C√°c m√¥ h√¨nh t√°ch nh·∫°c c√≥ nhi·ªÅu t√πy bi·∫øn kh√°c nhau**\n",
        "mo_hinh_tach = \"Main_340\" # @param [\"Main_340\", \"Main_390\", \"Main_406\", \"Main_427\", \"Main_438\", \"Inst_full_292\", \"Inst_HQ_1\", \"Inst_HQ_2\", \"Inst_HQ_3\", \"Inst_HQ_4\", \"Kim_Vocal_1\", \"Kim_Vocal_2\", \"Kim_Inst\", \"Inst_187_beta\", \"Inst_82_beta\", \"Inst_90_beta\", \"Voc_FT\", \"Crowd_HQ\", \"Inst_1\", \"Inst_2\", \"Inst_3\", \"MDXNET_1_9703\", \"MDXNET_2_9682\", \"MDXNET_3_9662\", \"Inst_Main\", \"MDXNET_Main\", \"MDXNET_9482\"]\n",
        "#@markdown **M·ª©c ƒë·ªô ch·ªìng ch√©o gi·ªØa c√°c ph·∫ßn √¢m thanh, k√≠ch th∆∞·ªõc c√°c ph√¢n ƒëo·∫°n**\n",
        "chong_cheo = \"0.25\" # @param [\"0.25\", \"0.5\", \"0.75\", \"0.99\"]\n",
        "kich_thuoc_phan_doan = 256 # @param {\"type\":\"slider\",\"min\":32,\"max\":2048,\"step\":8}\n",
        "#@markdown ___\n",
        "#@markdown **ƒê·ªãnh d·∫°ng √¢m thanh v√† l·ªçc t·∫°p √¢m**\n",
        "loc_tap_am = False # @param {\"type\":\"boolean\"}\n",
        "dinh_dang = \"wav\" # @param [\"wav\", \"mp3\", \"flac\"]\n",
        "#@markdown Hi·ªÉn th·ªã t·ªáp √¢m thanh nghe th·ª≠(C√≥ th·ªÉ g√¢y s·∫≠p colab)\n",
        "hien_thi_tep = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "\n",
        "def separator_music_mdx(input, output, format, segments_size, overlap, clean_audio, clean_strength, backing_denoise, separator_model, kara_model, backing, reverb, reverb_denoise, backing_reverb, mdx, mdx_denoise, info, hop_length, batch_size):\n",
        "  if not os.path.exists(input): raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y ƒë·∫ßu v√†o\")\n",
        "  if not os.path.exists(output): raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y ƒë·∫ßu ra\")\n",
        "\n",
        "  print(\"B·∫Øt ƒë·∫ßu t√°ch nh·∫°c...\")\n",
        "\n",
        "  cmd = f'{sys.executable} main/inference/separator_music.py --input_path {input} --output_path {output} --format {format} --mdx_model {separator_model} --segments_size {segments_size} --overlap {overlap} --mdx_hop_length {hop_length} --mdx_batch_size {batch_size} --clean_audio {clean_audio} --clean_strength {clean_strength} --backing_denoise {backing_denoise} --kara_model {kara_model} --backing {backing} --reverb {reverb} --reverb_denoise {reverb_denoise} --backing_reverb {backing_reverb} --mdx {mdx} --mdx_denoise {mdx_denoise}'\n",
        "\n",
        "  if not info: os.system(cmd)\n",
        "  else:\n",
        "    !$cmd\n",
        "\n",
        "\n",
        "if os.path.exists(os.path.join(\"audios\", \"audio.wav\")): input_path = os.path.join(\"audios\", \"audio.wav\")\n",
        "else:\n",
        "  %cd /content/Vietnamese_RVC/audios\n",
        "  file_name = next(iter(files.upload())); rename_file = file_name.replace(' ', '_').replace('(', '').replace(')', '').replace('{', '').replace('}', '')\n",
        "  os.rename(file_name, rename_file)\n",
        "  input_path = os.path.join(\"audios\", rename_file)\n",
        "\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "separator_music_mdx(input_path, os.path.join(\"audios\"), dinh_dang, kich_thuoc_phan_doan, chong_cheo, loc_tap_am, 0.5, True, mo_hinh_tach, \"Version-2\", tach_be, tach_vang, True, tach_be, True, True, hien_thong_tin, 1024, 1)\n",
        "\n",
        "if not hien_thong_tin: clear_output()\n",
        "display(Button(description=\"\\u2714 T√°ch nh·∫°c xong\", button_style=\"success\"))\n",
        "\n",
        "original_output = os.path.join(\"audios\", f\"Original_Vocals_No_Reverb.{dinh_dang}\") if tach_vang else os.path.join(\"audios\", f\"Original_Vocals.{dinh_dang}\")\n",
        "\n",
        "if os.path.exists(original_output) and hien_thi_tep: display(Audio(data=original_output, rate=AudioSegment.from_file(original_output).frame_rate, autoplay=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekfkFFNqppfM"
      },
      "source": [
        "# **Chuy·ªÉn ƒë·ªïi √¢m thanh üîä**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZTs633CT14k4"
      },
      "outputs": [],
      "source": [
        "#@title **üîé T√¨m ki·∫øm m√¥ h√¨nh**\n",
        "import codecs\n",
        "import requests\n",
        "\n",
        "from ipywidgets import Button\n",
        "from IPython.display import display\n",
        "\n",
        "#@markdown **T√¨m ki·∫øm li√™n k·∫øt m√¥ h√¨nh**\n",
        "ten_mo_hinh = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Model-Name\"}\n",
        "\n",
        "\n",
        "def search_models(name):\n",
        "    if not name: raise ValueError(\"Vui l√≤ng cung c·∫•p t√™n!\")\n",
        "\n",
        "    url = f\"https://cjtfqzjfdimgpvpwhzlv.supabase.co/rest/v1/models?name=ilike.%25{name}%25&order=created_at.desc&limit=15\"\n",
        "\n",
        "    response = requests.get(url, headers={\"apikey\": codecs.decode(\"rlWuoTpvBvWVHmV1AvVfVaE5pPV6VxcKIPW9.rlWcp3ZvBvWmqKOuLzSmMFVfVaWyMvV6VzAdqTMkrzczMTygM3O2pUqbrzk2Vvjvpz9fMFV6VzSho24vYPWcLKDvBwR3ZwL5ZwLkZmDfVzI4pPV6ZwN0ZwHjZwRmAU0.BlQKyuiU6Q-VfUvJuCNTHgfCTTHiJDlaskHrDjsLGbR\", \"rot13\")})\n",
        "    data = response.json()\n",
        "\n",
        "    if len(data) == 0: return print(f\"Kh√¥ng t√¨m th·∫•y {name}\")\n",
        "    else:\n",
        "      for item in data:\n",
        "        name_or_epoch = item[\"name\"] + \"-\" + item[\"epochs\"] + \"e\"\n",
        "        url = item[\"link\"]\n",
        "        output = f\"{name_or_epoch}: {url}\"\n",
        "        print(output)\n",
        "\n",
        "\n",
        "search_models(ten_mo_hinh)\n",
        "display(Button(description=\"\\u2714 T√¨m ki·∫øm xong!\", button_style=\"success\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "53L1lidMqFfA"
      },
      "outputs": [],
      "source": [
        "#@title **üì© T·∫£i xu·ªëng m√¥ h√¨nh**\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from subprocess import run\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "#@markdown **H·ªó tr·ª£ c√°c li√™n k·∫øt ƒë·∫øn t·ª´ huggingface.co / drive.google.com / mega.nz / mediafire.com**\n",
        "\n",
        "ten_cua_mo_hinh = \"\" # @param {\"type\":\"string\",\"placeholder\":\"My-Model\"}\n",
        "lien_ket_mo_hinh = \"\" # @param {\"type\":\"string\",\"placeholder\":\"https://huggingface.co//...\"}\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "from main.tools import gdown, meganz, mediafire\n",
        "\n",
        "def move_files_from_directory(src_dir, dest_weights, dest_logs, model_name):\n",
        "    for root, _, files in os.walk(src_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "\n",
        "            if file.endswith(\".index\"):\n",
        "                model_log_dir = os.path.join(dest_logs, model_name)\n",
        "                os.makedirs(model_log_dir, exist_ok=True)\n",
        "\n",
        "                filepath = os.path.join(model_log_dir, file.replace(' ', '_').replace('(', '').replace(')', '').replace('[', '').replace(']', '').strip())\n",
        "                if os.path.exists(filepath): os.remove(filepath)\n",
        "\n",
        "                shutil.move(file_path, filepath)\n",
        "            elif file.endswith(\".pth\") and \"G_\" not in file and \"D_\" not in file:\n",
        "                pth_path = os.path.join(dest_weights, model_name + \".pth\")\n",
        "                if os.path.exists(pth_path): os.remove(pth_path)\n",
        "\n",
        "                shutil.move(file_path, pth_path)\n",
        "\n",
        "def download_model(url=None, model=None):\n",
        "    if not url: raise ValueError(\"Vui l√≤ng cung c·∫•p ƒë∆∞·ªùng d·∫´n li√™n k·∫øt m√¥ h√¨nh\")\n",
        "    if not model: raise ValueError(\"Vui l√≤ng nh·∫≠p t√™n m√¥ h√¨nh ƒë·ªÉ l∆∞u\")\n",
        "\n",
        "    model = model.replace('.pth', '').replace('.index', '').replace('.zip', '').replace(' ', '_').replace('(', '').replace(')', '').replace('[', '').replace(']', '').strip()\n",
        "    url = url.replace('/blob/', '/resolve/').replace('?download=true', '').strip()\n",
        "\n",
        "    download_dir = os.path.join(\"download_model\")\n",
        "    weights_dir = os.path.join(\"assets\", \"weights\")\n",
        "    logs_dir = os.path.join(\"assets\", \"logs\")\n",
        "\n",
        "    if not os.path.exists(download_dir): os.makedirs(download_dir, exist_ok=True)\n",
        "    if not os.path.exists(weights_dir): os.makedirs(weights_dir, exist_ok=True)\n",
        "    if not os.path.exists(logs_dir): os.makedirs(logs_dir, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        print(\"B·∫Øt ƒë·∫ßu t·∫£i xu·ªëng...\")\n",
        "\n",
        "        if url.endswith('.pth'):\n",
        "            run([\"wget\", \"-q\", \"--show-progress\", \"--no-check-certificate\", url, \"-O\", os.path.join(weights_dir, f\"{model}.pth\")], check=True)\n",
        "        elif url.endswith('.index'):\n",
        "            model_log_dir = os.path.join(logs_dir, model)\n",
        "            os.makedirs(model_log_dir, exist_ok=True)\n",
        "            run([\"wget\", \"-q\", \"--show-progress\", \"--no-check-certificate\", url, \"-O\", os.path.join(model_log_dir, f\"{model}.index\")], check=True)\n",
        "        elif url.endswith('.zip'):\n",
        "            dest_path = os.path.join(download_dir, model + \".zip\")\n",
        "            run([\"wget\", \"-q\", \"--show-progress\", \"--no-check-certificate\", url, \"-O\", dest_path], check=True)\n",
        "            shutil.unpack_archive(dest_path, download_dir)\n",
        "\n",
        "            move_files_from_directory(download_dir, weights_dir, logs_dir, model)\n",
        "        else:\n",
        "            if 'drive.google.com' in url:\n",
        "                file_id = None\n",
        "\n",
        "                if '/file/d/' in url: file_id = url.split('/d/')[1].split('/')[0]\n",
        "                elif 'open?id=' in url: file_id = url.split('open?id=')[1].split('/')[0]\n",
        "\n",
        "                if file_id:\n",
        "                    file = gdown.gdown_download(id=file_id, output_dir=download_dir)\n",
        "                    if file.endswith('.zip'): shutil.unpack_archive(os.path.join(download_dir, file), download_dir)\n",
        "\n",
        "                    move_files_from_directory(download_dir, weights_dir, logs_dir, model)\n",
        "            elif 'mega.nz' in url:\n",
        "                meganz.mega_download_url(url, download_dir)\n",
        "\n",
        "                file_download = next((f for f in os.listdir(download_dir)), None)\n",
        "                if file_download.endswith(\".zip\"): shutil.unpack_archive(os.path.join(download_dir, file_download), download_dir)\n",
        "\n",
        "                move_files_from_directory(download_dir, weights_dir, logs_dir, model)\n",
        "            elif 'mediafire.com' in url:\n",
        "                file = mediafire.Mediafire_Download(url, download_dir)\n",
        "                if file.endswith('.zip'): shutil.unpack_archive(file, download_dir)\n",
        "\n",
        "                move_files_from_directory(download_dir, weights_dir, logs_dir, model)\n",
        "            else: print(\"Li√™n k·∫øt m√¥ h√¨nh c·ªßa b·∫°n kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£\")\n",
        "\n",
        "        print(\"Ho√†n th√†nh\")\n",
        "    except Exception as e:\n",
        "        print(f\"ƒê√£ x·∫£y ra l·ªói: {e}\")\n",
        "    finally:\n",
        "        shutil.rmtree(download_dir, ignore_errors=True)\n",
        "\n",
        "download_model(lien_ket_mo_hinh, ten_cua_mo_hinh)\n",
        "\n",
        "clear_output()\n",
        "display(Button(description=\"\\u2714 T·∫£i xu·ªëng xong!\", button_style=\"success\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Cb-8NmDBJsX",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Chuy·ªÉn ƒë·ªïi √¢m thanh üéµ**\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from ipywidgets import Button\n",
        "from pydub import AudioSegment\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output, display, Audio\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "#@markdown **C√°c t√πy ch·ªçn chuy·ªÉn ƒë·ªïi nh∆∞: S·ª≠ d·ª•ng ph·∫ßn √¢m thanh ƒë√£ t√°ch tr∆∞·ªõc ƒë√≥, chuy·ªÉn ƒë·ªïi gi·ªçng g·ªëc, chuy·ªÉn ƒë·ªïi gi·ªçng b√® v√† kh√¥ng k·∫øt h·ª£p b√®, k·∫øt h·ª£p nh·∫°c n·ªÅn**\n",
        "su_dung_am_thanh_vua_tach = False # @param {\"type\":\"boolean\"}\n",
        "su_dung_giong_goc = False # @param {\"type\":\"boolean\"}\n",
        "chuyen_doi_giong_be = False # @param {\"type\":\"boolean\"}\n",
        "khong_ket_hop_be = False # @param {\"type\":\"boolean\"}\n",
        "ket_hop_nhac = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown ___\n",
        "#@markdown **T√™n c·ªßa m√¥ h√¨nh ƒë·ªÉ t√¨m ki·∫øm t·ªáp m√¥ h√¨nh v√† ch·ªâ m·ª•c c·ªßa n√≥**\n",
        "ten_mo_hinh = \"\" # @param {\"type\":\"string\",\"placeholder\":\"My-Model\"}\n",
        "#@markdown **Cao ƒë·ªô c·ªßa gi·ªçng n√≥i -12 s·∫Ω tr·∫ßm v√† 12 s·∫Ω cao, ƒë∆∞·ª£c khuy·∫øn c√°o l√† tƒÉng l√™n 12 ƒë·ªÉ chuy·ªÉn ƒë·ªïi gi·ªçng nam sang n·ªØ v√† ng∆∞·ª£c l·∫°i**\n",
        "cao_do = 0 # @param {\"type\":\"slider\",\"min\":-20,\"max\":20,\"step\":1}\n",
        "#@markdown **B·∫£o v·ªá ph·ª• √¢m nh·∫ßm tr√°nh vi·ªác r√°ch ƒëi·ªán t·ª≠ khi chuy·ªÉn ƒë·ªïi √¢m thanh**\n",
        "bao_ve_phu_am = 0.5 # @param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.1}\n",
        "#@markdown ___\n",
        "#@markdown **Ph∆∞∆°ng ph√°p tr√≠ch xu·∫•t √¢m thanh, Khuy·∫øn c√°o: Harvest ho·∫∑c Rmvpe**\n",
        "phuong_phap = \"rmvpe\" #@param [\"pm\", \"dio\", \"crepe-tiny\", \"crepe\", \"fcpe\", \"rmvpe\", \"harvest\", \"hybrid[pm+dio]\", \"hybrid[pm+crepe-tiny]\", \"hybrid[pm+crepe]\", \"hybrid[pm+fcpe]\", \"hybrid[pm+rmvpe]\", \"hybrid[pm+harvest]\", \"hybrid[dio+crepe-tiny]\", \"hybrid[dio+crepe]\", \"hybrid[dio+fcpe]\", \"hybrid[dio+rmvpe]\", \"hybrid[dio+harvest]\", \"hybrid[crepe-tiny+crepe]\", \"hybrid[crepe-tiny+fcpe]\", \"hybrid[crepe-tiny+rmvpe]\", \"hybrid[crepe-tiny+harvest]\", \"hybrid[crepe+fcpe]\", \"hybrid[crepe+rmvpe]\", \"hybrid[crepe+harvest]\", \"hybrid[fcpe+rmvpe]\", \"hybrid[fcpe+harvest]\", \"hybrid[rmvpe+harvest]\"]\n",
        "#@markdown **hop length bi·ªÉu th·ªã kho·∫£ng th·ªùi gian c·∫ßn ƒë·ªÉ chuy·ªÉn sang thay ƒë·ªïi cao ƒë·ªô. Hop length nh·ªè c·∫ßn nhi·ªÅu th·ªùi gian h∆°n ƒë·ªÉ chuy·ªÉn ƒë·ªïi nh∆∞ng ch√≠nh x√°c h∆°n**\n",
        "hop_length = 64 # @param {\"type\":\"slider\",\"min\":64,\"max\":512,\"step\":1}\n",
        "#@markdown **S·ª©c ·∫£nh h∆∞·ªüng c·ªßa chƒ© m·ª•c khi chuy·ªÉn ƒë·ªïi c√†ng cao ·∫£nh h∆∞·ªüng c√†ng l·ªõn. Tuy nhi√™n, vi·ªác ch·ªçn gi√° tr·ªã th·∫•p h∆°n c√≥ th·ªÉ gi·∫£m hi·ªán t∆∞·ª£ng gi·∫£ trong √¢m thanh**\n",
        "anh_huong_chi_muc = 0.5 # @param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.01}\n",
        "#@markdown ___\n",
        "#@markdown **TƒÉng ch·∫•t l∆∞·ª£ng c·ªßa √¢m thanh nh∆∞ng t·ªën nhi·ªÅu t√†i nguy√™n**\n",
        "tang_chat_luong = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh tr√≠ch xu·∫•t c√≥ th·ªÉ ƒë∆∞a ra k·∫øt qu·∫£ t·ªët h∆°n**\n",
        "tu_dong_dieu_chinh = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **L·ªçc t·∫°p √¢m c·ªßa √¢m thanh khi convert**\n",
        "loc_tap_am = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt khi chuy·ªÉn ƒë·ªïi**\n",
        "hien_thong_tin = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **C·∫Øt nh·ªè √¢m thanh c√≥ th·ªÉ gi√∫p vi·ªác chuy·ªÉn ƒë·ªïi nhanh h∆°n m·ªôt t√≠**\n",
        "cat_am_thanh = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **ƒê·ªãnh d·∫°ng ƒë·∫ßu ra √¢m thanh**\n",
        "dinh_dang = \"wav\" # @param [\"wav\", \"mp3\", \"flac\", \"ogg\", \"m4a\"]\n",
        "#@markdown Hi·ªÉn th·ªã t·ªáp √¢m thanh nghe th·ª≠(C√≥ th·ªÉ g√¢y s·∫≠p colab)\n",
        "hien_thi_tep = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "def convert_a(pitch, filter_radius, index_rate, volume_envelope, protect, hop_length, f0_method, input_path, output_path, pth_path, index_path, f0_autotune, clean_audio, clean_strength, export_format, embedder_model, upscale_audio, resample_sr, info, split_audio, f0_autotune_strength):\n",
        "    if os.path.exists(output_path): os.remove(output_path)\n",
        "\n",
        "    cmd = f\"{sys.executable} main/inference/convert.py --pitch {pitch} --filter_radius {filter_radius} --index_rate {index_rate} --volume_envelope {volume_envelope} --protect {protect} --hop_length {hop_length} --f0_method {f0_method} --input_path {input_path} --output_path {output_path} --pth_path {pth_path} --index_path {index_path} --f0_autotune {f0_autotune} --clean_audio {clean_audio} --clean_strength {clean_strength} --export_format {export_format} --embedder_model {embedder_model} --upscale_audio {upscale_audio} --resample_sr {resample_sr} --split_audio {split_audio} --f0_autotune_strength {f0_autotune_strength}\"\n",
        "    if not info: os.system(cmd)\n",
        "    else:\n",
        "        !$cmd\n",
        "\n",
        "def convert_audio(clean, upscale, autotune, use_audio, use_original, convert_backing, not_merge_backing, merge_instrument, pitch, clean_strength, name, index_rate, input, format, f0method, hop_length, embedder_model, resample_sr, filter_radius, volume_envelope, protect, info, split_audio, f0_autotune_strength):\n",
        "    def get_audio_file(label):\n",
        "        matching_files = [f for f in os.listdir(\"audios\") if label in f]\n",
        "\n",
        "        if not matching_files: return \"Kh√¥ng t√¨m th·∫•y\"\n",
        "\n",
        "        return os.path.join(\"audios\", matching_files[0])\n",
        "\n",
        "    if name == \"\": raise ValueError(\"Vui l√≤ng nh·∫≠p t√™n m√¥ h√¨nh\")\n",
        "    model_path = os.path.join(\"assets\", \"weights\", f\"{name}.pth\")\n",
        "\n",
        "    try:\n",
        "      index_path = os.path.join(\"assets\", \"logs\", name,  [f for f in os.listdir(os.path.join(\"assets\", \"logs\", name)) if f.endswith('.index')][0])\n",
        "    except IndexError:\n",
        "      raise ValueError(\"L·ªói khi t√¨m ch·ªâ m·ª•c\")\n",
        "\n",
        "    if not os.path.exists(model_path): raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh\")\n",
        "    if not os.path.exists(index_path): raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y ch·ªâ m·ª•c\")\n",
        "\n",
        "    output_path = os.path.join(\"audios\", f\"Convert_Vocals.{format}\")\n",
        "    output_backing = os.path.join(\"audios\", f\"Convert_Backing.{format}\")\n",
        "    output_merge_backup = os.path.join(\"audios\", f\"Vocals+Backing.{format}\")\n",
        "    output_merge_instrument = os.path.join(\"audios\", f\"Vocals+Instruments.{format}\")\n",
        "\n",
        "    if use_audio:\n",
        "        if os.path.exists(output_path): os.remove(output_path)\n",
        "\n",
        "        if use_original:\n",
        "            original_vocal = get_audio_file('Original_Vocals_No_Reverb.')\n",
        "\n",
        "            if original_vocal == \"Kh√¥ng t√¨m th·∫•y\": original_vocal = get_audio_file('Original_Vocals.')\n",
        "            if original_vocal == \"Kh√¥ng t√¨m th·∫•y\": raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y gi·ªçng g·ªëc!\")\n",
        "\n",
        "            input_path = original_vocal\n",
        "        else:\n",
        "            main_vocal = get_audio_file('Main_Vocals_No_Reverb.')\n",
        "            backing_vocal = get_audio_file('Backing_Vocals_No_Reverb.')\n",
        "\n",
        "            if main_vocal == \"Kh√¥ng t√¨m th·∫•y\": main_vocal = get_audio_file('Main_Vocals.')\n",
        "            if not not_merge_backing and backing_vocal == \"Kh√¥ng t√¨m th·∫•y\": backing_vocal = get_audio_file('Backing_Vocals.')\n",
        "\n",
        "            if main_vocal == \"Kh√¥ng t√¨m th·∫•y\": raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y gi·ªçng ch√≠nh!\")\n",
        "            if not not_merge_backing and backing_vocal == \"Kh√¥ng t√¨m th·∫•y\": raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y gi·ªçng b√®!\")\n",
        "\n",
        "            input_path = main_vocal\n",
        "            backing_path = backing_vocal\n",
        "\n",
        "        print(\"ƒêang chuy·ªÉn ƒë·ªïi gi·ªçng n√≥i...\")\n",
        "        if not info: clear_output()\n",
        "\n",
        "        convert_a(pitch, filter_radius, index_rate, volume_envelope, protect, hop_length, f0method, input_path, output_path, model_path, index_path, autotune, clean, clean_strength, format, embedder_model, upscale, resample_sr, info, split_audio, f0_autotune_strength)\n",
        "\n",
        "        print(\"ƒê√£ Ho√†n th√†nh chuy·ªÉn ƒë·ªïi gi·ªçng n√≥i!\")\n",
        "\n",
        "        if convert_backing:\n",
        "            if os.path.exists(output_backing): os.remove(output_backing)\n",
        "\n",
        "            print(\"ƒêang chuy·ªÉn ƒë·ªïi gi·ªçng b√®...\")\n",
        "            if not info: clear_output()\n",
        "\n",
        "            convert_a(pitch, filter_radius, index_rate, volume_envelope, protect, hop_length, f0method, backing_path, output_backing, model_path, index_path, autotune, clean, clean_strength, format, embedder_model, upscale, resample_sr, info, split_audio, f0_autotune_strength)\n",
        "            print(\"ƒê√£ Ho√†n th√†nh chuy·ªÉn ƒë·ªïi gi·ªçng b√®!\")\n",
        "\n",
        "        if not not_merge_backing and not use_original:\n",
        "            backing_source = output_backing if convert_backing else backing_vocal\n",
        "\n",
        "            if os.path.exists(output_merge_backup): os.remove(output_merge_backup)\n",
        "\n",
        "            print(\"K·∫øt h·ª£p gi·ªçng v·ªõi gi·ªçng b√®...\")\n",
        "            if not info: clear_output()\n",
        "\n",
        "            AudioSegment.from_file(output_path).overlay(AudioSegment.from_file(backing_source)).export(output_merge_backup, format=format)\n",
        "\n",
        "            print(\"K·∫øt h·ª£p Ho√†n th√†nh\")\n",
        "\n",
        "        if merge_instrument:\n",
        "            if os.path.exists(output_merge_instrument): os.remove(output_merge_instrument)\n",
        "\n",
        "            print(\"K·∫øt h·ª£p gi·ªçng v·ªõi nh·∫°c n·ªÅn...\")\n",
        "            if not info: clear_output()\n",
        "\n",
        "            vocals = output_merge_backup if not not_merge_backing and not use_original else output_path\n",
        "\n",
        "            instruments = get_audio_file('Instruments.')\n",
        "\n",
        "            if instruments == \"Kh√¥ng t√¨m th·∫•y\":\n",
        "               print(\"Kh√¥ng t√¨m th·∫•y nh·∫°c n·ªÅn\")\n",
        "               output_merge_instrument = None\n",
        "            else: AudioSegment.from_file(instruments).overlay(AudioSegment.from_file(vocals)).export(output_merge_instrument, format=format)\n",
        "\n",
        "            print(\"K·∫øt h·ª£p Ho√†n th√†nh\")\n",
        "    else:\n",
        "        if not input or not os.path.exists(input): raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y ƒë·∫ßu v√†o!\")\n",
        "\n",
        "        output = os.path.join(\"audios\", f\"output.{format}\")\n",
        "\n",
        "        if os.path.exists(output): os.remove(output)\n",
        "\n",
        "        print(\"ƒêang chuy·ªÉn ƒë·ªïi gi·ªçng n√≥i...\")\n",
        "        if not info: clear_output()\n",
        "\n",
        "        convert_a(pitch, filter_radius, index_rate, volume_envelope, protect, hop_length, f0method, input, output, model_path, index_path, autotune, clean, clean_strength, format, embedder_model, upscale, resample_sr, info, split_audio, f0_autotune_strength)\n",
        "        print(\"K·∫øt h·ª£p Ho√†n th√†nh\")\n",
        "\n",
        "if not su_dung_am_thanh_vua_tach:\n",
        "    if ket_hop_nhac or khong_ket_hop_be or chuyen_doi_giong_be or su_dung_giong_goc: raise ValueError(\"Vui l√≤ng b·∫≠t s·ª≠ d·ª•ng √¢m thanh v·ª´a t√°ch ƒë·ªÉ s·ª≠ d·ª•ng\")\n",
        "\n",
        "    if su_dung_giong_goc:\n",
        "        if chuyen_doi_giong_be: raise ValueError(\"T·∫Øt chuy·ªÉn ƒë·ªïi gi·ªçng b√® ƒë·ªÉ c√≥ th·ªÉ s·ª≠ d·ª•ng gi·ªçng g·ªëc\")\n",
        "        elif khong_ket_hop_be: raise ValueError(\"T·∫Øt kh√¥ng k·∫øt h·ª£p gi·ªçng b√® ƒë·ªÉ c√≥ th·ªÉ s·ª≠ d·ª•ng gi·ªçng g·ªëc\")\n",
        "\n",
        "if not su_dung_am_thanh_vua_tach:\n",
        "  %cd /content/Vietnamese_RVC/audios\n",
        "  file_name = next(iter(files.upload())); rename_file = file_name.replace(' ', '_').replace('(', '').replace(')', '').replace('{', '').replace('}', '')\n",
        "  os.rename(file_name, rename_file)\n",
        "  input_path = os.path.join(\"audios\", rename_file)\n",
        "else: input_path = None\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "convert_audio(loc_tap_am, tang_chat_luong, tu_dong_dieu_chinh, su_dung_am_thanh_vua_tach, su_dung_giong_goc, chuyen_doi_giong_be, khong_ket_hop_be, ket_hop_nhac, cao_do, 0.5, ten_mo_hinh.replace('.pth', '').replace('.index', '').replace('.zip', '').replace(' ', '_').replace('(', '').replace(')', '').replace('[', '').replace(']', '').strip(), anh_huong_chi_muc, input_path, dinh_dang, phuong_phap, hop_length, \"hubert_base\", 0, 3, 1, bao_ve_phu_am, hien_thong_tin, cat_am_thanh, 0.8)\n",
        "if not hien_thong_tin: clear_output()\n",
        "\n",
        "display(Button(description=\"\\u2714 Chuy·ªÉn ƒë·ªïi xong\", button_style=\"success\"))\n",
        "\n",
        "audio = (os.path.join(\"audios\", f\"Vocals+Instruments.{dinh_dang}\") if ket_hop_nhac else os.path.join(\"audios\", f\"Vocals+Backing.{dinh_dang}\")) if not khong_ket_hop_be else (os.path.join(\"audios\", f\"Convert_Vocals.{dinh_dang}\") if su_dung_am_thanh_vua_tach else os.path.join(\"audios\", f\"output.{dinh_dang}\"))\n",
        "\n",
        "if os.path.exists(audio) and hien_thi_tep: display(Audio(data=audio, rate=AudioSegment.from_file(audio).frame_rate, autoplay=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qUIMCO9_6PxJ"
      },
      "outputs": [],
      "source": [
        "#@title **Chuy·ªÉn vƒÉn b·∫£n th√†nh gi·ªçng n√≥i üéµ**\n",
        "import os\n",
        "import sys\n",
        "import edge_tts\n",
        "\n",
        "from ipywidgets import Button\n",
        "from pydub import AudioSegment\n",
        "from IPython.display import clear_output, display, Audio\n",
        "\n",
        "#@markdown **N·ªôi d·ª•ng ƒë·ªçc, gi·ªçng ƒë·ªçc v√† t·ªëc ƒë·ªô ƒë·ªçc c·ªßa chuy·ªÉn ƒë·ªïi**\n",
        "noi_dung = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Hello Word\"}\n",
        "giong = \"vi-VN-HoaiMyNeural\" # @param ['af-ZA-AdriNeural', 'af-ZA-WillemNeural', 'sq-AL-AnilaNeural', 'sq-AL-IlirNeural', 'am-ET-AmehaNeural', 'am-ET-MekdesNeural', 'ar-DZ-AminaNeural', 'ar-DZ-IsmaelNeural', 'ar-BH-AliNeural', 'ar-BH-LailaNeural', 'ar-EG-SalmaNeural', 'ar-EG-ShakirNeural', 'ar-IQ-BasselNeural', 'ar-IQ-RanaNeural', 'ar-JO-SanaNeural', 'ar-JO-TaimNeural', 'ar-KW-FahedNeural', 'ar-KW-NouraNeural', 'ar-LB-LaylaNeural', 'ar-LB-RamiNeural', 'ar-LY-ImanNeural', 'ar-LY-OmarNeural', 'ar-MA-JamalNeural', 'ar-MA-MounaNeural', 'ar-OM-AbdullahNeural', 'ar-OM-AyshaNeural', 'ar-QA-AmalNeural', 'ar-QA-MoazNeural', 'ar-SA-HamedNeural', 'ar-SA-ZariyahNeural', 'ar-SY-AmanyNeural', 'ar-SY-LaithNeural', 'ar-TN-HediNeural', 'ar-TN-ReemNeural', 'ar-AE-FatimaNeural', 'ar-AE-HamdanNeural', 'ar-YE-MaryamNeural', 'ar-YE-SalehNeural', 'az-AZ-BabekNeural', 'az-AZ-BanuNeural', 'bn-BD-NabanitaNeural', 'bn-BD-PradeepNeural', 'bn-IN-BashkarNeural', 'bn-IN-TanishaaNeural', 'bs-BA-GoranNeural', 'bs-BA-VesnaNeural', 'bg-BG-BorislavNeural', 'bg-BG-KalinaNeural', 'my-MM-NilarNeural', 'my-MM-ThihaNeural', 'ca-ES-EnricNeural', 'ca-ES-JoanaNeural', 'zh-HK-HiuGaaiNeural', 'zh-HK-HiuMaanNeural', 'zh-HK-WanLungNeural', 'zh-CN-XiaoxiaoNeural', 'zh-CN-XiaoyiNeural', 'zh-CN-YunjianNeural', 'zh-CN-YunxiNeural', 'zh-CN-YunxiaNeural', 'zh-CN-YunyangNeural', 'zh-CN-liaoning-XiaobeiNeural', 'zh-TW-HsiaoChenNeural', 'zh-TW-YunJheNeural', 'zh-TW-HsiaoYuNeural', 'zh-CN-shaanxi-XiaoniNeural', 'hr-HR-GabrijelaNeural', 'hr-HR-SreckoNeural', 'cs-CZ-AntoninNeural', 'cs-CZ-VlastaNeural', 'da-DK-ChristelNeural', 'da-DK-JeppeNeural', 'nl-BE-ArnaudNeural', 'nl-BE-DenaNeural', 'nl-NL-ColetteNeural', 'nl-NL-FennaNeural', 'nl-NL-MaartenNeural', 'en-AU-NatashaNeural', 'en-AU-WilliamNeural', 'en-CA-ClaraNeural', 'en-CA-LiamNeural', 'en-HK-SamNeural', 'en-HK-YanNeural', 'en-IN-NeerjaExpressiveNeural', 'en-IN-NeerjaNeural', 'en-IN-PrabhatNeural', 'en-IE-ConnorNeural', 'en-IE-EmilyNeural', 'en-KE-AsiliaNeural', 'en-KE-ChilembaNeural', 'en-NZ-MitchellNeural', 'en-NZ-MollyNeural', 'en-NG-AbeoNeural', 'en-NG-EzinneNeural', 'en-PH-JamesNeural', 'en-PH-RosaNeural', 'en-SG-LunaNeural', 'en-SG-WayneNeural', 'en-ZA-LeahNeural', 'en-ZA-LukeNeural', 'en-TZ-ElimuNeural', 'en-TZ-ImaniNeural', 'en-GB-LibbyNeural', 'en-GB-MaisieNeural', 'en-GB-RyanNeural', 'en-GB-SoniaNeural', 'en-GB-ThomasNeural', 'en-US-AvaMultilingualNeural', 'en-US-AndrewMultilingualNeural', 'en-US-EmmaMultilingualNeural', 'en-US-BrianMultilingualNeural', 'en-US-AvaNeural', 'en-US-AndrewNeural', 'en-US-EmmaNeural', 'en-US-BrianNeural', 'en-US-AnaNeural', 'en-US-AriaNeural', 'en-US-ChristopherNeural', 'en-US-EricNeural', 'en-US-GuyNeural', 'en-US-JennyNeural', 'en-US-MichelleNeural', 'en-US-RogerNeural', 'en-US-SteffanNeural', 'et-EE-AnuNeural', 'et-EE-KertNeural', 'fil-PH-AngeloNeural', 'fil-PH-BlessicaNeural', 'fi-FI-HarriNeural', 'fi-FI-NooraNeural', 'fr-BE-CharlineNeural', 'fr-BE-GerardNeural', 'fr-CA-ThierryNeural', 'fr-CA-AntoineNeural', 'fr-CA-JeanNeural', 'fr-CA-SylvieNeural', 'fr-FR-VivienneMultilingualNeural', 'fr-FR-RemyMultilingualNeural', 'fr-FR-DeniseNeural', 'fr-FR-EloiseNeural', 'fr-FR-HenriNeural', 'fr-CH-ArianeNeural', 'fr-CH-FabriceNeural', 'gl-ES-RoiNeural', 'gl-ES-SabelaNeural', 'ka-GE-EkaNeural', 'ka-GE-GiorgiNeural', 'de-AT-IngridNeural', 'de-AT-JonasNeural', 'de-DE-SeraphinaMultilingualNeural', 'de-DE-FlorianMultilingualNeural', 'de-DE-AmalaNeural', 'de-DE-ConradNeural', 'de-DE-KatjaNeural', 'de-DE-KillianNeural', 'de-CH-JanNeural', 'de-CH-LeniNeural', 'el-GR-AthinaNeural', 'el-GR-NestorasNeural', 'gu-IN-DhwaniNeural', 'gu-IN-NiranjanNeural', 'he-IL-AvriNeural', 'he-IL-HilaNeural', 'hi-IN-MadhurNeural', 'hi-IN-SwaraNeural', 'hu-HU-NoemiNeural', 'hu-HU-TamasNeural', 'is-IS-GudrunNeural', 'is-IS-GunnarNeural', 'id-ID-ArdiNeural', 'id-ID-GadisNeural', 'ga-IE-ColmNeural', 'ga-IE-OrlaNeural', 'it-IT-GiuseppeNeural', 'it-IT-DiegoNeural', 'it-IT-ElsaNeural', 'it-IT-IsabellaNeural', 'ja-JP-KeitaNeural', 'ja-JP-NanamiNeural', 'jv-ID-DimasNeural', 'jv-ID-SitiNeural', 'kn-IN-GaganNeural', 'kn-IN-SapnaNeural', 'kk-KZ-AigulNeural', 'kk-KZ-DauletNeural', 'km-KH-PisethNeural', 'km-KH-SreymomNeural', 'ko-KR-HyunsuNeural', 'ko-KR-InJoonNeural', 'ko-KR-SunHiNeural', 'lo-LA-ChanthavongNeural', 'lo-LA-KeomanyNeural', 'lv-LV-EveritaNeural', 'lv-LV-NilsNeural', 'lt-LT-LeonasNeural', 'lt-LT-OnaNeural', 'mk-MK-AleksandarNeural', 'mk-MK-MarijaNeural', 'ms-MY-OsmanNeural', 'ms-MY-YasminNeural', 'ml-IN-MidhunNeural', 'ml-IN-SobhanaNeural', 'mt-MT-GraceNeural', 'mt-MT-JosephNeural', 'mr-IN-AarohiNeural', 'mr-IN-ManoharNeural', 'mn-MN-BataaNeural', 'mn-MN-YesuiNeural', 'ne-NP-HemkalaNeural', 'ne-NP-SagarNeural', 'nb-NO-FinnNeural', 'nb-NO-PernilleNeural', 'ps-AF-GulNawazNeural', 'ps-AF-LatifaNeural', 'fa-IR-DilaraNeural', 'fa-IR-FaridNeural', 'pl-PL-MarekNeural', 'pl-PL-ZofiaNeural', 'pt-BR-ThalitaNeural', 'pt-BR-AntonioNeural', 'pt-BR-FranciscaNeural', 'pt-PT-DuarteNeural', 'pt-PT-RaquelNeural', 'ro-RO-AlinaNeural', 'ro-RO-EmilNeural', 'ru-RU-DmitryNeural', 'ru-RU-SvetlanaNeural', 'sr-RS-NicholasNeural', 'sr-RS-SophieNeural', 'si-LK-SameeraNeural', 'si-LK-ThiliniNeural', 'sk-SK-LukasNeural', 'sk-SK-ViktoriaNeural', 'sl-SI-PetraNeural', 'sl-SI-RokNeural', 'so-SO-MuuseNeural', 'so-SO-UbaxNeural', 'es-AR-ElenaNeural', 'es-AR-TomasNeural', 'es-BO-MarceloNeural', 'es-BO-SofiaNeural', 'es-CL-CatalinaNeural', 'es-CL-LorenzoNeural', 'es-ES-XimenaNeural', 'es-CO-GonzaloNeural', 'es-CO-SalomeNeural', 'es-CR-JuanNeural', 'es-CR-MariaNeural', 'es-CU-BelkysNeural', 'es-CU-ManuelNeural', 'es-DO-EmilioNeural', 'es-DO-RamonaNeural', 'es-EC-AndreaNeural', 'es-EC-LuisNeural', 'es-SV-LorenaNeural', 'es-SV-RodrigoNeural', 'es-GQ-JavierNeural', 'es-GQ-TeresaNeural', 'es-GT-AndresNeural', 'es-GT-MartaNeural', 'es-HN-CarlosNeural', 'es-HN-KarlaNeural', 'es-MX-DaliaNeural', 'es-MX-JorgeNeural', 'es-NI-FedericoNeural', 'es-NI-YolandaNeural', 'es-PA-MargaritaNeural', 'es-PA-RobertoNeural', 'es-PY-MarioNeural', 'es-PY-TaniaNeural', 'es-PE-AlexNeural', 'es-PE-CamilaNeural', 'es-PR-KarinaNeural', 'es-PR-VictorNeural', 'es-ES-AlvaroNeural', 'es-ES-ElviraNeural', 'es-US-AlonsoNeural', 'es-US-PalomaNeural', 'es-UY-MateoNeural', 'es-UY-ValentinaNeural', 'es-VE-PaolaNeural', 'es-VE-SebastianNeural', 'su-ID-JajangNeural', 'su-ID-TutiNeural', 'sw-KE-RafikiNeural', 'sw-KE-ZuriNeural', 'sw-TZ-DaudiNeural', 'sw-TZ-RehemaNeural', 'sv-SE-MattiasNeural', 'sv-SE-SofieNeural', 'ta-IN-PallaviNeural', 'ta-IN-ValluvarNeural', 'ta-MY-KaniNeural', 'ta-MY-SuryaNeural', 'ta-SG-AnbuNeural', 'ta-SG-VenbaNeural', 'ta-LK-KumarNeural', 'ta-LK-SaranyaNeural', 'te-IN-MohanNeural', 'te-IN-ShrutiNeural', 'th-TH-NiwatNeural', 'th-TH-PremwadeeNeural', 'tr-TR-AhmetNeural', 'tr-TR-EmelNeural', 'uk-UA-OstapNeural', 'uk-UA-PolinaNeural', 'ur-IN-GulNeural', 'ur-IN-SalmanNeural', 'ur-PK-AsadNeural', 'ur-PK-UzmaNeural', 'uz-UZ-MadinaNeural', 'uz-UZ-SardorNeural', 'vi-VN-HoaiMyNeural', 'vi-VN-NamMinhNeural', 'cy-GB-AledNeural', 'cy-GB-NiaNeural', 'zu-ZA-ThandoNeural', 'zu-ZA-ThembaNeural']\n",
        "toc_do_doc = 0 # @param {\"type\":\"slider\",\"min\":-100,\"max\":100,\"step\":1}\n",
        "#@markdown ___\n",
        "#@markdown **T√™n c·ªßa m√¥ h√¨nh ƒë·ªÉ t√¨m ki·∫øm t·ªáp m√¥ h√¨nh v√† ch·ªâ m·ª•c c·ªßa n√≥**\n",
        "ten_mo_hinh = \"\" # @param {\"type\":\"string\",\"placeholder\":\"My-Model\"}\n",
        "#@markdown **Cao ƒë·ªô c·ªßa gi·ªçng n√≥i -12 s·∫Ω tr·∫ßm v√† 12 s·∫Ω cao, ƒë∆∞·ª£c khuy·∫øn c√°o l√† tƒÉng l√™n 12 ƒë·ªÉ chuy·ªÉn ƒë·ªïi gi·ªçng nam sang n·ªØ v√† ng∆∞·ª£c l·∫°i**\n",
        "cao_do = 0 # @param {\"type\":\"slider\",\"min\":-20,\"max\":20,\"step\":1}\n",
        "#@markdown **B·∫£o v·ªá ph·ª• √¢m nh·∫ßm tr√°nh vi·ªác r√°ch ƒëi·ªán t·ª≠ khi chuy·ªÉn ƒë·ªïi √¢m thanh**\n",
        "bao_ve_phu_am = 0.5 # @param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.1}\n",
        "#@markdown ___\n",
        "#@markdown **Ph∆∞∆°ng ph√°p tr√≠ch xu·∫•t √¢m thanh, Khuy·∫øn c√°o: Harvest ho·∫∑c Rmvpe**\n",
        "phuong_phap = \"rmvpe\" #@param [\"pm\", \"dio\", \"crepe-tiny\", \"crepe\", \"fcpe\", \"rmvpe\", \"harvest\", \"hybrid[pm+dio]\", \"hybrid[pm+crepe-tiny]\", \"hybrid[pm+crepe]\", \"hybrid[pm+fcpe]\", \"hybrid[pm+rmvpe]\", \"hybrid[pm+harvest]\", \"hybrid[dio+crepe-tiny]\", \"hybrid[dio+crepe]\", \"hybrid[dio+fcpe]\", \"hybrid[dio+rmvpe]\", \"hybrid[dio+harvest]\", \"hybrid[crepe-tiny+crepe]\", \"hybrid[crepe-tiny+fcpe]\", \"hybrid[crepe-tiny+rmvpe]\", \"hybrid[crepe-tiny+harvest]\", \"hybrid[crepe+fcpe]\", \"hybrid[crepe+rmvpe]\", \"hybrid[crepe+harvest]\", \"hybrid[fcpe+rmvpe]\", \"hybrid[fcpe+harvest]\", \"hybrid[rmvpe+harvest]\"]\n",
        "#@markdown **hop length bi·ªÉu th·ªã kho·∫£ng th·ªùi gian c·∫ßn ƒë·ªÉ chuy·ªÉn sang thay ƒë·ªïi cao ƒë·ªô. Hop length nh·ªè c·∫ßn nhi·ªÅu th·ªùi gian h∆°n ƒë·ªÉ chuy·ªÉn ƒë·ªïi nh∆∞ng ch√≠nh x√°c h∆°n**\n",
        "hop_length = 64 # @param {\"type\":\"slider\",\"min\":64,\"max\":512,\"step\":1}\n",
        "#@markdown **S·ª©c ·∫£nh h∆∞·ªüng c·ªßa chƒ© m·ª•c khi chuy·ªÉn ƒë·ªïi c√†ng cao ·∫£nh h∆∞·ªüng c√†ng l·ªõn. Tuy nhi√™n, vi·ªác ch·ªçn gi√° tr·ªã th·∫•p h∆°n c√≥ th·ªÉ gi·∫£m hi·ªán t∆∞·ª£ng gi·∫£ trong √¢m thanh**\n",
        "anh_huong_chi_muc = 0.5 # @param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.01}\n",
        "#@markdown ___\n",
        "#@markdown **TƒÉng ch·∫•t l∆∞·ª£ng c·ªßa √¢m thanh nh∆∞ng t·ªën nhi·ªÅu t√†i nguy√™n**\n",
        "tang_chat_luong = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh tr√≠ch xu·∫•t c√≥ th·ªÉ ƒë∆∞a ra k·∫øt qu·∫£ t·ªët h∆°n**\n",
        "tu_dong_dieu_chinh = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt khi chuy·ªÉn ƒë·ªïi**\n",
        "hien_thong_tin = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **ƒê·ªãnh d·∫°ng ƒë·∫ßu ra √¢m thanh**\n",
        "dinh_dang = \"wav\" # @param [\"wav\", \"mp3\", \"flac\", \"ogg\", \"m4a\"]\n",
        "#@markdown Hi·ªÉn th·ªã t·ªáp √¢m thanh nghe th·ª≠(C√≥ th·ªÉ g√¢y s·∫≠p colab)\n",
        "hien_thi_tep = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "def convert_b(pitch, filter_radius, index_rate, volume_envelope, protect, hop_length, f0_method, input_path, output_path, pth_path, index_path, f0_autotune, clean_audio, clean_strength, export_format, embedder_model, upscale_audio, resample_sr, info, split_audio, f0_autotune_strength):\n",
        "    if os.path.exists(output_path): os.remove(output_path)\n",
        "\n",
        "    cmd = f\"{sys.executable} main/inference/convert.py --pitch {pitch} --filter_radius {filter_radius} --index_rate {index_rate} --volume_envelope {volume_envelope} --protect {protect} --hop_length {hop_length} --f0_method {f0_method} --input_path {input_path} --output_path {output_path} --pth_path {pth_path} --index_path {index_path} --f0_autotune {f0_autotune} --clean_audio {clean_audio} --clean_strength {clean_strength} --export_format {export_format} --embedder_model {embedder_model} --upscale_audio {upscale_audio} --resample_sr {resample_sr} --split_audio {split_audio} --f0_autotune_strength {f0_autotune_strength}\"\n",
        "    if not info: os.system(cmd)\n",
        "    else:\n",
        "      !$cmd\n",
        "\n",
        "async def convert_tts(prompt, voice, speed, clean, upscale, autotune, pitch, clean_strength, name, index_rate, format, f0method, hop_length, embedder_model, resample_sr, filter_radius, volume_envelope, protect, info, split_audio, f0_autotune_strength):\n",
        "    model_path = os.path.join(\"assets\", \"weights\", f\"{name}.pth\")\n",
        "\n",
        "    if name == \"\": raise ValueError(\"Vui l√≤ng nh·∫≠p t√™n m√¥ h√¨nh\")\n",
        "    if prompt == \"\": raise ValueError(\"Vui l√≤ng nh·∫≠p vƒÉn b·∫£n ƒë·ªÉ ƒë·ªçc\")\n",
        "    if voice == \"\": raise ValueError(\"Vui l√≤ng ch·ªçn gi·ªçng\")\n",
        "\n",
        "    try:\n",
        "      index_path = os.path.join(\"assets\", \"logs\", name,  [f for f in os.listdir(os.path.join(\"assets\", \"logs\", name)) if f.endswith('.index')][0])\n",
        "    except IndexError:\n",
        "      raise ValueError(\"L·ªói khi t√¨m ch·ªâ m·ª•c\")\n",
        "\n",
        "    if not os.path.exists(model_path): raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh\")\n",
        "    if not os.path.exists(index_path): raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y ch·ªâ m·ª•c\")\n",
        "\n",
        "    print(\"Chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n...\")\n",
        "\n",
        "    output_tts = os.path.join(\"audios\", f\"tts.{format}\")\n",
        "\n",
        "    if os.path.exists(output_tts): os.remove(output_tts)\n",
        "    await edge_tts.Communicate(text=prompt, voice=voice, rate=f\"+{speed}%\" if speed >= 0 else f\"{speed}%\").save(output_tts)\n",
        "\n",
        "    print(\"Ho√†n th√†nh\")\n",
        "\n",
        "    output = os.path.join(\"audios\", f\"tts-convert.{format}\")\n",
        "    if os.path.exists(output): os.remove(output)\n",
        "\n",
        "    print(\"ƒêang chuy·ªÉn ƒë·ªïi gi·ªçng n√≥i...\")\n",
        "    if not info: clear_output()\n",
        "\n",
        "    convert_b(pitch, filter_radius, index_rate, volume_envelope, protect, hop_length, f0method, output_tts, output, model_path, index_path, autotune, clean, clean_strength, format, embedder_model, upscale, resample_sr, info, split_audio, f0_autotune_strength)\n",
        "    print(\"K·∫øt h·ª£p Ho√†n th√†nh\")\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "await convert_tts(noi_dung, giong, toc_do_doc, False, tang_chat_luong, tu_dong_dieu_chinh, cao_do, 0, ten_mo_hinh.replace('.pth', '').replace('.index', '').replace('.zip', '').replace(' ', '_').strip(), anh_huong_chi_muc, dinh_dang, phuong_phap, hop_length, \"hubert_base\", 0, 3, 1, bao_ve_phu_am, hien_thong_tin, False, 1)\n",
        "\n",
        "if not hien_thong_tin: clear_output()\n",
        "display(Button(description=\"\\u2714 Chuy·ªÉn ƒë·ªïi xong\", button_style=\"success\"))\n",
        "\n",
        "audio = os.path.join(\"audios\", f\"tts-convert.{dinh_dang}\")\n",
        "if os.path.exists(audio) and hien_thi_tep: display(Audio(data=audio, rate=AudioSegment.from_file(audio).frame_rate, autoplay=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ers351v_CMGN"
      },
      "source": [
        "# **Hu·∫•n luy·ªán m√¥ h√¨nh ü§ñ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1w-pCaK69uVd"
      },
      "outputs": [],
      "source": [
        "#@title **‚¨áÔ∏è C√†i ƒë·∫∑t hu·∫•n luy·ªán tr∆∞·ªõc**\n",
        "import os\n",
        "import codecs\n",
        "import requests\n",
        "import subprocess\n",
        "\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "#@markdown **M√¥ h√¨nh hu·∫•n luy·ªán**\n",
        "mo_hinh = 'Titan_Medium' #@param [\"RIN_E3\", \"OV2Super\", \"SnowieRuPretrain\", \"Itaila\", \"SnowieV3.1\", \"Snowie-X-RinE3\", \"KLM4.1\", \"Titan_Medium\", \"NanashiV1\", \"NanashiV1.5\", \"NanashiV1.7\", \"Rigel_Base\", \"Rigel_FineTuned\", \"RigelV1.5\", \"DMRV1\", \"IMA\", \"Nanashi_Anime_Normal\", \"Nanashi_Anime_Resize\", \"KLM_BeatzForge\", \"KLM4.2\"]\n",
        "#@markdown **T·ªëc ƒë·ªô l·∫•y m·∫´u c·ªßa m√¥ h√¨nh**\n",
        "toc_do = '48k' #@param [\"48k\", \"32k\", \"40k\"]\n",
        "\n",
        "def fetch_pretrained_data():\n",
        "    response = requests.get(codecs.decode(\"uggcf://uhttvatsnpr.pb/NauC/Pbyno_EIP_Cebwrpg_2/enj/znva/cergenva_pubvprf.wfba\", \"rot13\"))\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "def download_pretrained_model(model, sample_rate):\n",
        "    data = fetch_pretrained_data()\n",
        "    try:\n",
        "      paths = data[model][sample_rate]\n",
        "    except ValueError:\n",
        "      raise FileNotFoundError(f\"M√¥ h√¨nh {model} kh√¥ng c√≥ t·ªëc ƒë·ªô l·∫•y m·∫´u {sample_rate}\")\n",
        "\n",
        "    pretraineds_custom_path = os.path.join(\"assets\", \"model\", \"pretrained_custom\")\n",
        "    os.makedirs(pretraineds_custom_path, exist_ok=True)\n",
        "\n",
        "    d_url = codecs.decode(\"uggcf://uhttvatsnpr.pb\", \"rot13\") + f\"/{paths['D']}\"\n",
        "    g_url = codecs.decode(\"uggcf://uhttvatsnpr.pb\", \"rot13\") + f\"/{paths['G']}\"\n",
        "\n",
        "    print(\"T·∫£i xu·ªëng hu·∫•n luy·ªán tr∆∞·ªõc...\")\n",
        "    subprocess.run([\"wget\", d_url.replace('/blob/', '/resolve/').replace('?download=true', '').strip(), \"-P\", pretraineds_custom_path], check=True)\n",
        "    subprocess.run([\"wget\", g_url.replace('/blob/', '/resolve/').replace('?download=true', '').strip(), \"-P\", pretraineds_custom_path], check=True)\n",
        "\n",
        "    clear_output()\n",
        "    display(Button(description=\"\\u2714 T·∫£i xu·ªëng xong\", button_style=\"success\"))\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "download_pretrained_model(mo_hinh, toc_do)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **T·∫°o d·ªØ li·ªáu hu·∫•n luy·ªán t·ª´ ƒë∆∞·ªùng d·∫´n li√™n k·∫øt ‚ñ∂Ô∏è**\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "#@markdown **T√°ch nh·∫°c c·ªßa t·ªáp**\n",
        "tach_nhac = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **T√°ch vang khi t√°ch nh·∫°c**\n",
        "tach_vang = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **M·ª©c ƒë·ªô ch·ªìng ch√©o gi·ªØa c√°c ph·∫ßn √¢m thanh, k√≠ch th∆∞·ªõc c√°c ph√¢n ƒëo·∫°n**\n",
        "chong_cheo = \"0.25\" # @param [\"0.25\", \"0.5\", \"0.75\", \"0.99\"]\n",
        "kich_thuoc_phan_doan = 256 # @param {\"type\":\"slider\",\"min\":32,\"max\":2048,\"step\":8}\n",
        "#@markdown **ƒê∆∞·ªùng d·∫´n ƒë·∫øn video l√†m d·ªØ li·ªáu √¢m thanh, s·ª≠ d·ª•ng d·∫•u , ƒë·ªÉ ch·ªçn nhi·ªÅu √¢m thanh**\n",
        "duong_dan_am_thanh = \"\" # @param {\"type\":\"string\",\"placeholder\":\"https://youtube.com/...\"}\n",
        "#@markdown **B·ªè qua ph·∫ßn ƒë·∫ßu v√† ph·∫ßn cu·ªëi c·ªßa √¢m thanh. T√≠nh b·∫±ng gi√¢y, s·ª≠ d·ª•ng d·∫•u , ƒë·ªÉ s·ª≠ d·ª•ng nhi·ªÅu √¢m thanh**\n",
        "bo_qua = False # @param {\"type\":\"boolean\"}\n",
        "bo_qua_giay_dau = \"\" # @param {\"type\":\"string\",\"placeholder\":\"0, 1, 2\"}\n",
        "bo_qua_giay_cuoi = \"\" # @param {\"type\":\"string\",\"placeholder\":\"0, 1, 2\"}\n",
        "#@markdown **L√†m s·∫°ch d·ªØ li·ªáu √¢m thanh khi t·∫°o**\n",
        "lam_sach_du_lieu = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **X√≥a th√¥ng tin ƒë·∫ßu ra**\n",
        "xoa_dau_ra = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "def create_dataset(input_audio, output_dataset, resample, resample_sr, clean_dataset, clean_strength, separator_music, separator_reverb, kim_vocals_version, overlap, segments_size, denoise_mdx, skip, skip_start, skip_end, hop_length, batch_size):\n",
        "    create_dataset_cmd = f'{sys.executable} main/inference/create_dataset.py --input_audio \"{input_audio}\" --output_dataset {output_dataset} --resample {resample} --resample_sr {resample_sr} --clean_dataset {clean_dataset} --clean_strength {clean_strength} --separator_music {separator_music} --separator_reverb {separator_reverb} --kim_vocal_version {kim_vocals_version} --overlap {overlap} --segments_size {segments_size} --mdx_hop_length {hop_length} --mdx_batch_size {batch_size} --denoise_mdx {denoise_mdx} --skip {skip} --skip_start_audios \"{skip_start}\" --skip_end_audios \"{skip_end}\"'\n",
        "    !$create_dataset_cmd\n",
        "\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "create_dataset(duong_dan_am_thanh, \"dataset\", False, 0, lam_sach_du_lieu, 0.7, tach_nhac, tach_vang, 2, chong_cheo, kich_thuoc_phan_doan, True, bo_qua, bo_qua_giay_dau, bo_qua_giay_cuoi, 1024, 1)\n",
        "\n",
        "if xoa_dau_ra: clear_output()\n",
        "display(Button(description=\"\\u2714 T·∫°o th√†nh c√¥ng!\", button_style=\"success\"))"
      ],
      "metadata": {
        "id": "8yg85YQlUovq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEXlV0tGCWcG",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **X·ª≠ l√Ω v√† tr√≠ch xu·∫•t d·ªØ li·ªáu ‚õèÔ∏è**\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "\n",
        "#@markdown **T·∫£i c√°c d·ªØ li·ªáu √¢m thanh trong drive ƒë·ªÉ t·∫°o d·ªØ li·ªáu hu·∫•n luy·ªán**\n",
        "tai_du_lieu_huan_luyen_tu_drive = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **T√™n m√¥ h√¨nh ƒë·ªÉ t·∫°o t·∫≠p tin hu·∫•n luy·ªán**\n",
        "ten_mo_hinh = \"\" # @param {\"type\":\"string\",\"placeholder\":\"My-Model\"}\n",
        "#@markdown **T·ªëc ƒë·ªô l·∫•y m·∫´u c·ªßa m√¥ h√¨nh**\n",
        "toc_do_lay_mau = \"48k\" # @param [\"48k\", \"40k\", \"32k\"]\n",
        "#@markdown **Ph∆∞∆°ng ph√°p tr√≠ch xu·∫•t d·ªØ li·ªáu √¢m thanh**\n",
        "phuong_phap = \"rmvpe\" # @param [\"pm\", \"dio\", \"crepe\", \"crepe-tiny\", \"fcpe\", \"rmvpe\", \"harvest\"]\n",
        "#@markdown **hop length bi·ªÉu th·ªã kho·∫£ng th·ªùi gian c·∫ßn ƒë·ªÉ chuy·ªÉn sang thay ƒë·ªïi cao ƒë·ªô. Hop length nh·ªè c·∫ßn nhi·ªÅu th·ªùi gian h∆°n ƒë·ªÉ chuy·ªÉn ƒë·ªïi nh∆∞ng ch√≠nh x√°c h∆°n**\n",
        "hop_length = 64 # @param {\"type\":\"slider\",\"min\":64,\"max\":512,\"step\":1}\n",
        "#@markdown **L√†m s·∫°ch d·ªØ li·ªáu v√† x√≥a th√¥ng tin ƒë·∫ßu ra**\n",
        "lam_sach_du_lieu = False # @param {\"type\":\"boolean\"}\n",
        "xoa_dau_ra = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "python = sys.executable\n",
        "\n",
        "\n",
        "def preprocess(model_name, sample_rate, cpu_core, cut_preprocess, process_effects, path, clean_dataset, clean_strength):\n",
        "    dataset = os.path.join(path)\n",
        "    sr = int(sample_rate.rstrip(\"k\")) * 1000\n",
        "\n",
        "    if model_name == \"\": raise ValueError(\"Vui l√≤ng cung c·∫•p t√™n\")\n",
        "\n",
        "    if len([f for f in os.listdir(os.path.join(\"dataset\")) if os.path.isfile(os.path.join(\"dataset\", f)) and f.lower().endswith((\".wav\", \".mp3\", \".flac\", \".ogg\"))]) < 1: raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu\")\n",
        "\n",
        "    preprocess_cmd = f'{python} main/inference/preprocess.py --model_name {model_name} --dataset_path {dataset} --sample_rate {sr} --cpu_cores {cpu_core} --cut_preprocess {cut_preprocess} --process_effects {process_effects} --clean_dataset {clean_dataset} --clean_strength {clean_strength}'\n",
        "    !$preprocess_cmd\n",
        "\n",
        "\n",
        "def extract(model_name, version, method, pitch_guidance, hop_length, cpu_cores, gpu, sample_rate, embedder_model):\n",
        "    sr = int(sample_rate.rstrip(\"k\")) * 1000\n",
        "\n",
        "    if model_name == \"\": raise ValueError(\"Vui l√≤ng cung c·∫•p t√™n\")\n",
        "\n",
        "    if len([f for f in os.listdir(os.path.join(\"assets\", \"logs\", model_name, \"sliced_audios\")) if os.path.isfile(os.path.join(\"assets\", \"logs\", model_name, \"sliced_audios\", f))]) < 1 or len([f for f in os.listdir(os.path.join(\"assets\", \"logs\", model_name, \"sliced_audios_16k\")) if os.path.isfile(os.path.join(\"assets\", \"logs\", model_name, \"sliced_audios_16k\", f))]) < 1: raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ƒë∆∞·ª£c x·ª≠ l√≠, vui l√≤ng x·ª≠ l√≠ l·∫°i √¢m thanh\")\n",
        "\n",
        "    extract_cmd = f'{python} main/inference/extract.py --model_name {model_name} --rvc_version {version} --f0_method {method} --pitch_guidance {pitch_guidance} --hop_length {hop_length} --cpu_cores {cpu_cores} --gpu {gpu} --sample_rate {sr} --embedder_model {embedder_model}'\n",
        "    !$extract_cmd\n",
        "\n",
        "\n",
        "def create_index(model_name, rvc_version, index_algorithm):\n",
        "    if model_name == \"\": raise ValueError(\"Vui l√≤ng cung c·∫•p t√™n\")\n",
        "    if len([f for f in os.listdir(os.path.join(\"assets\", \"logs\", model_name, f\"{rvc_version}_extracted\")) if os.path.isfile(os.path.join(\"assets\", \"logs\", model_name, f\"{rvc_version}_extracted\", f))]) < 1: raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ƒë∆∞·ª£c tr√≠ch xu·∫•t, vui l√≤ng tr√≠ch xu·∫•t l·∫°i √¢m thanh\")\n",
        "\n",
        "    create_index_cmd = f'{python} main/inference/create_index.py --model_name {model_name} --rvc_version {rvc_version} --index_algorithm {index_algorithm}'\n",
        "    !$create_index_cmd\n",
        "\n",
        "\n",
        "if not tai_du_lieu_huan_luyen_tu_drive:\n",
        "  if len([f for f in os.listdir('/content/Vietnamese_RVC/dataset') if not '.ipynb_checkpoints' in f]) < 1:\n",
        "    print(\"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu, vui l√≤ng t·∫£i l√™n d·ªØ li·ªáu hu·∫•n luy·ªán √¢m thanh\")\n",
        "    %cd /content/Vietnamese_RVC/dataset\n",
        "    files.upload()\n",
        "else:\n",
        "  if not os.path.exists('/content/drive/MyDrive'): raise ValueError(\"B·∫°n ch∆∞a k·∫øt n·ªëi v·ªõi google drive\")\n",
        "  if len([f for f in os.listdir('/content/drive/MyDrive/dataset') if not '.ipynb_checkpoints' in f]) < 1: raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu\")\n",
        "\n",
        "  for audios in os.listdir('/content/drive/MyDrive/dataset'):\n",
        "    shutil.copy(f'/content/drive/MyDrive/dataset/{audios}', '/content/Vietnamese_RVC/dataset')\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "preprocess(ten_mo_hinh, toc_do_lay_mau, 2, True, False, \"dataset\", lam_sach_du_lieu, 0.7)\n",
        "extract(ten_mo_hinh, \"v2\", phuong_phap, True, hop_length, 2, 0, toc_do_lay_mau, \"hubert_base\")\n",
        "create_index(ten_mo_hinh, \"v2\", \"Auto\")\n",
        "\n",
        "\n",
        "if xoa_dau_ra: clear_output()\n",
        "display(Button(description=\"\\u2714 X·ª≠ l√Ω xong!\", button_style=\"success\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VdlJlOHCUud",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Hu·∫•n luy·ªán m√¥ h√¨nh ü§ñ**\n",
        "import os\n",
        "import sys\n",
        "import codecs\n",
        "import subprocess\n",
        "\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "#@markdown **T√™n m√¥ h√¨nh v√† t·ªëc ƒë·ªô l·∫•y m·∫´u c·ªßa m√¥ h√¨nh**\n",
        "ten_mo_hinh = \"\" # @param {\"type\":\"string\",\"placeholder\":\"My-Model\"}\n",
        "toc_do_lay_mau = \"48k\" #@param [\"48k\", \"40k\", \"32k\"]\n",
        "#@markdown ___\n",
        "#@markdown **S·ªë l∆∞·ª£ng k·ª∑ nguy√™n v√† t·∫ßn su·∫•t l∆∞u c·ªßa m√¥ h√¨nh khi hu·∫•n luy·ªán**\n",
        "so_luong_ky_nguyen = 300 # @param {\"type\":\"slider\",\"min\":1,\"max\":10000,\"step\":1}\n",
        "tan_suat_luu = 25 # @param {\"type\":\"slider\",\"min\":1,\"max\":10000,\"step\":1}\n",
        "#@markdown ___\n",
        "#@markdown **C√°c t√πy ch·ªçn v·ªÅ vi·ªác h·ªó tr·ª£ hu·∫•n luy·ªán: Kh√¥ng s·ª≠ d·ª•ng hu·∫•n luy·ªán tr∆∞·ªõc, s·ª≠ d·ª•ng hu·∫•n luy·ªán t√πy ch·ªânh v√† m√¥ h√¨nh t√πy ch·ªânh**\n",
        "khong_su_dung_huan_luyen_truoc = False # @param {\"type\":\"boolean\"}\n",
        "su_dung_huan_luyen_tuy_chinh = False # @param {\"type\":\"boolean\"}\n",
        "mo_hinh_huan_luyen_tuy_chinh = \"Titan_Medium\" #@param [\"RIN_E3\", \"OV2Super\", \"SnowieRuPretrain\", \"Itaila\", \"SnowieV3.1\", \"Snowie-X-RinE3\", \"KLM4.1\", \"Titan_Medium\", \"NanashiV1\", \"NanashiV1.5\", \"NanashiV1.7\", \"Rigel_Base\", \"Rigel_FineTuned\", \"RigelV1.5\", \"DMRV1\", \"IMA\", \"Nanashi_Anime_Normal\", \"Nanashi_Anime_Resize\", \"KLM_BeatzForge\", \"KLM4.2\"]\n",
        "#@markdown ___\n",
        "#@markdown **T√πy ch·ªçn v·ªÅ vi·ªác ph√°t hi·ªán hu·∫•n luy·ªán qu√° s·ª©c: bi·ªÉu ƒë·ªì hu·∫•n luy·ªán, t·ª± ƒë·ªông ki·ªÉm tra hu·∫•n luy·ªán v√† t·ªâ l·ªá ki·ªÉm tra hu·∫•n luy·ªán**\n",
        "su_dung_bieu_do = False # @param {\"type\":\"boolean\"}\n",
        "kiem_tra_huan_luyen = False # @param {\"type\":\"boolean\"}\n",
        "ti_le_kiem_tra = 50 # @param {\"type\":\"slider\",\"min\":1,\"max\":100,\"step\":1}\n",
        "#@markdown ___\n",
        "#@markdown **T√πy ch·ªçn v·ªÅ vi·ªác s·ª≠ d·ª•ng b·ªô nh·ªõ gpu trong vi·ªác hu·∫•n luy·ªán ƒë·ªÉ ƒë·∫©y nhanh t·ªëc ƒë·ªô hu·∫•n luy·ªán**\n",
        "kich_thuoc_lo = 8 # @param {\"type\":\"slider\",\"min\":1,\"max\":64,\"step\":1}\n",
        "bo_nho_dem = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown ___\n",
        "#@markdown **X√≥a c√°c th√¥ng tin hu·∫•n luy·ªán khi ho√†n th√†nh, c√≥ th·ªÉ xem l·∫°i trong train.log**\n",
        "xoa_dau_ra = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "def pretrained_selector(pitch_guidance):\n",
        "    if pitch_guidance:\n",
        "        return {\n",
        "            \"32k\": (\n",
        "                \"f0G32k.pth\",\n",
        "                \"f0D32k.pth\"\n",
        "            ),\n",
        "            \"40k\": (\n",
        "                \"f0G40k.pth\",\n",
        "                \"f0D40k.pth\"\n",
        "            ),\n",
        "            \"48k\": (\n",
        "                \"f0G48k.pth\",\n",
        "                \"f0D48k.pth\"\n",
        "            ),\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            \"32k\": (\n",
        "                \"G32k.pth\",\n",
        "                \"D32k.pth\"\n",
        "            ),\n",
        "            \"40k\": (\n",
        "                \"G40k.pth\",\n",
        "                \"D40k.pth\"\n",
        "            ),\n",
        "            \"48k\": (\n",
        "                \"G48k.pth\",\n",
        "                \"D48k.pth\"\n",
        "            )\n",
        "        }\n",
        "\n",
        "\n",
        "custom_pretrained_selector = {\n",
        "    \"RIN_E3\": {\n",
        "        \"40k\": {\n",
        "            \"D\": \"RIN_E3_D.pth\",\n",
        "            \"G\": \"RIN_E3_G.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"OV2Super\": {\n",
        "        \"32k\": {\n",
        "            \"D\": \"f0Ov2Super32kD.pth\",\n",
        "            \"G\": \"f0Ov2Super32kG.pth\"\n",
        "        },\n",
        "        \"40k\": {\n",
        "            \"D\": \"f0Ov2Super40kD.pth\",\n",
        "            \"G\": \"f0Ov2Super40kG.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"SnowieRuPretrain\": {\n",
        "        \"40k\": {\n",
        "            \"D\": \"D_Snowie_RuPretrain_EnP.pth\",\n",
        "            \"G\": \"G_Snowie_RuPretrain_EnP.pth\"\n",
        "        },\n",
        "        \"48k\": {\n",
        "            \"D\": \"D_Snowie_Rupretrain_48k_V1.2.pth\",\n",
        "            \"G\": \"G_Snowie_Rupretrain_48k_V1.2.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"Itaila\": {\n",
        "        \"32k\": {\n",
        "            \"D\": \"ItaIla_32k_D.pth\",\n",
        "            \"G\": \"ItaIla_32k_G.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"SnowieV3.1\": {\n",
        "        \"32k\": {\n",
        "            \"D\": \"D_SnowieV3.1_32k.pth\",\n",
        "            \"G\": \"G_SnowieV3.1_32k.pth\"\n",
        "        },\n",
        "        \"40k\": {\n",
        "            \"D\": \"D_SnowieV3.1_40k.pth\",\n",
        "            \"G\": \"G_SnowieV3.1_40k.pth\"\n",
        "        },\n",
        "        \"48k\": {\n",
        "            \"D\": \"D_SnowieV3.1_48k.pth\",\n",
        "            \"G\": \"G_SnowieV3.1_48k.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"Snowie-X-RinE3\": {\n",
        "        \"40k\": {\n",
        "            \"D\": \"D_Snowie-X-Rin_40k.pth\",\n",
        "            \"G\": \"G_Snowie-X-Rin_40k.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"KLM4.1\": {\n",
        "        \"32k\": {\n",
        "            \"D\": \"D_KLM41_32k.pth\",\n",
        "            \"G\": \"G_KLM41_32k.pth\"\n",
        "        },\n",
        "        \"48k\": {\n",
        "            \"D\": \"D_KLM41_48k.pth\",\n",
        "            \"G\": \"G_KLM41_48k.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"Titan_Medium\": {\n",
        "        \"32k\": {\n",
        "            \"D\": \"D-f032k-TITAN-Medium.pth\",\n",
        "            \"G\": \"G-f032k-TITAN-Medium.pth\"\n",
        "        },\n",
        "        \"40k\": {\n",
        "            \"D\": \"D-f040k-TITAN-Medium.pth\",\n",
        "            \"G\": \"G-f040k-TITAN-Medium.pth\"\n",
        "        },\n",
        "        \"48k\": {\n",
        "            \"D\": \"D-f048k-TITAN-Medium.pth\",\n",
        "            \"G\": \"G-f048k-TITAN-Medium.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"NanashiV1\": {\n",
        "        \"32k\": {\n",
        "            \"D\": \"D_nanashi_v1.pth\",\n",
        "            \"G\": \"G_nanashi_v1.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"NanashiV1.5\": {\n",
        "        \"32k\": {\n",
        "            \"D\": \"D_nanashi_v1_5.pth\",\n",
        "            \"G\": \"G_nanashi_v1_5.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"NanashiV1.7\": {\n",
        "        \"32k\": {\n",
        "            \"D\": \"D_nanashi_v1_7.pth\",\n",
        "            \"G\": \"G_nanashi_v1_7.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"Rigel_Base\": {\n",
        "        \"32k\": {\n",
        "            \"D\": \"D_Rigel_32k_3890220.pth\",\n",
        "            \"G\": \"G_Rigel_32k_3890220.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"Rigel_FineTuned\": {\n",
        "        \"32k\": {\n",
        "            \"D\": \"D_Rigel_32k_fp32_2854856.pth\",\n",
        "            \"G\": \"G_Rigel_32k_fp32_2854856.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"RigelV1.5\": {\n",
        "        \"32k\": {\n",
        "            \"D\": \"D_Rigel_Portuguese_50e.pth\",\n",
        "            \"G\": \"G_Rigel_Portuguese_50e.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"DMRV1\": {\n",
        "        \"32k\": {\n",
        "            \"D\": \"D_DMR-V1.pth\",\n",
        "            \"G\": \"G_DMR-V1.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"IMA\": {\n",
        "        \"32k\": {\n",
        "            \"D\": \"D_2333333.pth\",\n",
        "            \"G\": \"G_2333333.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"Nanashi_Anime_Normal\": {\n",
        "        \"32k\": {\n",
        "            \"D\": \"D_nanashi_anime_384e.pth\",\n",
        "            \"G\": \"G_nanashi_anime_384e.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"Nanashi_Anime_Resize\": {\n",
        "        \"32k\": {\n",
        "            \"D\": \"D_nanashi_anime_resized.pth\",\n",
        "            \"G\": \"G_nanashi_anime_resized.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"KLM_BeatzForge\": {\n",
        "        \"32k\": {\n",
        "            \"D\": \"D_BeatzForge_V2_32k.pth\",\n",
        "            \"G\": \"G_BeatzForge_V2_32k.pth\"\n",
        "        }\n",
        "    },\n",
        "    \"KLM4.2\": {\n",
        "        \"40k\": {\n",
        "            \"D\": \"D_KLM42_T4_40k.pth\",\n",
        "            \"G\": \"G_KLM42_T4_40k.pth\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "def training(model_name, rvc_version, save_every_epoch, save_only_latest, save_every_weights, total_epoch, sample_rate, batch_size, gpu, pitch_guidance, not_pretrain, custom_pretrained, pretrain_model, detector, threshold, sync_graph, cache):\n",
        "    if model_name == \"\": raise ValueError(\"Vui l√≤ng cung c·∫•p t√™n\")\n",
        "    if len(os.listdir(os.path.join(\"assets\", \"logs\", model_name, f\"{rvc_version}_extracted\"))) < 1: raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ƒë∆∞·ª£c tr√≠ch xu·∫•t, vui l√≤ng tr√≠ch xu·∫•t l·∫°i √¢m thanh\")\n",
        "\n",
        "    training_cmd = f'{sys.executable} main/inference/train.py --model_name {model_name} --rvc_version {rvc_version} --save_every_epoch {save_every_epoch} --save_only_latest {save_only_latest} --save_every_weights {save_every_weights} --total_epoch {total_epoch} --sample_rate {int(sample_rate.rstrip(\"k\")) * 1000} --batch_size {batch_size} --gpu {gpu} --pitch_guidance {pitch_guidance} --overtraining_detector {detector} --overtraining_threshold {threshold} --sync_graph {sync_graph} --cache_data_in_gpu {cache}'\n",
        "\n",
        "    if not not_pretrain:\n",
        "        if not custom_pretrained:\n",
        "          pg, pd = pretrained_selector(pitch_guidance)[sample_rate]\n",
        "        else:\n",
        "          try:\n",
        "            paths = custom_pretrained_selector[pretrain_model][sample_rate]\n",
        "          except ValueError:\n",
        "            raise ValueError(f\"M√¥ h√¨nh {pretrain_model} kh√¥ng c√≥ t·ªëc ƒë·ªô l·∫•y m·∫´u {sample_rate}\")\n",
        "\n",
        "          pg = os.path.join(paths['G'])\n",
        "          pd = os.path.join(paths['D'])\n",
        "\n",
        "        if not custom_pretrained:\n",
        "            pretrained_G = os.path.join(\"assets\", \"model\", f\"pretrained_{rvc_version}\", pg)\n",
        "            pretrained_D = os.path.join(\"assets\", \"model\", f\"pretrained_{rvc_version}\", pd)\n",
        "        else:\n",
        "            pretrained_G = os.path.join(\"assets\", \"model\", f\"pretrained_custom\", pg)\n",
        "            pretrained_D = os.path.join(\"assets\", \"model\", f\"pretrained_custom\", pd)\n",
        "\n",
        "        download_version = codecs.decode(\"uggcf://uhttvatsnpr.pb/yw1995/IbvprPbairefvbaJroHV/erfbyir/znva/cergenvarq_i2/\", \"rot13\") if rvc_version == \"v2\" else codecs.decode(\"uggcf://uhttvatsnpr.pb/VNUvfcnab/Nccyvb/erfbyir/znva/Erfbheprf/cergenvarq_i1/\", \"rot13\")\n",
        "\n",
        "        if not custom_pretrained:\n",
        "            if not os.path.exists(pretrained_G):\n",
        "                print(f\"T·∫£i xu·ªëng hu·∫•n luy·ªán tr∆∞·ªõc G{rvc_version} g·ªëc\")\n",
        "                subprocess.run([\"wget\", f\"{download_version}{pg}\", \"-P\", os.path.join(\"assets\", \"model\", f\"pretrained_{rvc_version}\")], check=True)\n",
        "\n",
        "            if not os.path.exists(pretrained_D):\n",
        "                print(f\"T·∫£i xu·ªëng hu·∫•n luy·ªán tr∆∞·ªõc D{rvc_version} g·ªëc\")\n",
        "                subprocess.run([\"wget\", f\"{download_version}{pd}\", \"-P\", os.path.join(\"assets\", \"model\", f\"pretrained_{rvc_version}\")], check=True)\n",
        "        else:\n",
        "            if not os.path.exists(pretrained_G): raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y hu·∫•n luy·ªán tr∆∞·ªõc G\")\n",
        "            if not os.path.exists(pretrained_D): raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y hu·∫•n luy·ªán tr∆∞·ªõc D\")\n",
        "\n",
        "        training_cmd += f\" --g_pretrained_path {pretrained_G} --d_pretrained_path {pretrained_D}\"\n",
        "    else: print(\"S·∫Ω kh√¥ng c√≥ hu·∫•n luy·ªán tr∆∞·ªõc ƒë∆∞·ª£c s·ª≠ d·ª•ng\")\n",
        "\n",
        "    print(\"B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán...\")\n",
        "\n",
        "    !$training_cmd\n",
        "\n",
        "    print(\"Ho√†n th√†nh\")\n",
        "\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "if su_dung_bieu_do:\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir ./assets/logs --port=6870\n",
        "\n",
        "training(ten_mo_hinh, \"v2\", tan_suat_luu, True, True, so_luong_ky_nguyen, toc_do_lay_mau, kich_thuoc_lo, 0, True, khong_su_dung_huan_luyen_truoc, su_dung_huan_luyen_tuy_chinh, mo_hinh_huan_luyen_tuy_chinh, kiem_tra_huan_luyen, ti_le_kiem_tra, False, bo_nho_dem)\n",
        "\n",
        "if xoa_dau_ra: clear_output()\n",
        "display(Button(description=\"\\u2714 Hu·∫•n luy·ªán xong!\", button_style=\"success\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "tkqks7bO2Cye",
        "XP4ifZaG_yd5",
        "ekfkFFNqppfM",
        "ers351v_CMGN"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}