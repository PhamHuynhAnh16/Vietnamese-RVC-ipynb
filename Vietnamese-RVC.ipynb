{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVAACnvlmE4I"
      },
      "source": [
        "**D·ª± √°n n√†y ƒë∆∞·ª£c n·∫•u b·ªüi [Ph·∫°m Hu·ª≥nh Anh](https://github.com/PhamHuynhAnh16)**\n",
        "\n",
        "# **Vui l√≤ng kh√¥ng s·ª≠ d·ª•ng d·ª± √°n v·ªõi b·∫•t k·ª≥ m·ª•c ƒë√≠ch n√†o vi ph·∫°m ƒë·∫°o ƒë·ª©c, ph√°p lu·∫≠t, ho·∫∑c g√¢y t·ªïn h·∫°i ƒë·∫øn c√° nh√¢n, t·ªï ch·ª©c...**\n",
        "\n",
        "# **Trong tr∆∞·ªùng h·ª£p ng∆∞·ªùi s·ª≠ d·ª•ng kh√¥ng tu√¢n th·ªß c√°c ƒëi·ªÅu kho·∫£n ho·∫∑c vi ph·∫°m, t√¥i s·∫Ω kh√¥ng ch·ªãu tr√°ch nhi·ªám v·ªÅ b·∫•t k·ª≥ khi·∫øu n·∫°i, thi·ªát h·∫°i, hay tr√°ch nhi·ªám ph√°p l√Ω n√†o, d√π l√† trong h·ª£p ƒë·ªìng, do s∆° su·∫•t, hay c√°c l√Ω do kh√°c, ph√°t sinh t·ª´, ngo√†i, ho·∫∑c li√™n quan ƒë·∫øn ph·∫ßn m·ªÅm, vi·ªác s·ª≠ d·ª•ng ph·∫ßn m·ªÅm ho·∫∑c c√°c giao d·ªãch kh√°c li√™n quan ƒë·∫øn ph·∫ßn m·ªÅm.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BJeRif5jjL5s"
      },
      "outputs": [],
      "source": [
        "#@title **üåè C√†i ƒë·∫∑t**\n",
        "import os\n",
        "\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "\n",
        "print(\"üë©üèª‚Äçüíª C√†i ƒë·∫∑t...\")\n",
        "\n",
        "!git clone https://github.com/PhamHuynhAnh16/Vietnamese-RVC /content/Vietnamese_RVC > /dev/null 2>&1\n",
        "!pip install -r /content/Vietnamese_RVC/requirements.txt --no-cache-dir -q > /dev/null 2>&1\n",
        "\n",
        "#@markdown **üíª C√†i ƒë·∫∑t s·∫Ω m·∫•t kho·∫£ng 2 ph√∫t ƒë·ªÉ ho√†n t·∫•t!**\n",
        "\n",
        "os.environ[\"TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD\"] = \"1\"\n",
        "os.environ[\"TORCH_FORCE_WEIGHTS_ONLY_LOAD\"] = \"0\"\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Ho√†n T·∫•t!\", button_style=\"success\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cIsBEvHaQWMJ"
      },
      "outputs": [],
      "source": [
        "#@title **üì± M·ªü giao di·ªán s·ª≠ d·ª•ng**\n",
        "import os\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "#@markdown **ƒê·ªÉ tr·∫£i nghi·ªám h·∫øt t√≠nh nƒÉng h√£y d√πng giao di·ªán:) C√≤n mu·ªën ƒë∆°n gi·∫£n th√¨ kh√¥ng d√πng giao di·ªán**\n",
        "\n",
        "#@markdown **N·∫øu bi·∫øt c√≥ th·ªÉ s·ª≠ d·ª•ng bi·ªÉu ƒë·ªì ƒë·ªÉ ki·ªÉm tra hu·∫•n luy·ªán qu√° s·ª©c üëç**\n",
        "su_dung_bieu_do = False #@param {type:\"boolean\"}\n",
        "\n",
        "if su_dung_bieu_do:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir ./assets/logs --port=6870\n",
        "\n",
        "!wget https://huggingface.co/AnhP/Vietnamese-RVC-Project/resolve/main/predictors/rmvpe.pt -O /content/Vietnamese_RVC/assets/models/predictors/rmvpe.pt > /dev/null 2>&1\n",
        "!wget https://huggingface.co/AnhP/Vietnamese-RVC-Project/resolve/main/embedders/fairseq/hubert_base.pt -O /content/Vietnamese_RVC/assets/models/embedders/hubert_base.pt > /dev/null 2>&1\n",
        "\n",
        "!python main/app/app.py --share"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkqks7bO2Cye"
      },
      "source": [
        "# **T√πy ch·ªânh th√™m üß∞**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1cxnr7qP2clf"
      },
      "outputs": [],
      "source": [
        "#@title **K·∫øt n·ªëi ho·∫∑c ng·∫Øt k·∫øt n·ªëi v·ªõi drive ‚òÅ**\n",
        "import os\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "if os.path.exists(\"/content/drive\"):\n",
        "    print(\"üîó Ng·∫Øt k·∫øt n·ªëi v·ªõi drive...\")\n",
        "    try:\n",
        "        drive.flush_and_unmount()\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Ho√†n T·∫•t!\", button_style=\"success\"))\n",
        "    except Exception as e:\n",
        "        raise ValueError(f'ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh ng·∫Øt k·∫øt n·ªëi drive: {e}')\n",
        "else:\n",
        "    print('üîó K·∫øt n·ªëi v·ªõi drive...')\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Ho√†n T·∫•t!\", button_style=\"success\"))\n",
        "    except Exception as e:\n",
        "        raise ValueError(f'ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh k·∫øt n·ªëi drive: {e}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-pS4-MMA7L9X"
      },
      "outputs": [],
      "source": [
        "#@title **Kh·ªüi ƒë·ªông ho·∫∑c ng·ª´ng sao l∆∞u üõ†**\n",
        "import os\n",
        "import time\n",
        "import threading\n",
        "import subprocess\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "\n",
        "logs_folder, weights_folder, audios_folder = '/content/drive/MyDrive/model/logs', '/content/drive/MyDrive/model/weights', '/content/drive/MyDrive/audios'\n",
        "\n",
        "#@markdown **N·∫øu kh√¥ng t√≠ch v√†o √¥ n√†o th√¨ s·∫Ω ng·ª´ng k·∫øt n·ªëi ·ªü ph·∫ßn ƒë√≥**\n",
        "khoi_dong_sao_luu_mo_hinh = False #@param {\"type\":\"boolean\"}\n",
        "khoi_dong_sao_luu_am_thanh = False #@param {\"type\":\"boolean\"}\n",
        "#@markdown **ƒê·ªìng b·ªô l√† s·∫Ω ƒë·ªìng b·ªô c√°c th∆∞ m·ª•c sao l∆∞u l·∫°i, vi·ªác th∆∞ m·ª•c b·ªã x√≥a m·∫•t 1 t·ªáp th√¨ ·ªü th∆∞ m·ª•c sao l∆∞u t·ªáp ƒë√≥ c≈©ng s·∫Ω b·ªã x√≥a**\n",
        "dong_bo_thu_muc = False #@param {\"type\":\"boolean\"}\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "class Channel:\n",
        "    def __init__(self, source, destination, sync_deletions=False, every=60, exclude = None):\n",
        "        self.source = source\n",
        "        self.destination = destination\n",
        "        self.event = threading.Event()\n",
        "        self.syncing_thread = threading.Thread(target=self._sync, args=())\n",
        "        self.sync_deletions = sync_deletions\n",
        "        self.every = every\n",
        "\n",
        "        if not exclude: exclude = []\n",
        "        if isinstance(exclude, str): exclude = [exclude]\n",
        "\n",
        "        self.exclude = exclude\n",
        "        self.command = ['rsync', '-aP']\n",
        "\n",
        "    def alive(self):\n",
        "        if self.syncing_thread.is_alive(): return True\n",
        "        else: return False\n",
        "\n",
        "    def _sync(self):\n",
        "        command = self.command\n",
        "\n",
        "        for exclusion in self.exclude:\n",
        "            command.append(f'--exclude={exclusion}')\n",
        "\n",
        "        command.extend([f'{self.source}/', f'{self.destination}/'])\n",
        "\n",
        "        if self.sync_deletions: command.append('--delete')\n",
        "\n",
        "        while not self.event.is_set():\n",
        "            subprocess.run(command)\n",
        "            time.sleep(self.every)\n",
        "\n",
        "    def copy(self):\n",
        "        command = self.command\n",
        "\n",
        "        for exclusion in self.exclude:\n",
        "            command.append(f'--exclude={exclusion}')\n",
        "\n",
        "        command.extend([f'{self.source}/', f'{self.destination}/'])\n",
        "\n",
        "        if self.sync_deletions: command.append('--delete')\n",
        "        subprocess.run(command)\n",
        "\n",
        "        return True\n",
        "\n",
        "    def start(self):\n",
        "        if self.syncing_thread.is_alive():\n",
        "            self.event.set()\n",
        "            self.syncing_thread.join()\n",
        "\n",
        "        if self.event.is_set(): self.event.clear()\n",
        "        if self.syncing_thread._started.is_set(): self.syncing_thread = threading.Thread(target=self._sync, args=())\n",
        "\n",
        "        self.syncing_thread.start()\n",
        "        return self.alive()\n",
        "\n",
        "    def stop(self):\n",
        "        if self.alive():\n",
        "            self.event.set()\n",
        "            self.syncing_thread.join()\n",
        "\n",
        "            while self.alive():\n",
        "                if not self.alive(): break\n",
        "\n",
        "        return not self.alive()\n",
        "\n",
        "if not \"logs_backup\" in locals(): logs_backup = Channel(\"/content/Vietnamese_RVC/assets/logs\", logs_folder, sync_deletions=dong_bo_thu_muc, every=40, exclude=\"mute\")\n",
        "if not \"weights_backup\" in locals(): weights_backup = Channel(\"/content/Vietnamese_RVC/assets/weights\", weights_folder, sync_deletions=dong_bo_thu_muc, every=40)\n",
        "if not \"audio_backup\" in locals(): audio_backup = Channel(\"/content/Vietnamese_RVC/audios\", audios_folder, sync_deletions=dong_bo_thu_muc, every=40)\n",
        "\n",
        "logs_backup.stop(); weights_backup.stop(); audio_backup.stop()\n",
        "\n",
        "if os.path.exists('/content/drive/MyDrive'):\n",
        "    if khoi_dong_sao_luu_mo_hinh:\n",
        "        if not os.path.exists(logs_folder): os.makedirs(logs_folder)\n",
        "        if not os.path.exists(weights_folder): os.makedirs(weights_folder)\n",
        "\n",
        "        logs_backup.start(); weights_backup.start()\n",
        "    else: logs_backup.stop(); weights_backup.stop()\n",
        "\n",
        "    if khoi_dong_sao_luu_am_thanh:\n",
        "        if not os.path.exists(audios_folder): os.makedirs(audios_folder)\n",
        "        audio_backup.start()\n",
        "    else: audio_backup.stop()\n",
        "else:\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "    except Exception as e:\n",
        "        raise ValueError(f'ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh k·∫øt n·ªëi drive: {e}')\n",
        "\n",
        "    if khoi_dong_sao_luu_mo_hinh:\n",
        "        if not os.path.exists(logs_folder): os.makedirs(logs_folder)\n",
        "        if not os.path.exists(weights_folder): os.makedirs(weights_folder)\n",
        "\n",
        "        logs_backup.start(); weights_backup.start()\n",
        "    else: logs_backup.stop(); weights_backup.stop()\n",
        "\n",
        "    if khoi_dong_sao_luu_am_thanh:\n",
        "        if not os.path.exists(audios_folder): os.makedirs(audios_folder)\n",
        "        audio_backup.start()\n",
        "    else: audio_backup.stop()\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Ho√†n T·∫•t!\", button_style=\"success\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2VfuHALUuW_B"
      },
      "outputs": [],
      "source": [
        "#@title **‚ôªÔ∏è Kh·ªüi ƒë·ªông d·ªçn r√°c**\n",
        "import os\n",
        "import time\n",
        "import threading\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import auth, drive\n",
        "from IPython.display import clear_output\n",
        "\n",
        "try:\n",
        "    from googleapiclient.discovery import build\n",
        "except:\n",
        "    os.system(\"pip install google-api-python-client\")\n",
        "    from googleapiclient.discovery import build\n",
        "\n",
        "class Clean:\n",
        "    def __init__(self, every=60):\n",
        "        self.service = build('drive', 'v3')\n",
        "        self.every = every\n",
        "        self.trash_cleanup_thread = None\n",
        "\n",
        "    def delete(self):\n",
        "        page_token = None\n",
        "\n",
        "        while 1:\n",
        "            response = self.service.files().list(q=\"trashed=true\", spaces='drive', fields=\"nextPageToken, files(id, name)\", pageToken=page_token).execute()\n",
        "\n",
        "            for file in response.get('files', []):\n",
        "                if file['name'].startswith(\"G_\") and file['name'].endswith(\".pth\") or file['name'].startswith(\"D_\") and file['name'].endswith(\".pth\"):\n",
        "                    try:\n",
        "                        self.service.files().delete(fileId=file['id']).execute()\n",
        "                    except Exception as e:\n",
        "                        raise RuntimeError(e)\n",
        "\n",
        "            page_token = response.get('nextPageToken', None)\n",
        "            if page_token is None: break\n",
        "\n",
        "    def clean(self):\n",
        "        while 1:\n",
        "            self.delete()\n",
        "            time.sleep(self.every)\n",
        "\n",
        "    def start(self):\n",
        "        self.trash_cleanup_thread = threading.Thread(target=self.clean)\n",
        "        self.trash_cleanup_thread.daemon = True\n",
        "        self.trash_cleanup_thread.start()\n",
        "\n",
        "    def stop(self):\n",
        "        if self.trash_cleanup_thread: self.trash_cleanup_thread.join()\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "#@markdown **S·ª≠ d·ª•ng khi hu·∫•n luy·ªán s·∫Ω d·ªçn b·ªõt c√°c t·ªáp tin D, G trong th√πng r√°c google drive**\n",
        "khoi_dong_don_rac = False #@param {\"type\":\"boolean\"}\n",
        "\n",
        "if khoi_dong_don_rac:\n",
        "    if os.path.exists('/content/drive/MyDrive'):\n",
        "        auth.authenticate_user()\n",
        "    else:\n",
        "        try:\n",
        "            drive.mount('/content/drive')\n",
        "        except Exception as e:\n",
        "            raise ValueError(f'ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh k·∫øt n·ªëi drive: {e}')\n",
        "\n",
        "        auth.authenticate_user()\n",
        "    Clean(every=40).start()\n",
        "else: Clean().stop()\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Ho√†n T·∫•t!\", button_style=\"success\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xbcVxSFMDOV4"
      },
      "outputs": [],
      "source": [
        "#@title **T·∫£i d·ªØ li·ªáu sao l∆∞u t·ª´ drive üìÇ**\n",
        "import os\n",
        "import shutil\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "logs_folder, weights_folder, audios_folder ='/content/drive/MyDrive/model/logs', '/content/drive/MyDrive/model/weights', '/content/drive/MyDrive/audios'\n",
        "\n",
        "#@markdown **T·∫£i c√°c m√¥ h√¨nh hu·∫•n luy·ªán ƒë·ªÉ ti·∫øp t·ª•c hu·∫•n luy·ªán**\n",
        "tai_mo_hinh = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **T·∫£i c√°c √¢m thanh ƒë∆∞·ª£c sao l∆∞u ƒë·ªÉ ti·∫øp t·ª•c s·ª≠ d·ª•ng**\n",
        "tai_am_thanh = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "if os.path.exists(\"/content/drive/MyDrive\"):\n",
        "  if tai_mo_hinh:\n",
        "    if len(os.listdir(logs_folder)) < 1 or len(os.listdir(weights_folder)) < 1: print(\"Kh√¥ng t√¨m th·∫•y d·ªØ Li·ªáu\")\n",
        "    else:\n",
        "      if os.path.exists(\"/content/drive/MyDrive/model\"):\n",
        "        shutil.copytree(logs_folder, \"/content/Vietnamese_RVC/assets/logs\", dirs_exist_ok=True)\n",
        "        shutil.copytree(weights_folder, \"/content/Vietnamese_RVC/assets/weights\", dirs_exist_ok=True)\n",
        "\n",
        "        clear_output()\n",
        "      else: print(\"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu m√¥ h√¨nh\")\n",
        "  if tai_am_thanh:\n",
        "    if len(os.listdir(audios_folder)) < 1: print(\"Kh√¥ng t√¨m th·∫•y d·ªØ Li·ªáu\")\n",
        "    else:\n",
        "      if os.path.exists(\"/content/drive/MyDrive/audios\"):\n",
        "        shutil.copytree(audios_folder, \"/content/Vietnamese_RVC/audios\", dirs_exist_ok=True)\n",
        "        clear_output()\n",
        "      else: print(\"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu √¢m thanh\")\n",
        "else: print(\"Google drive kh√¥ng ƒë∆∞·ª£c k·∫øt n·ªëi\")\n",
        "\n",
        "display(Button(description=\"\\u2714 Ho√†n T·∫•t!\", button_style=\"success\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **T·∫£i Xu·ªëng üì©**"
      ],
      "metadata": {
        "id": "vk026-j6Cm_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **üîé T√¨m ki·∫øm m√¥ h√¨nh**\n",
        "import json\n",
        "import codecs\n",
        "import requests\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def fetch_models_data(search):\n",
        "    all_table_data = []\n",
        "    page = 1\n",
        "\n",
        "    while 1:\n",
        "        try:\n",
        "            response = requests.post(url=codecs.decode(\"uggcf://ibvpr-zbqryf.pbz/srgpu_qngn.cuc\", \"rot13\"), data={\"page\": page, \"search\": search})\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                table_data = response.json().get(\"table\", \"\")\n",
        "                if not table_data.strip(): break\n",
        "                all_table_data.append(table_data)\n",
        "                page += 1\n",
        "            else: raise Exception(f\"ƒê√£ x·∫£y ra l·ªói, M√£ l·ªói: {response.status_code}\")\n",
        "        except json.JSONDecodeError:\n",
        "            raise Exception(\"ƒê√£ x·∫£y ra l·ªói kh√¥ng th·ªÉ ph√¢n t√≠ch t·ª´ ph·∫£n h·ªìi.\")\n",
        "        except requests.RequestException as e:\n",
        "            raise Exception(f\"G·ª≠i y√™u c·∫ßu th·∫•t b·∫°i: {e}\")\n",
        "    return all_table_data\n",
        "\n",
        "def search_models(name):\n",
        "    if not name: raise NameError(\"Vui l√≤ng nh·∫≠p t√™n m√¥ h√¨nh\")\n",
        "    tables = fetch_models_data(name)\n",
        "\n",
        "    if len(tables) == 0: print(\"Kh√¥ng t√¨m th·∫•y...\")\n",
        "    else:\n",
        "        for table in tables:\n",
        "            for row in BeautifulSoup(table, \"html.parser\").select(\"tr\"):\n",
        "                name_tag, url_tag = row.find(\"a\", {\"class\": \"fs-5\"}), row.find(\"a\", {\"class\": \"btn btn-sm fw-bold btn-light ms-0 p-1 ps-2 pe-2\"})\n",
        "                if name_tag and url_tag:\n",
        "                    name = name_tag.text.replace(\".onnx\", \"\").replace(\".pth\", \"\").replace(\".index\", \"\").replace(\".zip\", \"\").replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").replace('\"', \"\").replace(\"'\", \"\").replace(\"|\", \"_\").replace(\"-_-\", \"_\").replace(\"_-_\", \"_\").replace(\"-\", \"_\").replace(\"---\", \"_\").replace(\"___\", \"_\").strip()\n",
        "                    url = url_tag[\"href\"].replace(\"https://easyaivoice.com/run?url=\", \"\")\n",
        "                    if \"huggingface\" in url: print(f\"{name}: {url}\")\n",
        "\n",
        "#@markdown **T√¨m ki·∫øm li√™n k·∫øt m√¥ h√¨nh**\n",
        "ten_mo_hinh = \"\" # @param {\"type\":\"string\",\"placeholder\":\"T√™n c·ªßa m√¥ h√¨nh c·∫ßn t√¨m\"}\n",
        "\n",
        "search_models(ten_mo_hinh)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "49Mc9pnY9kdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **üì© T·∫£i xu·ªëng m√¥ h√¨nh**\n",
        "from ipywidgets import Button\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "#@markdown **H·ªó tr·ª£ c√°c li√™n k·∫øt ƒë·∫øn t·ª´ huggingface.co / drive.google.com / mega.nz / mediafire.com**\n",
        "\n",
        "ten_cua_mo_hinh = \"\" # @param {\"type\":\"string\",\"placeholder\":\"T√™n m√¥ h√¨nh\"}\n",
        "lien_ket_mo_hinh = \"\" # @param {\"type\":\"string\",\"placeholder\":\"https://huggingface.co//...\"}\n",
        "\n",
        "if not lien_ket_mo_hinh:\n",
        "    uploaded = files.upload()\n",
        "    args = f'from main.app.core.process import save_drop_model; save_drop_model(\\\\\"{list(uploaded.keys())[0]}\\\\\")'\n",
        "    !python3 -c \"$args\"\n",
        "else:\n",
        "    args = f'from main.app.core.downloads import download_model; download_model(\\\\\"{lien_ket_mo_hinh}\\\\\", \\\\\"{ten_cua_mo_hinh}\\\\\")'\n",
        "    !python3 -c \"$args\"\n",
        "\n",
        "clear_output()\n",
        "display(Button(description=\"\\u2714 Ho√†n t·∫•t!!\", button_style=\"success\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FYEQawebCzZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üßæ **T·∫£i xu·ªëng m√¥ h√¨nh hu·∫•n luy·ªán tr∆∞·ªõc**\n",
        "#@markdown **Ch·∫°y √¥ ƒë·ªÉ c√≥ th·ªÉ l·ª±a ch·ªçn m√¥ h√¨nh v√† t·ªëc ƒë·ªô l·∫•y m·∫´u c·ªßa m√¥ h√¨nh ƒë·ªÉ ti·∫øn h√†nh t·∫£i x·ªëng**\n",
        "import os\n",
        "import shutil\n",
        "import codecs\n",
        "import requests\n",
        "\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "from main.tools import huggingface\n",
        "\n",
        "def fetch_pretrained_data():\n",
        "    response = requests.get(codecs.decode(\"uggcf://uhttvatsnpr.pb/NauC/Ivrganzrfr-EIP-Cebwrpg/erfbyir/znva/wfba/phfgbz_cergenvarq.wfba\", \"rot13\"))\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "model_list = list(fetch_pretrained_data().keys())\n",
        "\n",
        "for m in model_list:\n",
        "    print(f\"{model_list.index(m)}. {m}\")\n",
        "\n",
        "while 1:\n",
        "    try:\n",
        "        model_index = int(input(\"Nh·∫≠p s·ªë th·ª© t·ª± c·ªßa m√¥ h√¨nh: \"))\n",
        "        if 0 <= model_index < len(model_list):\n",
        "            selected_model = model_list[model_index]\n",
        "            clear_output()\n",
        "            print(f\"B·∫°n ƒë√£ ch·ªçn m√¥ h√¨nh: {selected_model}\")\n",
        "            break\n",
        "        else: print(\"S·ªë th·ª© t·ª± kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "    except ValueError:\n",
        "        print(\"Vui l√≤ng nh·∫≠p m·ªôt s·ªë nguy√™n.\")\n",
        "    except IndexError:\n",
        "        print(\"S·ªë th·ª© t·ª± v∆∞·ª£t qu√° ph·∫°m vi. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "\n",
        "model_sr_list = list(fetch_pretrained_data()[selected_model].keys())\n",
        "\n",
        "if len(model_sr_list) == 1: selected_sr = model_sr_list[0]\n",
        "else:\n",
        "    for sr in model_sr_list:\n",
        "        print(f\"{model_sr_list.index(sr)}. {sr}\")\n",
        "\n",
        "    while 1:\n",
        "        try:\n",
        "            model_sr_index = int(input(\"Nh·∫≠p s·ªë th·ª© t·ª± c·ªßa t·ªëc ƒë·ªô l·∫•y m·∫´u: \"))\n",
        "            if 0 <= model_sr_index < len(model_sr_list):\n",
        "                selected_sr = model_sr_list[model_sr_index]\n",
        "                print(f\"B·∫°n ƒë√£ ch·ªçn t·ªëc ƒë·ªô l·∫•y m·∫´u: {selected_sr}\")\n",
        "                clear_output()\n",
        "                break\n",
        "            else: print(\"S·ªë th·ª© t·ª± kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "        except ValueError:\n",
        "            print(\"Vui l√≤ng nh·∫≠p m·ªôt s·ªë nguy√™n.\")\n",
        "        except IndexError:\n",
        "            print(\"S·ªë th·ª© t·ª± v∆∞·ª£t qu√° ph·∫°m vi. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "\n",
        "paths = fetch_pretrained_data()[selected_model][selected_sr]\n",
        "pretraineds_custom_path = os.path.join(\"assets\", \"models\", \"pretrained_custom\")\n",
        "\n",
        "if not os.path.exists(pretraineds_custom_path): os.makedirs(pretraineds_custom_path, exist_ok=True)\n",
        "url = codecs.decode(\"uggcf://uhttvatsnpr.pb/NauC/Ivrganzrfr-EIP-Cebwrpg/erfbyir/znva/cergenvarq_phfgbz/\", \"rot13\") + paths\n",
        "\n",
        "file = huggingface.HF_download_file(url.replace(\"/blob/\", \"/resolve/\").replace(\"?download=true\", \"\").strip(), os.path.join(pretraineds_custom_path, paths))\n",
        "if file.endswith(\".zip\"):\n",
        "    shutil.unpack_archive(file, pretraineds_custom_path)\n",
        "    os.remove(file)\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Ho√†n t·∫•t!\", button_style=\"success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1a52Dg5VHqFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üì• **T·∫£i xu·ªëng m√¥ h√¨nh hu·∫•n luy·ªán tr∆∞·ªõc**\n",
        "import os\n",
        "import json\n",
        "\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "#@markdown **Nh·∫≠p ƒë∆∞·ªùng d·∫´n hu·∫•n luy·ªán tr∆∞·ªõc ƒë·ªÉ ti·∫øn h√†nh t·∫£i xu·ªëng hu·∫•n luy·ªán tr∆∞·ªõc**\n",
        "huan_luyen_truoc_D = \"\" # @param {\"type\":\"string\",\"placeholder\":\"https://huggingface.co//...\"}\n",
        "huan_luyen_truoc_G = \"\" # @param {\"type\":\"string\",\"placeholder\":\"https://huggingface.co//...\"}\n",
        "\n",
        "download_url = \"T·∫£i t·ª´ ƒë∆∞·ªùng d·∫´n li√™n k·∫øt\" if json.load(open(os.path.join(\"main\", \"configs\", \"config.json\"), \"r\")).get(\"language\", \"vi-VN\") == \"vi-VN\" else \"Download from the link\"\n",
        "\n",
        "args = f'from main.app.core.downloads import download_pretrained_model; download_pretrained_model(\\\\\"{download_url}\\\\\", \\\\\"{huan_luyen_truoc_D}\\\\\", \\\\\"{huan_luyen_truoc_G}\\\\\")'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Ho√†n t·∫•t!\", button_style=\"success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QuFUjo-zIDWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Suy Lu·∫≠n üîä**"
      ],
      "metadata": {
        "id": "QxkQHawDuqDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **T√°ch Nh·∫°c**\n",
        "import os\n",
        "import re\n",
        "import yt_dlp\n",
        "import shutil\n",
        "import warnings\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import files\n",
        "from urllib.parse import urlparse\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "def download_url(url):\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.filterwarnings(\"ignore\")\n",
        "        ydl_opts = {\"format\": \"bestaudio/best\", \"postprocessors\": [{\"key\": \"FFmpegExtractAudio\", \"preferredcodec\": \"wav\", \"preferredquality\": \"192\"}], \"quiet\": True, \"no_warnings\": True, \"noplaylist\": True, \"verbose\": False}\n",
        "\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            audio_output = os.path.join(\"audios\", re.sub(r'\\s+', '-', re.sub(r'[^\\w\\s\\u4e00-\\u9fff\\uac00-\\ud7af\\u0400-\\u04FF\\u1100-\\u11FF]', '', ydl.extract_info(url, download=False).get('title', 'video')).strip()))\n",
        "            if os.path.exists(audio_output): shutil.rmtree(audio_output, ignore_errors=True)\n",
        "\n",
        "            ydl_opts['outtmpl'] = audio_output\n",
        "\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            audio_output += \".wav\"\n",
        "            ydl.download([url])\n",
        "\n",
        "        return audio_output\n",
        "\n",
        "def is_url(path):\n",
        "    try:\n",
        "        result = urlparse(path)\n",
        "        return all([result.scheme, result.netloc])\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "#@markdown **C√°c t√πy ch·ªçn v·ªÅ t√°ch b√® v√† t√°ch vang khi t√°ch nh·∫°c**\n",
        "tach_be = False # @param {\"type\":\"boolean\"}\n",
        "tach_vang = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **ƒê∆∞·ªùng d·∫´n ƒë·∫ßu v√†o (c√≥ th·ªÉ l√† ƒë∆∞·ªùng d·∫´n li√™n k·∫øt ho·∫∑c ƒë∆∞·ªùng d·∫´n t·ªáp) v√† ƒë·ªãnh d·∫°ng ƒë·∫ßu ra t·ªáp**\n",
        "duong_dan = \"\" #@param {\"type\":\"string\", \"placeholder\":\"Nh·∫≠p ƒë∆∞·ªùng d·∫´n ƒë·∫øn t·ªáp √¢m thanh ho·∫∑c ƒë∆∞·ªùng d·∫´n li√™n k·∫øt √¢m thanh\"}\n",
        "dinh_dang_am_thanh = \"wav\" #@param [\"wav\", \"mp3\", \"flac\", \"ogg\", \"opus\", \"m4a\", \"mp4\", \"aac\", \"alac\", \"wma\", \"aiff\", \"webm\", \"ac3\"]\n",
        "#@markdown **C√°c t√πy ch·ªçn v·ªÅ m√¥ h√¨nh t√°ch nh·∫°c, m·ª©c ch·ªìng ch√©o v√† k√≠ch th∆∞·ªõc ph√¢n ƒëo·∫°n**\n",
        "mo_hinh_tach_nhac = \"Voc_FT\" #@param [\"Main_340\", \"Main_390\", \"Main_406\", \"Main_427\", \"Main_438\", \"Inst_full_292\", \"Inst_HQ_1\", \"Inst_HQ_2\", \"Inst_HQ_3\", \"Inst_HQ_4\", \"Inst_HQ_5\", \"Kim_Vocal_1\", \"Kim_Vocal_2\", \"Kim_Inst\", \"Inst_187_beta\", \"Inst_82_beta\", \"Inst_90_beta\", \"Voc_FT\", \"Crowd_HQ\", \"Inst_1\", \"Inst_2\", \"Inst_3\", \"MDXNET_1_9703\", \"MDXNET_2_9682\", \"MDXNET_3_9662\", \"Inst_Main\", \"MDXNET_Main\", \"MDXNET_9482\", \"HT-Normal\", \"HT-Tuned\", \"HD_MMI\",  \"HT_6S\"]\n",
        "chong_cheo = \"0.25\" # @param [\"0.25\", \"0.5\", \"0.75\", \"0.99\"]\n",
        "kich_thuoc_phan_doan = 256 # @param {\"type\":\"slider\",\"min\":32,\"max\":2048,\"step\":8}\n",
        "\n",
        "if not duong_dan:\n",
        "    uploaded = files.upload()\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    input_path = os.path.join(\"audios\", os.path.basename(filename).replace(' ', '_').replace('(', '').replace(')', '').replace('{', '').replace('}', ''))\n",
        "    shutil.move(filename, input_path)\n",
        "else: input_path = download_url(duong_dan) if is_url(duong_dan) else duong_dan\n",
        "\n",
        "args = f'from main.app.core.separate import separator_music; separator_music(\\\\\"{input_path}\\\\\", \\\\\"audios\\\\\", \\\\\"{dinh_dang_am_thanh}\\\\\", 2, {kich_thuoc_phan_doan}, {chong_cheo}, False, 0.7, True, \\\\\"{mo_hinh_tach_nhac}\\\\\", \\\\\"Version-2\\\\\", {tach_be}, {tach_vang}, {tach_be and tach_vang}, 1024, 1, 48000)'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "clear_output()\n",
        "print(f\"T·ªáp ƒë·∫ßu ra c·ªßa b·∫°n n·∫±m trong th∆∞ m·ª•c: /content/Vietnamese_RVC/audios/{os.path.splitext(os.path.basename(input_path))[0]}\")\n",
        "display(Button(description=\"\\u2714 Ho√†n T·∫•t!\", button_style=\"success\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1R7mSj8avRF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üéµ **Chuy·ªÉn ƒê·ªïi √Çm Thanh** üéµ\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "def convert_audio(clean, autotune, use_audio, use_original, convert_backing, not_merge_backing, merge_instrument, pitch, clean_strength, model, index, index_rate, input, output, format, method, hybrid_method, hop_length, embedders, custom_embedders, resample_sr, filter_radius, volume_envelope, protect, split_audio, f0_autotune_strength, input_audio_name, checkpointing, onnx_f0_mode, formant_shifting, formant_qfrency, formant_timbre, f0_file, embedders_mode, proposal_pitch, proposal_pitch_threshold):\n",
        "    args = f'from main.app.core.inference import convert_audio; convert_audio({clean}, {autotune}, {use_audio}, {use_original}, {convert_backing}, {not_merge_backing}, {merge_instrument}, {pitch}, {clean_strength}, \\\\\"{model}\\\\\", \\\\\"{index}\\\\\", {index_rate}, \\\\\"{input}\\\\\", \\\\\"{output}\\\\\", \\\\\"{format}\\\\\", \\\\\"{method}\\\\\", \\\\\"{hybrid_method}\\\\\", {hop_length}, \\\\\"{embedders}\\\\\", \\\\\"{custom_embedders}\\\\\", {resample_sr}, {filter_radius}, {volume_envelope}, {protect}, {split_audio}, {f0_autotune_strength}, \\\\\"{input_audio_name}\\\\\", {checkpointing}, {onnx_f0_mode}, {formant_shifting}, {formant_qfrency}, {formant_timbre}, \\\\\"{f0_file}\\\\\", \\\\\"{embedders_mode}\\\\\", {proposal_pitch}, {proposal_pitch_threshold})'\n",
        "    !python3 -c \"$args\"\n",
        "\n",
        "def get_audio_file(output_audio, label):\n",
        "    matching_files = [f for f in os.listdir(output_audio) if label in f]\n",
        "\n",
        "    if not matching_files: raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y nh·∫°c n·ªÅn!\")\n",
        "    return os.path.join(output_audio, matching_files[0])\n",
        "\n",
        "def convert_selection(clean, autotune, use_audio, use_original, convert_backing, not_merge_backing, merge_instrument, pitch, clean_strength, model, index, index_rate, input, output, format, method, hybrid_method, hop_length, embedders, custom_embedders, resample_sr, filter_radius, volume_envelope, protect, split_audio, f0_autotune_strength, checkpointing, onnx_f0_mode, formant_shifting, formant_qfrency, formant_timbre, f0_file, embedders_mode, proposal_pitch, proposal_pitch_threshold):\n",
        "    if use_audio:\n",
        "        choice = [f for f in os.listdir(\"audios\") if os.path.isdir(os.path.join(\"audios\", f))]\n",
        "\n",
        "        if len(choice) == 0: raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y b·∫£n t√°ch nh·∫°c n√†o!\")\n",
        "        elif len(choice) == 1:\n",
        "            choice_audio = choice[0]\n",
        "            convert_audio(clean, autotune, use_audio, use_original, convert_backing, not_merge_backing, False, pitch, clean_strength, model, index, index_rate, None, None, format, method, hybrid_method, hop_length, embedders, custom_embedders, resample_sr, filter_radius, volume_envelope, protect, split_audio, f0_autotune_strength, choice_audio, checkpointing, onnx_f0_mode, formant_shifting, formant_qfrency, formant_timbre, f0_file, embedders_mode, proposal_pitch, proposal_pitch_threshold)\n",
        "        else:\n",
        "            print(\"ƒê√£ t√¨m th·∫•y nhi·ªÅu h∆°n 1 b·∫£n t√°ch nh·∫°c, vui l√≤ng ch·ªçn b√†i ƒë·ªÉ ti·∫øn h√†nh chuy·ªÉn ƒë·ªïi!\")\n",
        "            for c in choice:\n",
        "                print(f\"{choice.index(c)}. {c}\")\n",
        "\n",
        "            while 1:\n",
        "                try:\n",
        "                    choice_select = int(input(\"H√£y nh·∫≠p s·ªë th·ª© t·ª± c·ªßa b·∫£n t√°ch: \"))\n",
        "\n",
        "                    if 0 <= choice_select < len(choice):\n",
        "                        choice_audio = choice[choice_select]\n",
        "                        print(f\"B·∫°n ƒë√£ ch·ªçn b·∫£n t√°ch: {choice_audio}\")\n",
        "                        break\n",
        "                    else: print(\"S·ªë th·ª© t·ª± kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "                except ValueError:\n",
        "                    print(\"Vui l√≤ng nh·∫≠p m·ªôt s·ªë nguy√™n.\")\n",
        "                except IndexError:\n",
        "                    print(\"S·ªë th·ª© t·ª± v∆∞·ª£t qu√° ph·∫°m vi. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "            convert_audio(clean, autotune, use_audio, use_original, convert_backing, not_merge_backing, False, pitch, clean_strength, model, index, index_rate, None, None, format, method, hybrid_method, hop_length, embedders, custom_embedders, resample_sr, filter_radius, volume_envelope, protect, split_audio, f0_autotune_strength, choice_audio, checkpointing, onnx_f0_mode, formant_shifting, formant_qfrency, formant_timbre, f0_file, embedders_mode, proposal_pitch, proposal_pitch_threshold)\n",
        "    else: convert_audio(clean, autotune, use_audio, use_original, convert_backing, not_merge_backing, False, pitch, clean_strength, model, index, index_rate, input, output, format, method, hybrid_method, hop_length, embedders, custom_embedders, resample_sr, filter_radius, volume_envelope, protect, split_audio, f0_autotune_strength, None, checkpointing, onnx_f0_mode, formant_shifting, formant_qfrency, formant_timbre, f0_file, embedders_mode, proposal_pitch, proposal_pitch_threshold)\n",
        "\n",
        "    if use_audio: output_path = f\"/content/Vietnamese_RVC/audios/{choice_audio}/Vocals+Backing.{format}\" if convert_backing else f\"/content/Vietnamese_RVC/audios/{choice_audio}/Convert_Vocals.{format}\"\n",
        "    return audio_effects(output_path, os.path.join(\"audios\", choice_audio, f\"Vocals+Instruments.{format}\") if merge_instrument else os.path.join(\"audios\", choice_audio, f\"{os.path.splitext(os.path.basename(output_path))[0]}_Effects.{format}\"), format, merge_instrument, get_audio_file(os.path.join(\"audios\", choice_audio), \"Instruments.\")) if use_audio else f\"/content/Vietnamese_RVC/audios/output.{format}\"\n",
        "\n",
        "def audio_effects(input_path, output_path, export_format, merge_instrument, audio_combination_input):\n",
        "    if not input_path or not os.path.exists(input_path) or os.path.isdir(input_path): raise FileNotFoundError(\"ƒê∆∞·ªùng d·∫´n t·ªáp ƒë·∫ßu v√†o kh√¥ng h·ª£p l·ªá!\")\n",
        "    if not output_path: raise ValueError(\"ƒê∆∞·ªùng d·∫´n t·ªáp ƒë·∫ßu ra kh√¥ng h·ª£p l·ªá!\")\n",
        "    output_dir = os.path.dirname(output_path) or output_path\n",
        "\n",
        "    if not os.path.exists(output_dir): os.makedirs(output_dir, exist_ok=True)\n",
        "    if os.path.exists(output_path): os.remove(output_path)\n",
        "\n",
        "    !python main/inference/audio_effects.py --input_path $input_path --output_path $output_path --reverb_room_size 0.15 --reverb_damping 0.7 --reverb_wet_level 0.2 --reverb_dry_level 0.8 --reverb_width 1.0 --reverb_freeze_mode False --export_format $export_format --reverb True --audio_combination $merge_instrument --audio_combination_input $audio_combination_input\n",
        "    return output_path\n",
        "\n",
        "def get_index(model):\n",
        "    return next((f for f in [os.path.join(root, name) for root, _, files in os.walk(os.path.join(\"assets\", \"logs\"), topdown=False) for name in files if name.endswith(\".index\") and \"trained\" not in name] if model.split(\".\")[0] in f), \"\")\n",
        "\n",
        "#@markdown **C√°c t√πy ch·ªçn s·ª≠ d·ª•ng c√°c b·∫£n ƒë∆∞·ª£c t√°ch nh·∫°c ƒë∆∞·ª£c t√°ch tr∆∞·ªõc ƒë√≥**\n",
        "su_dung_giong_goc = False #@param {\"type\":\"boolean\"}\n",
        "chuyen_doi_giong_be = False #@param {\"type\":\"boolean\"}\n",
        "ket_hop_nhac_nen = False #@param {\"type\":\"boolean\"}\n",
        "#@markdown **C√°c t√πy ch·ªçn v·ªÅ m√¥ h√¨nh nh∆∞: Cao ƒë·ªô v√† Ch·ªâ m·ª•c**\n",
        "ten_mo_hinh = \"\" #@param {\"type\":\"string\",\"placeholder\":\"T√™n m√¥ h√¨nh\"}\n",
        "cao_do = 0 #@param {\"type\":\"slider\",\"min\":-20,\"max\":20,\"step\":1}\n",
        "anh_huong_cua_chi_muc = 0.5 #@param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.01}\n",
        "#@markdown **T√πy ch·ªçn ƒë·∫ßu v√†o v√† ƒë·ªãnh d·∫°ng ƒë·∫ßu ra c·ªßa t·ªáp**\n",
        "duong_dan_dau_vao = \"\" #@param {\"type\":\"string\",\"placeholder\":\"ƒê∆∞·ªùng d·∫´n t·ªáp √¢m thanh\"}\n",
        "dinh_dang_tep = \"wav\" #@param [\"wav\", \"mp3\", \"flac\", \"ogg\", \"opus\", \"m4a\", \"mp4\", \"aac\", \"alac\", \"wma\", \"aiff\", \"webm\", \"ac3\"]\n",
        "#@markdown **C√°c t√πy ch·ªçn v·ªÅ tr√≠ch xu·∫•t d·ªØ li·ªáu, hop length, b·∫£o v·ªá √¢m thanh v√† t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh tr√≠ch xu·∫•t ƒë·ªÉ ƒë·∫°t ch·∫•t l∆∞·ª£ng cao h∆°n**\n",
        "phuong_phap_trich_xuat = \"rmvpe\" #@param [\"mangio-crepe-full\", \"crepe-full\", \"fcpe\", \"rmvpe\", \"harvest\", \"pyin\"]\n",
        "hop_length = 64 # @param {\"type\":\"slider\",\"min\":64,\"max\":512,\"step\":1}\n",
        "bao_ve_phu_am = 0.5 #@param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.1}\n",
        "#@markdown **T√πy ch·ªçn v·ªÅ c·∫Øt √¢m thanh**\n",
        "cat_am_thanh = False #@param {\"type\":\"boolean\"}\n",
        "\n",
        "if ten_mo_hinh:\n",
        "    if not ten_mo_hinh.endswith((\".pth\", \".onnx\")): ten_mo_hinh = ten_mo_hinh + \".pth\"\n",
        "    model_path = os.path.join(\"assets\", \"weights\", ten_mo_hinh)\n",
        "    index_path = get_index(ten_mo_hinh.split(\"_\")[0])\n",
        "else:\n",
        "    model_name = sorted(list(model for model in os.listdir(os.path.join(\"assets\", \"weights\")) if model.endswith((\".pth\", \".onnx\")) and not model.startswith(\"G_\") and not model.startswith(\"D_\")))\n",
        "    indexpath = sorted([os.path.join(root, name) for root, _, files in os.walk(os.path.join(\"assets\", \"logs\"), topdown=False) for name in files if name.endswith(\".index\")])\n",
        "\n",
        "    if len(model_name) < 1: raise ValueError(\"Vui l√≤ng cung c·∫•p m√¥ h√¨nh ƒë·ªÉ ti·∫øn h√†nh chuy·ªÉn ƒë·ªïi!\")\n",
        "    elif len(model_name) == 1:\n",
        "        model_path = os.path.join(\"assets\", \"weights\", model_name[0])\n",
        "        index_path = get_index(os.path.basename(model_name[0])[0])\n",
        "    else:\n",
        "        print(\"T√¨m th·∫•y nhi·ªÅu h∆°n 1 m√¥ h√¨nh, vui l√≤ng nh·∫≠p s·ªë th·ª© t·ª± c·ªßa m√¥ h√¨nh ƒë·ªÉ ti·∫øn h√†nh chuy·ªÉn ƒë·ªïi!\")\n",
        "        for m in model_name:\n",
        "            print(f\"{model_name.index(m)}. {m}\")\n",
        "\n",
        "        while 1:\n",
        "            try:\n",
        "                model_index = int(input(\"Nh·∫≠p s·ªë th·ª© t·ª± c·ªßa m√¥ h√¨nh: \"))\n",
        "                if model_index < len(model_name):\n",
        "                    selected_model = model_name[model_index]\n",
        "                    print(f\"B·∫°n ƒë√£ ch·ªçn m√¥ h√¨nh: {selected_model}\")\n",
        "                    break\n",
        "                else: print(\"S·ªë th·ª© t·ª± kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "            except ValueError:\n",
        "                print(\"Vui l√≤ng nh·∫≠p m·ªôt s·ªë nguy√™n.\")\n",
        "            except IndexError:\n",
        "                print(\"S·ªë th·ª© t·ª± v∆∞·ª£t qu√° ph·∫°m vi. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "\n",
        "        model_path = os.path.join(\"assets\", \"weights\", selected_model)\n",
        "        index_path = get_index(os.path.basename(selected_model).split(\"_\")[0])\n",
        "\n",
        "if not index_path: print(\"Kh√¥ng t√¨m th·∫•y ch·ªâ m·ª•c!\")\n",
        "\n",
        "if not duong_dan_dau_vao and not (su_dung_giong_goc or chuyen_doi_giong_be or ket_hop_nhac_nen):\n",
        "    uploaded = files.upload()\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    input_path = os.path.join(\"audios\", os.path.basename(filename).replace(' ', '_').replace('(', '').replace(')', '').replace('{', '').replace('}', ''))\n",
        "    shutil.move(filename, input_path)\n",
        "else: input_path = duong_dan_dau_vao\n",
        "\n",
        "output_files = convert_selection(False, False, (su_dung_giong_goc or chuyen_doi_giong_be or ket_hop_nhac_nen), su_dung_giong_goc, chuyen_doi_giong_be, False, ket_hop_nhac_nen, cao_do, 0.7, model_path, index_path, anh_huong_cua_chi_muc, input_path, os.path.join(\"audios\", \"output.wav\"), dinh_dang_tep, phuong_phap_trich_xuat, None, hop_length, \"hubert_base\", None, 0, 3, 1, bao_ve_phu_am, cat_am_thanh, 1, False, False, False, 0, 0, \"\", \"fairseq\", False, 255.0)\n",
        "clear_output()\n",
        "\n",
        "print(f\"T·ªáp ƒë·∫ßu ra c·ªßa b·∫°n l√†: {output_files}\")\n",
        "display(Button(description=\"\\u2714 Ho√†n T·∫•t!\", button_style=\"success\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aQ8LqaeGLDYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üéµ **Chuy·ªÉn ƒê·ªïi VƒÉn B·∫£n** üéµ\n",
        "import os\n",
        "import zipfile\n",
        "import xml.etree.ElementTree\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "def get_index(model):\n",
        "    return next((f for f in [os.path.join(root, name) for root, _, files in os.walk(os.path.join(\"assets\", \"logs\"), topdown=False) for name in files if name.endswith(\".index\") and \"trained\" not in name] if model.split(\".\")[0] in f), \"\")\n",
        "\n",
        "def read_docx_text(path):\n",
        "    with zipfile.ZipFile(path) as docx:\n",
        "        with docx.open(\"word/document.xml\") as document_xml:\n",
        "            xml_content = document_xml.read()\n",
        "\n",
        "    WORD_NAMESPACE = '{http://schemas.openxmlformats.org/wordprocessingml/2006/main}'\n",
        "\n",
        "    paragraphs = []\n",
        "    for paragraph in xml.etree.ElementTree.XML(xml_content).iter(WORD_NAMESPACE + 'p'):\n",
        "        texts = [node.text for node in paragraph.iter(WORD_NAMESPACE + 't') if node.text]\n",
        "        if texts: paragraphs.append(''.join(texts))\n",
        "\n",
        "    return '\\n'.join(paragraphs)\n",
        "\n",
        "def process_input(file_path):\n",
        "    if file_path.endswith(\".srt\"): file_contents = \"\"\n",
        "    elif file_path.endswith(\".docx\"): file_contents = read_docx_text(file_path)\n",
        "    else:\n",
        "        try:\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "                file_contents = file.read()\n",
        "        except Exception as e:\n",
        "            file_contents = \"\"\n",
        "\n",
        "    return file_contents\n",
        "\n",
        "#@markdown **VƒÉn b·∫£n c·∫ßn ƒë·ªçc v√† c√°c t√πy ch·ªçn v·ªÅ gi·ªçng ƒë·ªçc v√† t·ªëc ƒë·ªô ƒë·ªçc**\n",
        "van_ban = \"\" # @param {\"type\":\"string\", \"placeholder\":\"VƒÉn b·∫£n c·∫ßn ƒë·ªçc\"}\n",
        "giong_noi = \"vi-VN-NamMinhNeural\" # @param [\"af-ZA-AdriNeural\", \"af-ZA-WillemNeural\", \"sq-AL-AnilaNeural\", \"sq-AL-IlirNeural\", \"am-ET-AmehaNeural\", \"am-ET-MekdesNeural\", \"ar-DZ-AminaNeural\", \"ar-DZ-IsmaelNeural\", \"ar-BH-AliNeural\", \"ar-BH-LailaNeural\", \"ar-EG-SalmaNeural\", \"ar-EG-ShakirNeural\", \"ar-IQ-BasselNeural\", \"ar-IQ-RanaNeural\", \"ar-JO-SanaNeural\", \"ar-JO-TaimNeural\", \"ar-KW-FahedNeural\", \"ar-KW-NouraNeural\", \"ar-LB-LaylaNeural\", \"ar-LB-RamiNeural\", \"ar-LY-ImanNeural\", \"ar-LY-OmarNeural\", \"ar-MA-JamalNeural\", \"ar-MA-MounaNeural\", \"ar-OM-AbdullahNeural\", \"ar-OM-AyshaNeural\", \"ar-QA-AmalNeural\", \"ar-QA-MoazNeural\", \"ar-SA-HamedNeural\", \"ar-SA-ZariyahNeural\", \"ar-SY-AmanyNeural\", \"ar-SY-LaithNeural\", \"ar-TN-HediNeural\", \"ar-TN-ReemNeural\", \"ar-AE-FatimaNeural\", \"ar-AE-HamdanNeural\", \"ar-YE-MaryamNeural\", \"ar-YE-SalehNeural\", \"az-AZ-BabekNeural\", \"az-AZ-BanuNeural\", \"bn-BD-NabanitaNeural\", \"bn-BD-PradeepNeural\", \"bn-IN-BashkarNeural\", \"bn-IN-TanishaaNeural\", \"bs-BA-GoranNeural\", \"bs-BA-VesnaNeural\", \"bg-BG-BorislavNeural\", \"bg-BG-KalinaNeural\", \"my-MM-NilarNeural\", \"my-MM-ThihaNeural\", \"ca-ES-EnricNeural\", \"ca-ES-JoanaNeural\", \"zh-HK-HiuGaaiNeural\", \"zh-HK-HiuMaanNeural\", \"zh-HK-WanLungNeural\", \"zh-CN-XiaoxiaoNeural\", \"zh-CN-XiaoyiNeural\", \"zh-CN-YunjianNeural\", \"zh-CN-YunxiNeural\", \"zh-CN-YunxiaNeural\", \"zh-CN-YunyangNeural\", \"zh-CN-liaoning-XiaobeiNeural\", \"zh-TW-HsiaoChenNeural\", \"zh-TW-YunJheNeural\", \"zh-TW-HsiaoYuNeural\", \"zh-CN-shaanxi-XiaoniNeural\", \"hr-HR-GabrijelaNeural\", \"hr-HR-SreckoNeural\", \"cs-CZ-AntoninNeural\", \"cs-CZ-VlastaNeural\", \"da-DK-ChristelNeural\", \"da-DK-JeppeNeural\", \"nl-BE-ArnaudNeural\", \"nl-BE-DenaNeural\", \"nl-NL-ColetteNeural\", \"nl-NL-FennaNeural\", \"nl-NL-MaartenNeural\", \"en-AU-NatashaNeural\", \"en-AU-WilliamNeural\", \"en-CA-ClaraNeural\", \"en-CA-LiamNeural\", \"en-HK-SamNeural\", \"en-HK-YanNeural\", \"en-IN-NeerjaExpressiveNeural\", \"en-IN-NeerjaNeural\", \"en-IN-PrabhatNeural\", \"en-IE-ConnorNeural\", \"en-IE-EmilyNeural\", \"en-KE-AsiliaNeural\", \"en-KE-ChilembaNeural\", \"en-NZ-MitchellNeural\", \"en-NZ-MollyNeural\", \"en-NG-AbeoNeural\", \"en-NG-EzinneNeural\", \"en-PH-JamesNeural\", \"en-PH-RosaNeural\", \"en-SG-LunaNeural\", \"en-SG-WayneNeural\", \"en-ZA-LeahNeural\", \"en-ZA-LukeNeural\", \"en-TZ-ElimuNeural\", \"en-TZ-ImaniNeural\", \"en-GB-LibbyNeural\", \"en-GB-MaisieNeural\", \"en-GB-RyanNeural\", \"en-GB-SoniaNeural\", \"en-GB-ThomasNeural\", \"en-US-AvaMultilingualNeural\", \"en-US-AndrewMultilingualNeural\", \"en-US-EmmaMultilingualNeural\", \"en-US-BrianMultilingualNeural\", \"en-US-AvaNeural\", \"en-US-AndrewNeural\", \"en-US-EmmaNeural\", \"en-US-BrianNeural\", \"en-US-AnaNeural\", \"en-US-AriaNeural\", \"en-US-ChristopherNeural\", \"en-US-EricNeural\", \"en-US-GuyNeural\", \"en-US-JennyNeural\", \"en-US-MichelleNeural\", \"en-US-RogerNeural\", \"en-US-SteffanNeural\", \"et-EE-AnuNeural\", \"et-EE-KertNeural\", \"fil-PH-AngeloNeural\", \"fil-PH-BlessicaNeural\", \"fi-FI-HarriNeural\", \"fi-FI-NooraNeural\", \"fr-BE-CharlineNeural\", \"fr-BE-GerardNeural\", \"fr-CA-ThierryNeural\", \"fr-CA-AntoineNeural\", \"fr-CA-JeanNeural\", \"fr-CA-SylvieNeural\", \"fr-FR-VivienneMultilingualNeural\", \"fr-FR-RemyMultilingualNeural\", \"fr-FR-DeniseNeural\", \"fr-FR-EloiseNeural\", \"fr-FR-HenriNeural\", \"fr-CH-ArianeNeural\", \"fr-CH-FabriceNeural\", \"gl-ES-RoiNeural\", \"gl-ES-SabelaNeural\", \"ka-GE-EkaNeural\", \"ka-GE-GiorgiNeural\", \"de-AT-IngridNeural\", \"de-AT-JonasNeural\", \"de-DE-SeraphinaMultilingualNeural\", \"de-DE-FlorianMultilingualNeural\", \"de-DE-AmalaNeural\", \"de-DE-ConradNeural\", \"de-DE-KatjaNeural\", \"de-DE-KillianNeural\", \"de-CH-JanNeural\", \"de-CH-LeniNeural\", \"el-GR-AthinaNeural\", \"el-GR-NestorasNeural\", \"gu-IN-DhwaniNeural\", \"gu-IN-NiranjanNeural\", \"he-IL-AvriNeural\", \"he-IL-HilaNeural\", \"hi-IN-MadhurNeural\", \"hi-IN-SwaraNeural\", \"hu-HU-NoemiNeural\", \"hu-HU-TamasNeural\", \"is-IS-GudrunNeural\", \"is-IS-GunnarNeural\", \"id-ID-ArdiNeural\", \"id-ID-GadisNeural\", \"ga-IE-ColmNeural\", \"ga-IE-OrlaNeural\", \"it-IT-GiuseppeNeural\", \"it-IT-DiegoNeural\", \"it-IT-ElsaNeural\", \"it-IT-IsabellaNeural\", \"ja-JP-KeitaNeural\", \"ja-JP-NanamiNeural\", \"jv-ID-DimasNeural\", \"jv-ID-SitiNeural\", \"kn-IN-GaganNeural\", \"kn-IN-SapnaNeural\", \"kk-KZ-AigulNeural\", \"kk-KZ-DauletNeural\", \"km-KH-PisethNeural\", \"km-KH-SreymomNeural\", \"ko-KR-HyunsuNeural\", \"ko-KR-InJoonNeural\", \"ko-KR-SunHiNeural\", \"lo-LA-ChanthavongNeural\", \"lo-LA-KeomanyNeural\", \"lv-LV-EveritaNeural\", \"lv-LV-NilsNeural\", \"lt-LT-LeonasNeural\", \"lt-LT-OnaNeural\", \"mk-MK-AleksandarNeural\", \"mk-MK-MarijaNeural\", \"ms-MY-OsmanNeural\", \"ms-MY-YasminNeural\", \"ml-IN-MidhunNeural\", \"ml-IN-SobhanaNeural\", \"mt-MT-GraceNeural\", \"mt-MT-JosephNeural\", \"mr-IN-AarohiNeural\", \"mr-IN-ManoharNeural\", \"mn-MN-BataaNeural\", \"mn-MN-YesuiNeural\", \"ne-NP-HemkalaNeural\", \"ne-NP-SagarNeural\", \"nb-NO-FinnNeural\", \"nb-NO-PernilleNeural\", \"ps-AF-GulNawazNeural\", \"ps-AF-LatifaNeural\", \"fa-IR-DilaraNeural\", \"fa-IR-FaridNeural\", \"pl-PL-MarekNeural\", \"pl-PL-ZofiaNeural\", \"pt-BR-ThalitaNeural\", \"pt-BR-AntonioNeural\", \"pt-BR-FranciscaNeural\", \"pt-PT-DuarteNeural\", \"pt-PT-RaquelNeural\", \"ro-RO-AlinaNeural\", \"ro-RO-EmilNeural\", \"ru-RU-DmitryNeural\", \"ru-RU-SvetlanaNeural\", \"sr-RS-NicholasNeural\", \"sr-RS-SophieNeural\", \"si-LK-SameeraNeural\", \"si-LK-ThiliniNeural\", \"sk-SK-LukasNeural\", \"sk-SK-ViktoriaNeural\", \"sl-SI-PetraNeural\", \"sl-SI-RokNeural\", \"so-SO-MuuseNeural\", \"so-SO-UbaxNeural\", \"es-AR-ElenaNeural\", \"es-AR-TomasNeural\", \"es-BO-MarceloNeural\", \"es-BO-SofiaNeural\", \"es-CL-CatalinaNeural\", \"es-CL-LorenzoNeural\", \"es-ES-XimenaNeural\", \"es-CO-GonzaloNeural\", \"es-CO-SalomeNeural\", \"es-CR-JuanNeural\", \"es-CR-MariaNeural\", \"es-CU-BelkysNeural\", \"es-CU-ManuelNeural\", \"es-DO-EmilioNeural\", \"es-DO-RamonaNeural\", \"es-EC-AndreaNeural\", \"es-EC-LuisNeural\", \"es-SV-LorenaNeural\", \"es-SV-RodrigoNeural\", \"es-GQ-JavierNeural\", \"es-GQ-TeresaNeural\", \"es-GT-AndresNeural\", \"es-GT-MartaNeural\", \"es-HN-CarlosNeural\", \"es-HN-KarlaNeural\", \"es-MX-DaliaNeural\", \"es-MX-JorgeNeural\", \"es-NI-FedericoNeural\", \"es-NI-YolandaNeural\", \"es-PA-MargaritaNeural\", \"es-PA-RobertoNeural\", \"es-PY-MarioNeural\", \"es-PY-TaniaNeural\", \"es-PE-AlexNeural\", \"es-PE-CamilaNeural\", \"es-PR-KarinaNeural\", \"es-PR-VictorNeural\", \"es-ES-AlvaroNeural\", \"es-ES-ElviraNeural\", \"es-US-AlonsoNeural\", \"es-US-PalomaNeural\", \"es-UY-MateoNeural\", \"es-UY-ValentinaNeural\", \"es-VE-PaolaNeural\", \"es-VE-SebastianNeural\", \"su-ID-JajangNeural\", \"su-ID-TutiNeural\", \"sw-KE-RafikiNeural\", \"sw-KE-ZuriNeural\", \"sw-TZ-DaudiNeural\", \"sw-TZ-RehemaNeural\", \"sv-SE-MattiasNeural\", \"sv-SE-SofieNeural\", \"ta-IN-PallaviNeural\", \"ta-IN-ValluvarNeural\", \"ta-MY-KaniNeural\", \"ta-MY-SuryaNeural\", \"ta-SG-AnbuNeural\", \"ta-SG-VenbaNeural\", \"ta-LK-KumarNeural\", \"ta-LK-SaranyaNeural\", \"te-IN-MohanNeural\", \"te-IN-ShrutiNeural\", \"th-TH-NiwatNeural\", \"th-TH-PremwadeeNeural\", \"tr-TR-AhmetNeural\", \"tr-TR-EmelNeural\", \"uk-UA-OstapNeural\", \"uk-UA-PolinaNeural\", \"ur-IN-GulNeural\", \"ur-IN-SalmanNeural\", \"ur-PK-AsadNeural\", \"ur-PK-UzmaNeural\", \"uz-UZ-MadinaNeural\", \"uz-UZ-SardorNeural\", \"vi-VN-HoaiMyNeural\", \"vi-VN-NamMinhNeural\", \"cy-GB-AledNeural\", \"cy-GB-NiaNeural\", \"zu-ZA-ThandoNeural\", \"zu-ZA-ThembaNeural\"]\n",
        "toc_do_doc = 0 # @param {\"type\":\"slider\",\"min\":-100,\"max\":100,\"step\":1}\n",
        "#@markdown **C√°c t√πy ch·ªçn v·ªÅ m√¥ h√¨nh nh∆∞: Cao ƒë·ªô v√† Ch·ªâ m·ª•c**\n",
        "ten_mo_hinh = \"\" #@param {\"type\":\"string\",\"placeholder\":\"T√™n m√¥ h√¨nh\"}\n",
        "cao_do = 0 #@param {\"type\":\"slider\",\"min\":-20,\"max\":20,\"step\":1}\n",
        "anh_huong_cua_chi_muc = 0.5 #@param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.01}\n",
        "#@markdown **C√°c t√πy ch·ªçn v·ªÅ tr√≠ch xu·∫•t d·ªØ li·ªáu, hop length, b·∫£o v·ªá √¢m thanh**\n",
        "phuong_phap_trich_xuat = \"rmvpe\" #@param [\"mangio-crepe-full\", \"crepe-full\", \"fcpe\", \"rmvpe\", \"harvest\", \"pyin\"]\n",
        "hop_length = 64 # @param {\"type\":\"slider\",\"min\":64,\"max\":512,\"step\":1}\n",
        "bao_ve_phu_am = 0.5 #@param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.1}\n",
        "#@markdown **T√πy ch·ªçn v·ªÅ c·∫Øt √¢m thanh tƒ©nh ƒë·ªÉ ƒë·∫°t t·ªëc ƒë·ªô cao h∆°n v√† ƒë·ªãnh d·∫°ng t·ªáp ƒë·∫ßu ra**\n",
        "cat_am_thanh = False #@param {\"type\":\"boolean\"}\n",
        "dinh_dang_tep = \"wav\" #@param [\"wav\", \"mp3\", \"flac\", \"ogg\", \"opus\", \"m4a\", \"mp4\", \"aac\", \"alac\", \"wma\", \"aiff\", \"webm\", \"ac3\"]\n",
        "\n",
        "filename = None\n",
        "if van_ban: input_text = van_ban\n",
        "else:\n",
        "    print(\"√î vƒÉn b·∫£n tr·ªëng. Vui l√≤ng t·∫£i l√™n 1 t·ªáp vƒÉn b·∫£n txt ƒë·ªÉ ti·∫øn h√†nh chuy·ªÉn ƒë·ªïi!\")\n",
        "    uploaded = files.upload()\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    input_text = process_input(filename)\n",
        "\n",
        "if ten_mo_hinh:\n",
        "    if not ten_mo_hinh.endswith((\".pth\", \".onnx\")): ten_mo_hinh = ten_mo_hinh + \".pth\"\n",
        "    model_path = os.path.join(\"assets\", \"weights\", ten_mo_hinh)\n",
        "    index_path = get_index(f\"{ten_mo_hinh}.pth\".split(\"_\")[0])\n",
        "else:\n",
        "    model_name = sorted(list(model for model in os.listdir(os.path.join(\"assets\", \"weights\")) if model.endswith((\".pth\", \".onnx\")) and not model.startswith(\"G_\") and not model.startswith(\"D_\")))\n",
        "    indexpath = sorted([os.path.join(root, name) for root, _, files in os.walk(os.path.join(\"assets\", \"logs\"), topdown=False) for name in files if name.endswith(\".index\")])\n",
        "\n",
        "    if len(model_name) < 1: raise ValueError(\"Vui l√≤ng cung c·∫•p m√¥ h√¨nh ƒë·ªÉ ti·∫øn h√†nh chuy·ªÉn ƒë·ªïi!\")\n",
        "    elif len(model_name) == 1:\n",
        "        model_path = os.path.join(\"assets\", \"weights\", model_name[0])\n",
        "        index_path = get_index(os.path.basename(model_name[0])[0])\n",
        "    else:\n",
        "        print(\"T√¨m th·∫•y nhi·ªÅu h∆°n 1 m√¥ h√¨nh, vui l√≤ng nh·∫≠p s·ªë th·ª© t·ª± c·ªßa m√¥ h√¨nh ƒë·ªÉ ti·∫øn h√†nh chuy·ªÉn ƒë·ªïi!\")\n",
        "        for m in model_name:\n",
        "            print(f\"{model_name.index(m)}. {m}\")\n",
        "\n",
        "        while 1:\n",
        "            try:\n",
        "                model_index = int(input(\"Nh·∫≠p s·ªë th·ª© t·ª± c·ªßa m√¥ h√¨nh: \"))\n",
        "                if 0 <= model_index < len(model_name):\n",
        "                    selected_model = model_name[model_index]\n",
        "                    print(f\"B·∫°n ƒë√£ ch·ªçn m√¥ h√¨nh: {selected_model}\")\n",
        "                    break\n",
        "                else: print(\"S·ªë th·ª© t·ª± kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "            except ValueError:\n",
        "                print(\"Vui l√≤ng nh·∫≠p m·ªôt s·ªë nguy√™n.\")\n",
        "            except IndexError:\n",
        "                print(\"S·ªë th·ª© t·ª± v∆∞·ª£t qu√° ph·∫°m vi. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "\n",
        "        model_path = os.path.join(\"assets\", \"weights\", selected_model)\n",
        "        index_path = get_index(os.path.basename(selected_model).split(\"_\")[0])\n",
        "\n",
        "if not index_path: print(\"Kh√¥ng t√¨m th·∫•y ch·ªâ m·ª•c!\")\n",
        "\n",
        "tts_output = os.path.join(\"audios\", f\"tts.{dinh_dang_tep}\")\n",
        "convert_tts_output = os.path.join(\"audios\", f\"tts-convert.{dinh_dang_tep}\")\n",
        "\n",
        "args = f'from main.app.core.tts import TTS; TTS(\\\\\"{input_text}\\\\\", \\\\\"{giong_noi}\\\\\", {toc_do_doc}, \\\\\"{tts_output}\\\\\", 0, False, \\\\\"{filename}\\\\\")'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "args = f'from main.app.core.inference import convert_tts; convert_tts(False, False, {cao_do}, 0.7, \\\\\"{model_path}\\\\\", \\\\\"{index_path}\\\\\", {anh_huong_cua_chi_muc}, \\\\\"{tts_output}\\\\\", \\\\\"{convert_tts_output}\\\\\", \\\\\"{dinh_dang_tep}\\\\\", \\\\\"{phuong_phap_trich_xuat}\\\\\", None, {hop_length}, \\\\\"hubert_base\\\\\", None, 0, 3, 1, {bao_ve_phu_am}, {cat_am_thanh}, 1, False, False, False, 0, 0, \\\\\"None\\\\\", \\\\\"fairseq\\\\\", False, 255.0)'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "clear_output()\n",
        "print(f\"T·ªáp ƒë·∫ßu ra c·ªßa b·∫°n l√†: /content/Vietnamese_RVC/audios/tts-convert.{dinh_dang_tep}\")\n",
        "display(Button(description=\"\\u2714 Ho√†n T·∫•t!\", button_style=\"success\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kzVFeANCq2lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hu·∫•n Luy·ªán M√¥ H√¨nh ü§ñ**"
      ],
      "metadata": {
        "id": "9U2vuwoUyiPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìÅ **T·∫°o d·ªØ li·ªáu hu·∫•n luy·ªán t·ª´ ƒë∆∞·ªùng d·∫´n**\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "#@markdown **T·∫°o d·ªØ li·ªáu hu·∫•n luy·ªán t·ª´ ƒë∆∞·ªùng d·∫´n li√™n k·∫øt**\n",
        "lam_sach_du_lieu = False #@param {\"type\":\"boolean\"}\n",
        "duong_dan_lien_ket = \"\" #@param {\"type\":\"string\", placeholder:\"ƒê∆∞·ªùng d·∫´n li√™n k·∫øt\"}\n",
        "\n",
        "args = f'from main.app.core.training import create_dataset; [None for _ in create_dataset(\\\\\"{duong_dan_lien_ket}\\\\\", \\\\\"dataset\\\\\", {lam_sach_du_lieu}, 0.7, True, \\\\\"Version-2\\\\\", 0.25, 384, True, False, 0, 0, 1024, 1, 48000)]'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "clear_output()\n",
        "display(Button(description=\"\\u2714 Ho√†n T·∫•t!\", button_style=\"success\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XYssmDxRy4Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üî® **X·ª≠ l√Ω tr√≠ch xu·∫•t d·ªØ li·ªáu** ‚õèÔ∏è\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "#@markdown **T·∫£i d·ªØ li·ªáu t·ª´ google drive l√™n d·ªØ li·ªáu c·ªßa google colab ƒë·ªÉ ti·∫øn h√†nh x·ª≠ l√Ω v√† tr√≠ch xu·∫•t**\n",
        "tai_du_lieu_tu_drive = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **T√™n c·ªßa m√¥ h√¨nh ƒë·ªÉ ti·∫øn h√†nh**\n",
        "ten_mo_hinh = \"\" #@param {\"type\":\"string\", placeholder: \"T√™n m√¥ h√¨nh\"}\n",
        "#@markdown **T·ªëc ƒë·ªô l·∫•y m·∫´u c·ªßa m√¥ h√¨nh ƒë·ªÉ ti·∫øn h√†nh**\n",
        "toc_do_lay_mau = \"48k\" #@param [\"32k\", \"40k\", \"48k\"]\n",
        "#@markdown **Ph∆∞∆°ng ph√°p tr√≠ch xu·∫•t cao ƒë·ªô v√† hop length cho m√¥ h√¨nh**\n",
        "phuong_phap_trich_xuat = \"rmvpe\" #@param [\"mangio-crepe-full\", \"crepe-full\", \"fcpe\", \"rmvpe\", \"harvest\", \"pyin\"]\n",
        "hop_length = 64 # @param {\"type\":\"slider\",\"min\":64,\"max\":512,\"step\":1}\n",
        "\n",
        "if tai_du_lieu_tu_drive:\n",
        "    if not os.path.exists(\"/content/drive/MyDrive\"): raise ValueError(\"B·∫°n ch∆∞a k·∫øt n·ªëi v·ªõi google drive\")\n",
        "    if len([f for f in os.listdir(\"/content/drive/MyDrive/dataset\") if not \".ipynb_checkpoints\" in f]) < 1: raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu\")\n",
        "\n",
        "    for audios in os.listdir(\"/content/drive/MyDrive/dataset\"):\n",
        "        shutil.copy(f\"/content/drive/MyDrive/dataset/{audios}\", \"/content/Vietnamese_RVC/dataset\")\n",
        "elif not any(f.lower().endswith((\"wav\", \"mp3\", \"flac\", \"ogg\", \"opus\", \"m4a\", \"mp4\", \"aac\", \"alac\", \"wma\", \"aiff\", \"webm\", \"ac3\")) for f in os.listdir(\"/content/Vietnamese_RVC/dataset\") if os.path.isfile(os.path.join(\"/content/Vietnamese_RVC/dataset\", f))):\n",
        "    uploaded = files.upload()\n",
        "    for f in list(uploaded.keys()):\n",
        "        input_path = os.path.join(\"dataset\", os.path.basename(f).replace(' ', '_').replace('(', '').replace(')', '').replace('{', '').replace('}', ''))\n",
        "        shutil.move(f, input_path)\n",
        "\n",
        "if not ten_mo_hinh: raise ValueError(\"Vui l√≤ng cung c·∫•p t√™n ƒë·ªÉ ti·∫øn h√†nh!\")\n",
        "\n",
        "args = f'from main.app.core.training import preprocess; [None for _ in preprocess(\\\\\"{ten_mo_hinh}\\\\\", \\\\\"{toc_do_lay_mau}\\\\\", 2, True, True, \\\\\"dataset\\\\\", False, 0.7)]'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "args = f'from main.app.core.training import extract; [None for _ in extract(\\\\\"{ten_mo_hinh}\\\\\", \\\\\"v2\\\\\", \\\\\"{phuong_phap_trich_xuat}\\\\\", True, {hop_length}, 2, 0, \\\\\"{toc_do_lay_mau}\\\\\", \\\\\"hubert_base\\\\\", None, False, \\\\\"fairseq\\\\\", False, 1, None, False)]'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "args = f'from main.app.core.training import create_index; [None for _ in create_index(\\\\\"{ten_mo_hinh}\\\\\", \\\\\"v2\\\\\", \\\\\"Auto\\\\\")]'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "clear_output()\n",
        "display(Button(description=\"\\u2714 Ho√†n T·∫•t!\", button_style=\"success\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6B_JOyUUy0U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ü§ñ **Hu·∫•n luy·ªán m√¥ h√¨nh**\n",
        "import os\n",
        "\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "#@markdown **T√™n c·ªßa m√¥ h√¨nh v√† t·ªëc ƒë·ªô l·∫•y m·∫´u ƒë·ªÉ ti·∫øn h√†nh hu·∫•n luy·ªán m√¥ h√¨nh**\n",
        "ten_mo_hinh = \"\" #@param {\"type\":\"string\", placeholder: \"T√™n m√¥ h√¨nh\"}\n",
        "toc_do_lay_mau = \"48k\" #@param [\"32k\", \"40k\", \"48k\"]\n",
        "#@markdown **S·ªë l∆∞·ª£ng k·ª∑ nguy√™n c·ªßa m√¥ h√¨nh v√† bao nhi√™u k·ª∑ nguy√™n s·∫Ω l∆∞u m·ªôt l·∫ßn**\n",
        "so_luong_ky_nguyen = 300 #@param {\"type\":\"slider\", min:1, max:10000}\n",
        "tan_suat_luu = 50 #@param {\"type\":\"slider\", min:1, max:10000}\n",
        "#@markdown **T√πy ch·ªçn v·ªÅ k√≠ch th∆∞·ªõc l√¥ v√† c√≥ s·ª≠ d·ª•ng b·ªô nh·ªõ ƒë·ªám hay kh√¥ng**\n",
        "kich_thuoc_lo = 10 #@param {\"type\":\"slider\", min:1, max:20}\n",
        "bo_nho_dem = False #@param {\"type\":\"boolean\"}\n",
        "#@markdown **T√πy ch·ªçn v·ªÅ bi·ªÉu ƒë·ªì hu·∫•n luy·ªán, t·ª± ƒë·ªông ki·ªÉm tra hu·∫•n luy·ªán qu√° s·ª©c v√† s·ª≠ d·ª•ng t√πy ch·ªânh m√¥ h√¨nh hu·∫•n luy·ªán tr∆∞·ªõc**\n",
        "su_dung_bieu_do = False #@param {type:\"boolean\"}\n",
        "kiem_tra_huan_luyen = False #@param {\"type\":\"boolean\"}\n",
        "tuy_chinh_huan_luyen_truoc = False #@param {\"type\":\"boolean\"}\n",
        "\n",
        "if su_dung_bieu_do:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir ./assets/logs --port=6870\n",
        "\n",
        "if tuy_chinh_huan_luyen_truoc:\n",
        "    model_name = [f for f in os.listdir(os.path.join(\"assets\", \"models\", \"pretrained_custom\")) if f.endswith(\".pth\")]\n",
        "\n",
        "    if len(model_name) == 2:\n",
        "        for m in model_name:\n",
        "            print(f\"{model_name.index(m)}. {m}\")\n",
        "\n",
        "        while 1:\n",
        "            try:\n",
        "                model_index_d = int(input(\"Nh·∫≠p s·ªë th·ª© t·ª± c·ªßa m√¥ h√¨nh D: \"))\n",
        "                if 0 <= model_index_d < len(model_name):\n",
        "                    selected_model_D = model_name[model_index_d]\n",
        "                    print(f\"B·∫°n ƒë√£ ch·ªçn m√¥ h√¨nh D: {selected_model_D}\")\n",
        "                    break\n",
        "                else: print(\"S·ªë th·ª© t·ª± kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "            except ValueError:\n",
        "                print(\"Vui l√≤ng nh·∫≠p m·ªôt s·ªë nguy√™n.\")\n",
        "            except IndexError:\n",
        "                print(\"S·ªë th·ª© t·ª± v∆∞·ª£t qu√° ph·∫°m vi. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "\n",
        "        model_name.remove(selected_model_D)\n",
        "        model_index_g = model_name[0]\n",
        "    elif len(model_name) >= 2:\n",
        "        for m in model_name:\n",
        "            print(f\"{model_name.index(m)}. {m}\")\n",
        "\n",
        "        while 1:\n",
        "            try:\n",
        "                model_index_d = int(input(\"Nh·∫≠p s·ªë th·ª© t·ª± c·ªßa m√¥ h√¨nh D: \"))\n",
        "                if 0 <= model_index_d < len(model_name):\n",
        "                    selected_model_D = model_name[model_index_d]\n",
        "                    print(f\"B·∫°n ƒë√£ ch·ªçn m√¥ h√¨nh D: {selected_model_D}\")\n",
        "                    break\n",
        "                else: print(\"S·ªë th·ª© t·ª± kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "            except ValueError:\n",
        "                print(\"Vui l√≤ng nh·∫≠p m·ªôt s·ªë nguy√™n.\")\n",
        "            except IndexError:\n",
        "                print(\"S·ªë th·ª© t·ª± v∆∞·ª£t qu√° ph·∫°m vi. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "\n",
        "        while 1:\n",
        "            try:\n",
        "                model_index_g = int(input(\"Nh·∫≠p s·ªë th·ª© t·ª± c·ªßa m√¥ h√¨nh G: \"))\n",
        "                if 0 <= model_index_g < len(model_name):\n",
        "                    selected_model_G = model_name[model_index_g]\n",
        "                    print(f\"B·∫°n ƒë√£ ch·ªçn m√¥ h√¨nh G: {selected_model_G}\")\n",
        "                    break\n",
        "                else: print(\"S·ªë th·ª© t·ª± kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "            except ValueError:\n",
        "                print(\"Vui l√≤ng nh·∫≠p m·ªôt s·ªë nguy√™n.\")\n",
        "            except IndexError:\n",
        "                print(\"S·ªë th·ª© t·ª± v∆∞·ª£t qu√° ph·∫°m vi. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "\n",
        "        if selected_model_D == selected_model_G: raise ValueError(\"M√¥ h√¨nh D v√† G gi·ªëng nhau!\")\n",
        "        clear_output()\n",
        "    else: print(\"kh√¥ng t√¨m th·∫•y m√¥ h√¨nh hu·∫•n luy·ªán tr∆∞·ªõc n√†o!\")\n",
        "else: selected_model_G = selected_model_D = None\n",
        "\n",
        "\n",
        "args = f'from main.app.core.training import training; [None for _ in training(\\\\\"{ten_mo_hinh}\\\\\", \\\\\"v2\\\\\", {tan_suat_luu}, True, True, {so_luong_ky_nguyen}, \\\\\"{toc_do_lay_mau}\\\\\", {kich_thuoc_lo}, 0, True, False, {tuy_chinh_huan_luyen_truoc}, \\\\\"{selected_model_G}\\\\\", \\\\\"{selected_model_D}\\\\\", {kiem_tra_huan_luyen}, 50, False, {bo_nho_dem}, \\\\\"\\\\\", \\\\\"Default\\\\\", False, False, True, \\\\\"AdamW\\\\\", False)]'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "Button(description=\"\\u2714 Ho√†n t·∫•t!\", button_style=\"success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pRuwjqoky7lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üì¶ **N√©n v√† l∆∞u m√¥ h√¨nh** üì¶\n",
        "\n",
        "#@markdown **Ch·∫°y √¥ n√†y v√† ch·ªçn t·ªáp m√¥ h√¨nh c·∫ßn n√©n!**\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def get_index(model):\n",
        "    return next((f for f in [os.path.join(root, name) for root, _, files in os.walk(os.path.join(\"assets\", \"logs\"), topdown=False) for name in files if name.endswith(\".index\") and \"trained\" not in name] if model.split(\".\")[0] in f), \"\")\n",
        "\n",
        "model_name = sorted(list(model for model in os.listdir(os.path.join(\"assets\", \"weights\")) if model.endswith((\".pth\", \".onnx\")) and not model.startswith(\"G_\") and not model.startswith(\"D_\")))\n",
        "indexpath = sorted([os.path.join(root, name) for root, _, files in os.walk(os.path.join(\"assets\", \"logs\"), topdown=False) for name in files if name.endswith(\".index\")])\n",
        "\n",
        "if len(model_name) < 1: raise ValueError(\"Vui l√≤ng cung c·∫•p m√¥ h√¨nh ƒë·ªÉ ti·∫øn h√†nh chuy·ªÉn ƒë·ªïi!\")\n",
        "elif len(model_name) == 1:\n",
        "    model_path = os.path.join(\"assets\", \"weights\", model_name[0])\n",
        "    index_path = get_index(os.path.basename(model_name[0])[0])\n",
        "else:\n",
        "    print(\"T√¨m th·∫•y nhi·ªÅu h∆°n 1 m√¥ h√¨nh, vui l√≤ng nh·∫≠p s·ªë th·ª© t·ª± c·ªßa m√¥ h√¨nh ƒë·ªÉ ti·∫øn h√†nh chuy·ªÉn ƒë·ªïi!\")\n",
        "    for m in model_name:\n",
        "        print(f\"{model_name.index(m)}. {m}\")\n",
        "\n",
        "    while 1:\n",
        "        try:\n",
        "            model_index = int(input(\"Nh·∫≠p s·ªë th·ª© t·ª± c·ªßa m√¥ h√¨nh: \"))\n",
        "            if 0 <= model_index < len(model_name):\n",
        "                selected_model = model_name[model_index]\n",
        "                print(f\"B·∫°n ƒë√£ ch·ªçn m√¥ h√¨nh: {selected_model}\")\n",
        "                break\n",
        "            else: print(\"S·ªë th·ª© t·ª± kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "        except ValueError:\n",
        "            print(\"Vui l√≤ng nh·∫≠p m·ªôt s·ªë nguy√™n.\")\n",
        "        except IndexError:\n",
        "            print(\"S·ªë th·ª© t·ª± v∆∞·ª£t qu√° ph·∫°m vi. Vui l√≤ng nh·∫≠p l·∫°i.\")\n",
        "\n",
        "    model_path = os.path.join(\"assets\", \"weights\", selected_model)\n",
        "    index_path = get_index(os.path.basename(selected_model).split(\"_\")[0])\n",
        "\n",
        "if not index_path: print(\"Kh√¥ng t√¨m th·∫•y ch·ªâ m·ª•c!\")\n",
        "zip_file_path = os.path.join(\"assets\", os.path.basename(model_path).split(\"_\")[0] + \".zip\")\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
        "    zipf.write(model_path, os.path.basename(model_path))\n",
        "    if index_path: zipf.write(index_path, os.path.basename(index_path))\n",
        "\n",
        "clear_output()\n",
        "print(f\"ƒê∆∞·ªùng d·∫´n m√¥ h√¨nh c·ªßa b·∫°n: {zip_file_path}\")\n",
        "Button(description=\"\\u2714 Ho√†n t·∫•t!\", button_style=\"success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7_Z2qvZo4oHa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tkqks7bO2Cye",
        "XP4ifZaG_yd5",
        "ekfkFFNqppfM",
        "ers351v_CMGN"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}